<!DOCTYPE html><html><head><link rel="stylesheet" type="text/css" media="all" href="/css/app.css"><link rel="alternate" type="application/rss+xml" title="{ blog: david mosher }" href="/index.xml"><title>{ blog: david mosher }</title></head><body><div id="wrap"><header class="root"><h1><a href="/">{ blog: david mosher }</a></h1><h2>personal opinions from a software developer living in ottawa, canada</h2></header><aside id="sidebar"><section id="profile"><a href="https://github.com/davemo" title="David Mosher's Github"><img class="profile_image" src="/img/davemo.headphones.png" alt="David Mosher"></a><p>David Mosher is a Canadian Software Developer, Designer, Musician, and Artist.</p><div class="icons"><a class="icon github" href="https://github.com/davemo" title="davemo on github"></a><a class="icon linkedin" href="https://linkedin.com/in/dmosher" title="dmosher on linkedin"></a><a class="icon twitter" href="https://twitter.com/dmosher" title="dmosher on twitter"></a><a class="icon youtube" href="https://youtube.com/davidmosher" title="davidmosher on youtube"></a></div></section><nav><a href="/">homepage</a><a href="/archive.html">blog archives</a></nav></aside><article class="post clearfix"><header><section id="navigation"></section><h1>archives</h1></header><section class="body"><div class="inner" id="archive"><div><a href="/posts/2020-03-10-the-missing-fundamental.html">The Missing Fundamental</a><pre><{
  "path": "app/posts/2020-03-10-the-missing-fundamental.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The Missing Fundamental",
      "date": "2020-03-10"
    },
    "source": "\nMusic composition and production is a large part of my life outside of software development, so much so that I often find myself thinking of ways to draw parallels between the two. One such parallel that has stuck with me over the past 6 months or so is the concept of [the missing fundamental](https://en.wikipedia.org/wiki/Missing_fundamental).\n\n> A harmonic sound is said to have a **missing fundamental**, **suppressed fundamental**, or **phantom fundamental** when its overtones suggest a fundamental frequency but the sound lacks a component at the fundamental frequency itself.\n\nWhen I first learned about this concept, I couldn't help but think of how it applied to the work we do as software engineers. In the same way that skilled audio engineers can leverage the concept of the missing fundamental to improve the characteristics of sound, skilled software engineers can use a similar set of skills to improve the performance of applications.\n\n> This very concept of \"missing fundamental\" being reproduced based on the overtones in the tone has been used to create the illusion of bass in sound systems that are not capable of such bass. In mid-1999, Meir Shashoua of Tel Aviv, co-founder of Waves Audio, patented an algorithm to create the sense of the missing fundamental by synthesizing higher harmonics. Waves Audio released the MaxxBass plug-in to allow computer users to apply the synthesized harmonics to their audio files.\n\n# The Fundamentals of Software Performance\n\n[Ali](https://blog.testdouble.com/authors/ali-ibrahim/) and I were recently tasked with improving the performance of a legacy codebase that was deployed on Heroku using Node.js, MongoDB, and Angular 1. One of our first steps in evaluating the performance of code is to do an audit of dependencies and configuration; this is a great starting point because it can often lead to simple fixes for performance issues, like updating a database ORM adapter that can query things more efficiently.\n\nIn this case an audit of dependencies didn't yield much and we had to dive further into configuration on Heroku to really make sense of the performance challenge. Significant discovery number one was that the application was configured using Performance L [dynos](https://www.heroku.com/dynos) on Heroku (the most expensive _and_ highest tier available). This seemed strange since it did not appear commensurate with the surface area of the application; its purpose was to sync data using Heroku scheduler to pull from SalesForce into MongoDB.\n\nOne of our first steps was to reduce the dyno size and monitor logs to see if the Performance L size was warranted.\n\n## Fundamental #1: Investigate\n\nHeroku makes it pretty easy to peek at logs for your app, which is what we started with: `heroku logs --tail -a td-client-slow-app`. This yielded the following trace:\n\n```shell\napp[web.1]:\napp[web.1]: <--- Last few GCs --->\napp[web.1]:\napp[web.1]: <--- JS stacktrace --->\napp[web.1]:\napp[web.1]: ==== JS stack trace ==========\napp[web.1]:\napp[web.1]: 0: ExitFrame [pc: 0x1374fd9]\napp[web.1]: Security context: 0x01f9540008a1 <JSObject>\napp[web.1]: 1: getOwnPropertyNames [0x1f954001251](truncated...)\napp[web.1]: 2: getOwnPropertyDescriptors [0x3dffde9f7229]\n[/app/node_modules/mongoose/lib/helpers/document/compile.js:159]\napp[web.1]:\napp[web.1]: FATAL ERROR: Ineffective mark-compacts\napp[web.1]: near heap limit Allocation failed -\napp[web.1]: JavaScript heap out of memory\n```\n\n(Note: The [slug](https://devcenter.heroku.com/articles/slug-compiler) for this application was \\~74mb, which didn't seem overly large to warrant running out of memory on the lowest tier dyno Heroku provides. That dyno allocates up to 512mb of RAM, so we dug into the code path that led to the above stacktrace to gain some more information.)\n\n## Fundamental #2: Profile\n\nNode.js has some pretty decent profiling tools for engineers who want to dive into performance profiling. TD-resident DevOps pro [Micah](https://blog.testdouble.com/authors/micah-adams/) showed me that you can add some flags to the `node` process on startup to influence how V8 manages garbage collection. This is useful if you aren't getting consistency in your crashes and want to place constraints on the application runtime in order to suss out the source of the memory leak.\n\n`node --optimize_for_size --max_old_space_size=460 app.js`\n\nArtifically lowering the max heap size below what Heroku provisions for Standard dynos yielded the source of the leak was a method called `getUsers` which was responsible for querying a list of users and their permissions from MongoDB. Here's a sample of what that code looked like as we first found it:\n\n```javascript\ngetUsers: function(req, res) {\n  User.find({}, function(err, users) {\n    var allUsers = users;\n    var adminUsers = [];\n    var corpUsers = [];\n    var techUsers = [];\n    var formalUsers = [];\n    var searchUsers = [];\n    users.forEach(function(user) {\n      if(user.permissions.admin &&\n         (user.permissions.admin.corpUsers ||\n          user.permissions.admin.techUsers ||\n          user.permissions.admin.formalUsers ||\n          user.permissions.admin.searchUsers ||\n          user.permissions.admin.superAdmin)) {\n        adminUsers.push(user);\n      }\n      if(user.permissions.general.corpUsers) {\n        corpUsers.push(user);\n      }\n      if(user.permissions.general.formalUsers) {\n        formalUsers.push(user);\n      }\n      if(user.permissions.general.search) {\n        searchUsers.push(user);\n      }\n      // this continued on for another 40 lines or so...\n    })\n  })\n}\n```\n\nNode.js has [performance tooling](https://nodejs.org/api/perf_hooks.html) built-in that allows you to gain insight around memory and CPU usage, which is what we used next:\n\n```javascript\nconst { PerformanceObserver, performance } = require('perf_hooks')\nconst o = new PerformanceObserver((items) => {\n  console.log(items.getEntries()[0]);\n  performance.clearMarks();\n})\no.observe({ entryTypes: ['measure']})\n```\n\n```javascript\n// to get the approx mem usage you can add this log line:\nconsole.log(`\n  The script uses ~\n  ${process.memoryUsage().heapUsed / 1024 / 1024}\n  MB\n`)\n```\n\n```shell\n# Output\nPerformanceEntry {\n  name: 'getUsers to res.status(200)',\n  entryType: 'measure',\n  startTime: 5486.524808,\n  duration: 6559.275542\n}\nThe script uses ~ 456.143798828125 MB\n```\n\nLooking at this code I couldn't help but wonder if there was a more efficient way to query and aggregate this information.\n\n## Fundamental #3: Identify the _Missing_ Fundamental\n\nReturning to the idea of the missing fundamental, as audio engineers must ask themselves \"what can I change about the frequencies in this mix in order to bring things into harmony?\" the relevant question for software engineers is very similar: \"what does this system need in order to bring harmony to its operation?\". In our case it was also helpful to consider that question in a historical context as \"what fundamental were the original developers missing when they built this?\"\n\nIn both cases, the answer for this application was **how to query things more efficiently**!\n\nThe `getUsers` method above was doing two things wrong; querying inefficiently for _all_ the users in the system and then allocating large arrays to partition the data based on permissions. Once we understood the missing fundamental we had a path forward to try and optimize this poorly performing code: we should see if we can query things more efficiently. This is what we came up with using `async/await` and the MongoDB [aggregation pipeline](https://docs.mongodb.com/manual/aggregation/):\n\n```javascript\ngetUsers: async function(req, res) {\n  const adminUsers = await User.aggregate([\n    {\n      $match: {\n        $or: [\n          { \"permissions.admin.corpUsers\" : { $eq: true }},\n          { \"permissions.admin.techUsers\" : { $eq: true }},\n          { \"permissions.admin.formalUsers\" : { $eq: true }},\n          { \"permissions.admin.searchUser\" : { $eq: true }},\n          { \"permissions.admin.superAdmin\" : { $eq: true }},\n        ]\n      }\n    }\n  ])\n\n  const corpUsers = await User.aggregate([\n    {\n      $match: {\n        \"permissions.general.corpUsers\" : { $eq: true }\n      }\n    }\n  ])\n\n  // ... etc...\n\n  res.status(200).json({\n    data: {\n      adminUsers,\n      corpUsers,\n      ...\n    }\n  })\n}\n```\n\nOnce we had re-written and tested the query to make sure the output was the same, we re-ran our performance profiling to see what the difference was.\n\n```shell\nPerformanceEntry {\n  name: 'getUsers to res.status(200)',\n  entryType: 'measure',\n  startTime: 496079.094306,\n  duration: 270.1256\n}\nThe script uses ~ 44.550048828125 MB\n```\n\nUsing the Aggregation pipeline had yielded an order of magnitude less memory and CPU usage! Here's a couple of screenshots from the Heroku dashboard for this app that show the before/after comparisons as well.\n\n### Before - request timeouts, and large amounts of memory consumption.\n\n![Before](/img/the-missing-fundamental/before-30s-timeouts-large-ram-usage.png)\n\n### After - no timeouts, memory consumption reduced by a factor of 10.\n\n![After](/img/the-missing-fundamental/after-2s-no-timeouts-50mb-ram-usage.png)\n\n# Conclusions\n\nIf you find yourself in a similar situation evaluating the performance of some legacy code I would encourage you to think about asking questions around what the missing fundamental(s) are. Walking through **investigate**, **profile**, **identify** (rinse. repeat.) has been useful for me, and I hope it is for you!\n\nIf you're interested in this type of work, you should reach out and [say hi](mailto:hi@testdouble.com); they're always looking to hire expert software engineers. :)"
  },
  "attributes": {
    "title": "The Missing Fundamental",
    "date": "2020-03-10"
  },
  "markdown": "\nMusic composition and production is a large part of my life outside of software development, so much so that I often find myself thinking of ways to draw parallels between the two. One such parallel that has stuck with me over the past 6 months or so is the concept of [the missing fundamental](https://en.wikipedia.org/wiki/Missing_fundamental).\n\n> A harmonic sound is said to have a **missing fundamental**, **suppressed fundamental**, or **phantom fundamental** when its overtones suggest a fundamental frequency but the sound lacks a component at the fundamental frequency itself.\n\nWhen I first learned about this concept, I couldn't help but think of how it applied to the work we do as software engineers. In the same way that skilled audio engineers can leverage the concept of the missing fundamental to improve the characteristics of sound, skilled software engineers can use a similar set of skills to improve the performance of applications.\n\n> This very concept of \"missing fundamental\" being reproduced based on the overtones in the tone has been used to create the illusion of bass in sound systems that are not capable of such bass. In mid-1999, Meir Shashoua of Tel Aviv, co-founder of Waves Audio, patented an algorithm to create the sense of the missing fundamental by synthesizing higher harmonics. Waves Audio released the MaxxBass plug-in to allow computer users to apply the synthesized harmonics to their audio files.\n\n# The Fundamentals of Software Performance\n\n[Ali](https://blog.testdouble.com/authors/ali-ibrahim/) and I were recently tasked with improving the performance of a legacy codebase that was deployed on Heroku using Node.js, MongoDB, and Angular 1. One of our first steps in evaluating the performance of code is to do an audit of dependencies and configuration; this is a great starting point because it can often lead to simple fixes for performance issues, like updating a database ORM adapter that can query things more efficiently.\n\nIn this case an audit of dependencies didn't yield much and we had to dive further into configuration on Heroku to really make sense of the performance challenge. Significant discovery number one was that the application was configured using Performance L [dynos](https://www.heroku.com/dynos) on Heroku (the most expensive _and_ highest tier available). This seemed strange since it did not appear commensurate with the surface area of the application; its purpose was to sync data using Heroku scheduler to pull from SalesForce into MongoDB.\n\nOne of our first steps was to reduce the dyno size and monitor logs to see if the Performance L size was warranted.\n\n## Fundamental #1: Investigate\n\nHeroku makes it pretty easy to peek at logs for your app, which is what we started with: `heroku logs --tail -a td-client-slow-app`. This yielded the following trace:\n\n```shell\napp[web.1]:\napp[web.1]: <--- Last few GCs --->\napp[web.1]:\napp[web.1]: <--- JS stacktrace --->\napp[web.1]:\napp[web.1]: ==== JS stack trace ==========\napp[web.1]:\napp[web.1]: 0: ExitFrame [pc: 0x1374fd9]\napp[web.1]: Security context: 0x01f9540008a1 <JSObject>\napp[web.1]: 1: getOwnPropertyNames [0x1f954001251](truncated...)\napp[web.1]: 2: getOwnPropertyDescriptors [0x3dffde9f7229]\n[/app/node_modules/mongoose/lib/helpers/document/compile.js:159]\napp[web.1]:\napp[web.1]: FATAL ERROR: Ineffective mark-compacts\napp[web.1]: near heap limit Allocation failed -\napp[web.1]: JavaScript heap out of memory\n```\n\n(Note: The [slug](https://devcenter.heroku.com/articles/slug-compiler) for this application was \\~74mb, which didn't seem overly large to warrant running out of memory on the lowest tier dyno Heroku provides. That dyno allocates up to 512mb of RAM, so we dug into the code path that led to the above stacktrace to gain some more information.)\n\n## Fundamental #2: Profile\n\nNode.js has some pretty decent profiling tools for engineers who want to dive into performance profiling. TD-resident DevOps pro [Micah](https://blog.testdouble.com/authors/micah-adams/) showed me that you can add some flags to the `node` process on startup to influence how V8 manages garbage collection. This is useful if you aren't getting consistency in your crashes and want to place constraints on the application runtime in order to suss out the source of the memory leak.\n\n`node --optimize_for_size --max_old_space_size=460 app.js`\n\nArtifically lowering the max heap size below what Heroku provisions for Standard dynos yielded the source of the leak was a method called `getUsers` which was responsible for querying a list of users and their permissions from MongoDB. Here's a sample of what that code looked like as we first found it:\n\n```javascript\ngetUsers: function(req, res) {\n  User.find({}, function(err, users) {\n    var allUsers = users;\n    var adminUsers = [];\n    var corpUsers = [];\n    var techUsers = [];\n    var formalUsers = [];\n    var searchUsers = [];\n    users.forEach(function(user) {\n      if(user.permissions.admin &&\n         (user.permissions.admin.corpUsers ||\n          user.permissions.admin.techUsers ||\n          user.permissions.admin.formalUsers ||\n          user.permissions.admin.searchUsers ||\n          user.permissions.admin.superAdmin)) {\n        adminUsers.push(user);\n      }\n      if(user.permissions.general.corpUsers) {\n        corpUsers.push(user);\n      }\n      if(user.permissions.general.formalUsers) {\n        formalUsers.push(user);\n      }\n      if(user.permissions.general.search) {\n        searchUsers.push(user);\n      }\n      // this continued on for another 40 lines or so...\n    })\n  })\n}\n```\n\nNode.js has [performance tooling](https://nodejs.org/api/perf_hooks.html) built-in that allows you to gain insight around memory and CPU usage, which is what we used next:\n\n```javascript\nconst { PerformanceObserver, performance } = require('perf_hooks')\nconst o = new PerformanceObserver((items) => {\n  console.log(items.getEntries()[0]);\n  performance.clearMarks();\n})\no.observe({ entryTypes: ['measure']})\n```\n\n```javascript\n// to get the approx mem usage you can add this log line:\nconsole.log(`\n  The script uses ~\n  ${process.memoryUsage().heapUsed / 1024 / 1024}\n  MB\n`)\n```\n\n```shell\n# Output\nPerformanceEntry {\n  name: 'getUsers to res.status(200)',\n  entryType: 'measure',\n  startTime: 5486.524808,\n  duration: 6559.275542\n}\nThe script uses ~ 456.143798828125 MB\n```\n\nLooking at this code I couldn't help but wonder if there was a more efficient way to query and aggregate this information.\n\n## Fundamental #3: Identify the _Missing_ Fundamental\n\nReturning to the idea of the missing fundamental, as audio engineers must ask themselves \"what can I change about the frequencies in this mix in order to bring things into harmony?\" the relevant question for software engineers is very similar: \"what does this system need in order to bring harmony to its operation?\". In our case it was also helpful to consider that question in a historical context as \"what fundamental were the original developers missing when they built this?\"\n\nIn both cases, the answer for this application was **how to query things more efficiently**!\n\nThe `getUsers` method above was doing two things wrong; querying inefficiently for _all_ the users in the system and then allocating large arrays to partition the data based on permissions. Once we understood the missing fundamental we had a path forward to try and optimize this poorly performing code: we should see if we can query things more efficiently. This is what we came up with using `async/await` and the MongoDB [aggregation pipeline](https://docs.mongodb.com/manual/aggregation/):\n\n```javascript\ngetUsers: async function(req, res) {\n  const adminUsers = await User.aggregate([\n    {\n      $match: {\n        $or: [\n          { \"permissions.admin.corpUsers\" : { $eq: true }},\n          { \"permissions.admin.techUsers\" : { $eq: true }},\n          { \"permissions.admin.formalUsers\" : { $eq: true }},\n          { \"permissions.admin.searchUser\" : { $eq: true }},\n          { \"permissions.admin.superAdmin\" : { $eq: true }},\n        ]\n      }\n    }\n  ])\n\n  const corpUsers = await User.aggregate([\n    {\n      $match: {\n        \"permissions.general.corpUsers\" : { $eq: true }\n      }\n    }\n  ])\n\n  // ... etc...\n\n  res.status(200).json({\n    data: {\n      adminUsers,\n      corpUsers,\n      ...\n    }\n  })\n}\n```\n\nOnce we had re-written and tested the query to make sure the output was the same, we re-ran our performance profiling to see what the difference was.\n\n```shell\nPerformanceEntry {\n  name: 'getUsers to res.status(200)',\n  entryType: 'measure',\n  startTime: 496079.094306,\n  duration: 270.1256\n}\nThe script uses ~ 44.550048828125 MB\n```\n\nUsing the Aggregation pipeline had yielded an order of magnitude less memory and CPU usage! Here's a couple of screenshots from the Heroku dashboard for this app that show the before/after comparisons as well.\n\n### Before - request timeouts, and large amounts of memory consumption.\n\n![Before](/img/the-missing-fundamental/before-30s-timeouts-large-ram-usage.png)\n\n### After - no timeouts, memory consumption reduced by a factor of 10.\n\n![After](/img/the-missing-fundamental/after-2s-no-timeouts-50mb-ram-usage.png)\n\n# Conclusions\n\nIf you find yourself in a similar situation evaluating the performance of some legacy code I would encourage you to think about asking questions around what the missing fundamental(s) are. Walking through **investigate**, **profile**, **identify** (rinse. repeat.) has been useful for me, and I hope it is for you!\n\nIf you're interested in this type of work, you should reach out and [say hi](mailto:hi@testdouble.com); they're always looking to hire expert software engineers. :)"
}></{
  "path": "app/posts/2020-03-10-the-missing-fundamental.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The Missing Fundamental",
      "date": "2020-03-10"
    },
    "source": "\nMusic composition and production is a large part of my life outside of software development, so much so that I often find myself thinking of ways to draw parallels between the two. One such parallel that has stuck with me over the past 6 months or so is the concept of [the missing fundamental](https://en.wikipedia.org/wiki/Missing_fundamental).\n\n> A harmonic sound is said to have a **missing fundamental**, **suppressed fundamental**, or **phantom fundamental** when its overtones suggest a fundamental frequency but the sound lacks a component at the fundamental frequency itself.\n\nWhen I first learned about this concept, I couldn't help but think of how it applied to the work we do as software engineers. In the same way that skilled audio engineers can leverage the concept of the missing fundamental to improve the characteristics of sound, skilled software engineers can use a similar set of skills to improve the performance of applications.\n\n> This very concept of \"missing fundamental\" being reproduced based on the overtones in the tone has been used to create the illusion of bass in sound systems that are not capable of such bass. In mid-1999, Meir Shashoua of Tel Aviv, co-founder of Waves Audio, patented an algorithm to create the sense of the missing fundamental by synthesizing higher harmonics. Waves Audio released the MaxxBass plug-in to allow computer users to apply the synthesized harmonics to their audio files.\n\n# The Fundamentals of Software Performance\n\n[Ali](https://blog.testdouble.com/authors/ali-ibrahim/) and I were recently tasked with improving the performance of a legacy codebase that was deployed on Heroku using Node.js, MongoDB, and Angular 1. One of our first steps in evaluating the performance of code is to do an audit of dependencies and configuration; this is a great starting point because it can often lead to simple fixes for performance issues, like updating a database ORM adapter that can query things more efficiently.\n\nIn this case an audit of dependencies didn't yield much and we had to dive further into configuration on Heroku to really make sense of the performance challenge. Significant discovery number one was that the application was configured using Performance L [dynos](https://www.heroku.com/dynos) on Heroku (the most expensive _and_ highest tier available). This seemed strange since it did not appear commensurate with the surface area of the application; its purpose was to sync data using Heroku scheduler to pull from SalesForce into MongoDB.\n\nOne of our first steps was to reduce the dyno size and monitor logs to see if the Performance L size was warranted.\n\n## Fundamental #1: Investigate\n\nHeroku makes it pretty easy to peek at logs for your app, which is what we started with: `heroku logs --tail -a td-client-slow-app`. This yielded the following trace:\n\n```shell\napp[web.1]:\napp[web.1]: <--- Last few GCs --->\napp[web.1]:\napp[web.1]: <--- JS stacktrace --->\napp[web.1]:\napp[web.1]: ==== JS stack trace ==========\napp[web.1]:\napp[web.1]: 0: ExitFrame [pc: 0x1374fd9]\napp[web.1]: Security context: 0x01f9540008a1 <JSObject>\napp[web.1]: 1: getOwnPropertyNames [0x1f954001251](truncated...)\napp[web.1]: 2: getOwnPropertyDescriptors [0x3dffde9f7229]\n[/app/node_modules/mongoose/lib/helpers/document/compile.js:159]\napp[web.1]:\napp[web.1]: FATAL ERROR: Ineffective mark-compacts\napp[web.1]: near heap limit Allocation failed -\napp[web.1]: JavaScript heap out of memory\n```\n\n(Note: The [slug](https://devcenter.heroku.com/articles/slug-compiler) for this application was \\~74mb, which didn't seem overly large to warrant running out of memory on the lowest tier dyno Heroku provides. That dyno allocates up to 512mb of RAM, so we dug into the code path that led to the above stacktrace to gain some more information.)\n\n## Fundamental #2: Profile\n\nNode.js has some pretty decent profiling tools for engineers who want to dive into performance profiling. TD-resident DevOps pro [Micah](https://blog.testdouble.com/authors/micah-adams/) showed me that you can add some flags to the `node` process on startup to influence how V8 manages garbage collection. This is useful if you aren't getting consistency in your crashes and want to place constraints on the application runtime in order to suss out the source of the memory leak.\n\n`node --optimize_for_size --max_old_space_size=460 app.js`\n\nArtifically lowering the max heap size below what Heroku provisions for Standard dynos yielded the source of the leak was a method called `getUsers` which was responsible for querying a list of users and their permissions from MongoDB. Here's a sample of what that code looked like as we first found it:\n\n```javascript\ngetUsers: function(req, res) {\n  User.find({}, function(err, users) {\n    var allUsers = users;\n    var adminUsers = [];\n    var corpUsers = [];\n    var techUsers = [];\n    var formalUsers = [];\n    var searchUsers = [];\n    users.forEach(function(user) {\n      if(user.permissions.admin &&\n         (user.permissions.admin.corpUsers ||\n          user.permissions.admin.techUsers ||\n          user.permissions.admin.formalUsers ||\n          user.permissions.admin.searchUsers ||\n          user.permissions.admin.superAdmin)) {\n        adminUsers.push(user);\n      }\n      if(user.permissions.general.corpUsers) {\n        corpUsers.push(user);\n      }\n      if(user.permissions.general.formalUsers) {\n        formalUsers.push(user);\n      }\n      if(user.permissions.general.search) {\n        searchUsers.push(user);\n      }\n      // this continued on for another 40 lines or so...\n    })\n  })\n}\n```\n\nNode.js has [performance tooling](https://nodejs.org/api/perf_hooks.html) built-in that allows you to gain insight around memory and CPU usage, which is what we used next:\n\n```javascript\nconst { PerformanceObserver, performance } = require('perf_hooks')\nconst o = new PerformanceObserver((items) => {\n  console.log(items.getEntries()[0]);\n  performance.clearMarks();\n})\no.observe({ entryTypes: ['measure']})\n```\n\n```javascript\n// to get the approx mem usage you can add this log line:\nconsole.log(`\n  The script uses ~\n  ${process.memoryUsage().heapUsed / 1024 / 1024}\n  MB\n`)\n```\n\n```shell\n# Output\nPerformanceEntry {\n  name: 'getUsers to res.status(200)',\n  entryType: 'measure',\n  startTime: 5486.524808,\n  duration: 6559.275542\n}\nThe script uses ~ 456.143798828125 MB\n```\n\nLooking at this code I couldn't help but wonder if there was a more efficient way to query and aggregate this information.\n\n## Fundamental #3: Identify the _Missing_ Fundamental\n\nReturning to the idea of the missing fundamental, as audio engineers must ask themselves \"what can I change about the frequencies in this mix in order to bring things into harmony?\" the relevant question for software engineers is very similar: \"what does this system need in order to bring harmony to its operation?\". In our case it was also helpful to consider that question in a historical context as \"what fundamental were the original developers missing when they built this?\"\n\nIn both cases, the answer for this application was **how to query things more efficiently**!\n\nThe `getUsers` method above was doing two things wrong; querying inefficiently for _all_ the users in the system and then allocating large arrays to partition the data based on permissions. Once we understood the missing fundamental we had a path forward to try and optimize this poorly performing code: we should see if we can query things more efficiently. This is what we came up with using `async/await` and the MongoDB [aggregation pipeline](https://docs.mongodb.com/manual/aggregation/):\n\n```javascript\ngetUsers: async function(req, res) {\n  const adminUsers = await User.aggregate([\n    {\n      $match: {\n        $or: [\n          { \"permissions.admin.corpUsers\" : { $eq: true }},\n          { \"permissions.admin.techUsers\" : { $eq: true }},\n          { \"permissions.admin.formalUsers\" : { $eq: true }},\n          { \"permissions.admin.searchUser\" : { $eq: true }},\n          { \"permissions.admin.superAdmin\" : { $eq: true }},\n        ]\n      }\n    }\n  ])\n\n  const corpUsers = await User.aggregate([\n    {\n      $match: {\n        \"permissions.general.corpUsers\" : { $eq: true }\n      }\n    }\n  ])\n\n  // ... etc...\n\n  res.status(200).json({\n    data: {\n      adminUsers,\n      corpUsers,\n      ...\n    }\n  })\n}\n```\n\nOnce we had re-written and tested the query to make sure the output was the same, we re-ran our performance profiling to see what the difference was.\n\n```shell\nPerformanceEntry {\n  name: 'getUsers to res.status(200)',\n  entryType: 'measure',\n  startTime: 496079.094306,\n  duration: 270.1256\n}\nThe script uses ~ 44.550048828125 MB\n```\n\nUsing the Aggregation pipeline had yielded an order of magnitude less memory and CPU usage! Here's a couple of screenshots from the Heroku dashboard for this app that show the before/after comparisons as well.\n\n### Before - request timeouts, and large amounts of memory consumption.\n\n![Before](/img/the-missing-fundamental/before-30s-timeouts-large-ram-usage.png)\n\n### After - no timeouts, memory consumption reduced by a factor of 10.\n\n![After](/img/the-missing-fundamental/after-2s-no-timeouts-50mb-ram-usage.png)\n\n# Conclusions\n\nIf you find yourself in a similar situation evaluating the performance of some legacy code I would encourage you to think about asking questions around what the missing fundamental(s) are. Walking through **investigate**, **profile**, **identify** (rinse. repeat.) has been useful for me, and I hope it is for you!\n\nIf you're interested in this type of work, you should reach out and [say hi](mailto:hi@testdouble.com); they're always looking to hire expert software engineers. :)"
  },
  "attributes": {
    "title": "The Missing Fundamental",
    "date": "2020-03-10"
  },
  "markdown": "\nMusic composition and production is a large part of my life outside of software development, so much so that I often find myself thinking of ways to draw parallels between the two. One such parallel that has stuck with me over the past 6 months or so is the concept of [the missing fundamental](https://en.wikipedia.org/wiki/Missing_fundamental).\n\n> A harmonic sound is said to have a **missing fundamental**, **suppressed fundamental**, or **phantom fundamental** when its overtones suggest a fundamental frequency but the sound lacks a component at the fundamental frequency itself.\n\nWhen I first learned about this concept, I couldn't help but think of how it applied to the work we do as software engineers. In the same way that skilled audio engineers can leverage the concept of the missing fundamental to improve the characteristics of sound, skilled software engineers can use a similar set of skills to improve the performance of applications.\n\n> This very concept of \"missing fundamental\" being reproduced based on the overtones in the tone has been used to create the illusion of bass in sound systems that are not capable of such bass. In mid-1999, Meir Shashoua of Tel Aviv, co-founder of Waves Audio, patented an algorithm to create the sense of the missing fundamental by synthesizing higher harmonics. Waves Audio released the MaxxBass plug-in to allow computer users to apply the synthesized harmonics to their audio files.\n\n# The Fundamentals of Software Performance\n\n[Ali](https://blog.testdouble.com/authors/ali-ibrahim/) and I were recently tasked with improving the performance of a legacy codebase that was deployed on Heroku using Node.js, MongoDB, and Angular 1. One of our first steps in evaluating the performance of code is to do an audit of dependencies and configuration; this is a great starting point because it can often lead to simple fixes for performance issues, like updating a database ORM adapter that can query things more efficiently.\n\nIn this case an audit of dependencies didn't yield much and we had to dive further into configuration on Heroku to really make sense of the performance challenge. Significant discovery number one was that the application was configured using Performance L [dynos](https://www.heroku.com/dynos) on Heroku (the most expensive _and_ highest tier available). This seemed strange since it did not appear commensurate with the surface area of the application; its purpose was to sync data using Heroku scheduler to pull from SalesForce into MongoDB.\n\nOne of our first steps was to reduce the dyno size and monitor logs to see if the Performance L size was warranted.\n\n## Fundamental #1: Investigate\n\nHeroku makes it pretty easy to peek at logs for your app, which is what we started with: `heroku logs --tail -a td-client-slow-app`. This yielded the following trace:\n\n```shell\napp[web.1]:\napp[web.1]: <--- Last few GCs --->\napp[web.1]:\napp[web.1]: <--- JS stacktrace --->\napp[web.1]:\napp[web.1]: ==== JS stack trace ==========\napp[web.1]:\napp[web.1]: 0: ExitFrame [pc: 0x1374fd9]\napp[web.1]: Security context: 0x01f9540008a1 <JSObject>\napp[web.1]: 1: getOwnPropertyNames [0x1f954001251](truncated...)\napp[web.1]: 2: getOwnPropertyDescriptors [0x3dffde9f7229]\n[/app/node_modules/mongoose/lib/helpers/document/compile.js:159]\napp[web.1]:\napp[web.1]: FATAL ERROR: Ineffective mark-compacts\napp[web.1]: near heap limit Allocation failed -\napp[web.1]: JavaScript heap out of memory\n```\n\n(Note: The [slug](https://devcenter.heroku.com/articles/slug-compiler) for this application was \\~74mb, which didn't seem overly large to warrant running out of memory on the lowest tier dyno Heroku provides. That dyno allocates up to 512mb of RAM, so we dug into the code path that led to the above stacktrace to gain some more information.)\n\n## Fundamental #2: Profile\n\nNode.js has some pretty decent profiling tools for engineers who want to dive into performance profiling. TD-resident DevOps pro [Micah](https://blog.testdouble.com/authors/micah-adams/) showed me that you can add some flags to the `node` process on startup to influence how V8 manages garbage collection. This is useful if you aren't getting consistency in your crashes and want to place constraints on the application runtime in order to suss out the source of the memory leak.\n\n`node --optimize_for_size --max_old_space_size=460 app.js`\n\nArtifically lowering the max heap size below what Heroku provisions for Standard dynos yielded the source of the leak was a method called `getUsers` which was responsible for querying a list of users and their permissions from MongoDB. Here's a sample of what that code looked like as we first found it:\n\n```javascript\ngetUsers: function(req, res) {\n  User.find({}, function(err, users) {\n    var allUsers = users;\n    var adminUsers = [];\n    var corpUsers = [];\n    var techUsers = [];\n    var formalUsers = [];\n    var searchUsers = [];\n    users.forEach(function(user) {\n      if(user.permissions.admin &&\n         (user.permissions.admin.corpUsers ||\n          user.permissions.admin.techUsers ||\n          user.permissions.admin.formalUsers ||\n          user.permissions.admin.searchUsers ||\n          user.permissions.admin.superAdmin)) {\n        adminUsers.push(user);\n      }\n      if(user.permissions.general.corpUsers) {\n        corpUsers.push(user);\n      }\n      if(user.permissions.general.formalUsers) {\n        formalUsers.push(user);\n      }\n      if(user.permissions.general.search) {\n        searchUsers.push(user);\n      }\n      // this continued on for another 40 lines or so...\n    })\n  })\n}\n```\n\nNode.js has [performance tooling](https://nodejs.org/api/perf_hooks.html) built-in that allows you to gain insight around memory and CPU usage, which is what we used next:\n\n```javascript\nconst { PerformanceObserver, performance } = require('perf_hooks')\nconst o = new PerformanceObserver((items) => {\n  console.log(items.getEntries()[0]);\n  performance.clearMarks();\n})\no.observe({ entryTypes: ['measure']})\n```\n\n```javascript\n// to get the approx mem usage you can add this log line:\nconsole.log(`\n  The script uses ~\n  ${process.memoryUsage().heapUsed / 1024 / 1024}\n  MB\n`)\n```\n\n```shell\n# Output\nPerformanceEntry {\n  name: 'getUsers to res.status(200)',\n  entryType: 'measure',\n  startTime: 5486.524808,\n  duration: 6559.275542\n}\nThe script uses ~ 456.143798828125 MB\n```\n\nLooking at this code I couldn't help but wonder if there was a more efficient way to query and aggregate this information.\n\n## Fundamental #3: Identify the _Missing_ Fundamental\n\nReturning to the idea of the missing fundamental, as audio engineers must ask themselves \"what can I change about the frequencies in this mix in order to bring things into harmony?\" the relevant question for software engineers is very similar: \"what does this system need in order to bring harmony to its operation?\". In our case it was also helpful to consider that question in a historical context as \"what fundamental were the original developers missing when they built this?\"\n\nIn both cases, the answer for this application was **how to query things more efficiently**!\n\nThe `getUsers` method above was doing two things wrong; querying inefficiently for _all_ the users in the system and then allocating large arrays to partition the data based on permissions. Once we understood the missing fundamental we had a path forward to try and optimize this poorly performing code: we should see if we can query things more efficiently. This is what we came up with using `async/await` and the MongoDB [aggregation pipeline](https://docs.mongodb.com/manual/aggregation/):\n\n```javascript\ngetUsers: async function(req, res) {\n  const adminUsers = await User.aggregate([\n    {\n      $match: {\n        $or: [\n          { \"permissions.admin.corpUsers\" : { $eq: true }},\n          { \"permissions.admin.techUsers\" : { $eq: true }},\n          { \"permissions.admin.formalUsers\" : { $eq: true }},\n          { \"permissions.admin.searchUser\" : { $eq: true }},\n          { \"permissions.admin.superAdmin\" : { $eq: true }},\n        ]\n      }\n    }\n  ])\n\n  const corpUsers = await User.aggregate([\n    {\n      $match: {\n        \"permissions.general.corpUsers\" : { $eq: true }\n      }\n    }\n  ])\n\n  // ... etc...\n\n  res.status(200).json({\n    data: {\n      adminUsers,\n      corpUsers,\n      ...\n    }\n  })\n}\n```\n\nOnce we had re-written and tested the query to make sure the output was the same, we re-ran our performance profiling to see what the difference was.\n\n```shell\nPerformanceEntry {\n  name: 'getUsers to res.status(200)',\n  entryType: 'measure',\n  startTime: 496079.094306,\n  duration: 270.1256\n}\nThe script uses ~ 44.550048828125 MB\n```\n\nUsing the Aggregation pipeline had yielded an order of magnitude less memory and CPU usage! Here's a couple of screenshots from the Heroku dashboard for this app that show the before/after comparisons as well.\n\n### Before - request timeouts, and large amounts of memory consumption.\n\n![Before](/img/the-missing-fundamental/before-30s-timeouts-large-ram-usage.png)\n\n### After - no timeouts, memory consumption reduced by a factor of 10.\n\n![After](/img/the-missing-fundamental/after-2s-no-timeouts-50mb-ram-usage.png)\n\n# Conclusions\n\nIf you find yourself in a similar situation evaluating the performance of some legacy code I would encourage you to think about asking questions around what the missing fundamental(s) are. Walking through **investigate**, **profile**, **identify** (rinse. repeat.) has been useful for me, and I hope it is for you!\n\nIf you're interested in this type of work, you should reach out and [say hi](mailto:hi@testdouble.com); they're always looking to hire expert software engineers. :)"
}></pre></div><div><a href="/posts/2019-08-27-css-the-visual-state-machine.html">CSS is a visual state machine</a><pre><{
  "path": "app/posts/2019-08-27-css-the-visual-state-machine.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "CSS is a visual state machine",
      "date": "2019-08-27"
    },
    "source": "\n> Thinking of web applications in terms of [state machines](https://en.wikipedia.org/wiki/Finite-state_machine) is [not a new idea](https://www.techrepublic.com/article/set-up-web-applications-as-finite-state-machines/); in fact, it has become so popular in the past few years that teams are spending increasingly more time breaking down their application into states managed by front-end frameworks.\n\n<iframe src=\"https://www.youtube.com/embed/xpnmtkjCNng?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nWhether you use [Redux](https://redux.js.org/), [MobX](https://mobx.js.org), or even perhaps something framework-agnostic like [xState](https://xstate.js.org), it is clear that thinking about web applications in terms of state machines is occurring much more frequently. With all this focus on state, transitions, and the benefits that come with structuring our applications like this, I've found there is still an area that is often overlooked when it comes to managing state in web applications: **the visual or presentation layer**.\n\nCSS is incredibly powerful yet frequently misunderstood by most developers, which often leads to derision of the language. I think this is mostly due to a fundamental error in the way web developers manage presentation, often focusing their efforts on conditional logic in templates instead of a more flexible application of state-specific CSS selectors to HTML elements.\n\n## A Simple Example\n\nLet us examine a simple example of a multi-selectable list for a user interface (UI) that a designer may have provided in mockup form for us as web developers to decompose into working code.\n\n![An animation of a multi-selectable list of users in tabular form. Each row has an icon which changes to indicate the selection state, defaulting to a snowman, empty checkbox on hover, and finally checked checkbox when selected.](/img/css-the-visual-state-machine/css-mockup.gif)\n\nWe can see there are a number of interactions at play, and at first glance these might seem simple enough that we would be tempted to solve the problem without putting much upfront thought into it. However, I think despite the simplicity of the example, there are enough complex states to enumerate that we should spend some time thinking about them before we dive into creating this UI.\n\n| State                            | Trigger             | Change                                                                                                 |\n| -------------------------------- | ------------------- | ------------------------------------------------------------------------------------------------------ |\n| _Selected_                       | Click               | Icon changes to a checkbox                                                                             |\n| _Unselected_                     | Click               | Icon changes to an empty box                                                                           |\n| _Hovering, No Selections_        | Hover               | The snowman icon for the hovered row changes to an empty checkbox to indicate potential for selection  |\n| _Hovering, 1 or More Selections_ | Hover               | All unselected row icons remain as empty checkboxes, and a yellow highlight appears on the hovered row |\n| _1 or more Selections Active_    | No User Interaction | All icons change to empty checkboxes to indicate the ability to select multiple rows                   |\n\nPutting aside [interaction design](https://en.wikipedia.org/wiki/Interaction_design) (IxD) and [accessibility](https://en.wikipedia.org/wiki/Web_accessibility) (a11y) concerns for the time being, after enumerating the states that we see here there is a lot to consider when building this UI! How should we manage the states? Should the logic live in our template or in our stylesheets? Let's take a brief look at the first approach, using an implementation in [Svelte](https://svelte.dev).\n\nSvelte is a compiler that takes as input one or more `.svelte` files with _regions_ of functionality based on JavaScript, HTML, and CSS; with that input it produces the minimal amount of DOM API output in JavaScript to achieve the desired result. It's a different take than something like React, Angular, or Ember, which ship substantial runtimes to the browser that execute application code. If you are interested in learning more I highly recommend watching this excellent talk called _[Rethinking Reactivity](https://www.youtube.com/watch?v=AdNJ3fydeao)_ from Rich Harris introducing some of the core ideas. The code in the following examples is intended to be simple enough that you should be able to port the ideas represented to any other framework with minimal effort.\n\n## Implementation: Templates\n\nOne of the first places a web developer might start is by crafting the template that represents the UI mockup we received from our designer friend above. This seems like a logical place to start, given we need some way to represent the data in a web browser. Let's build a template using svelte-infused HTML and see how it looks.\n\n``` html\n<table>\n  {#each users as user}\n  <tr>\n    <td class=\"icon\">\n      {#if user.selected && hasSelection}\n        {checkedBox}\n      {:else if !user.selected && hasSelection}\n        {uncheckedBox}\n      {:else}\n        {snowman}\n      {/if}\n    </td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\nAside from the svelte-specific things like the `{#each}` and `{#if}` blocks, this is probably close to what you might implement in any front-end or server-side templating solution. We've taken the list of potential states that we extracted from the mockup above and encoded them as conditional logic in our templates in order to achieve the desired result. The one special case we needed to account for was the non-interactive state \"1 or more Selections Active\"; to do this we defined a local variable in our JavaScript region called `hasSelection` which is defined using Sveltes [reactive declarations](https://svelte.dev/tutorial/reactive-declarations) as `$: hasSelection = users.some(u => u.selected)`.\n\nAlthough the code above satisfies _most_ of the user experience (UX) as detailed in the mockup, there are two problems that shake out of an implementation like this that focuses on conditional logic in templates:\n\n1. We didn't capture _all_ of the states enumerated, as we cannot effectively translate a user's `hover` action in templates alone unless we get really creative and complex\n2. This paradigm scales _very poorly_ as our templates grow, mixing concerns of `presentation` and `data` in a template, resulting in code that is much harder to read and maintain over the life of a project\n\nThe scalability concern is the more worrisome of the two, yet is a common byproduct of developers using conditional logic in templates. Increasingly thorny conditionals can lead to missed acceptance criteria, which in turn can lead to stress and tension on a team. Rather than throw blame around, it's worth focusing on whether that approach is healthy for a long-term project.\n\nI think we can do better if we shift our focus from conditional logic in templates to thinking more in terms of leveraging CSS as the language we use to define the states in our presentational state machine and using JavaScript to manage when to apply those states. Let's see what that looks like as we refactor the above example.\n\n## Implementation: Stylesheets\n\nOne of the first considerations we'll need to make is how to address both the concerns raised in the previous section. We need to handle the `hover` state properly, and we also should strive for a solution that encodes data in the template and presentation in the stylesheets. Let's start by refactoring the template to eliminate the conditional logic:\n\n``` html\n<table class:hasSelection=\"{hasSelection}\" class=\"selectable\">\n  {#each users as user}\n  <tr class:selected=\"{user.selected}\">\n    <td class=\"icon\"></td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\nThe first thing you might notice is that we removed the conditional blocks replaced them with [svelte's class element directive](https://svelte.dev/docs#class_name). This is an elegant way to control toggling of a CSS class on an element via a boolean value, which we previously defined as `{user.selected}` and `{hasSelection}`. We also added a `class=selectable` to the root table element in order to allow us to better manage the complexity of the conditional logic for states in CSS. Let's defer looking at the JavaScript that defines those values and instead look at what the definition of each state in our presentational state machine looks like when we encode it with CSS:\n\n``` css\n/*\n  CSS variables in conjunction with escaped unicode or html\n  entities are a great way to represent things like icons\n*/\n:root {\n  --unchecked-box: \"\\02610\";\n  --checked-box: \"\\02611\";\n  --snowman: \"\\02603\";\n}\n\n/*\n  Managing the hover states to show a yellow background\n*/\ntr:hover,\ntr:hover td {\n  cursor: pointer;\n  background-color: yellow;\n}\n\n/*\n  Our first state, every icon should default to the snowman\n*/\n.icon:after {\n  content: var(--snowman);\n}\n\n/*\n  A complex state, if the table has a selection,\n  then every selected items icon should be the checked box\n*/\n.selectable.hasSelection .selected .icon:after {\n  content: var(--checked-box);\n}\n\n/*\n  A combined selector to handle the alternative complex states:\n  - for a table without a selection, when the user hovers, show the unchecked box\n  - for a table with selections, swap the icon from the snowman to the unchecked box\n*/\n.selectable:not(.hasSelection) tr:hover .icon:after,\n.selectable.hasSelection .icon:after {\n  content: var(--unchecked-box);\n}\n```\n\nWith the combination of CSS and svelte-infused HTML we've achieved the result our designer was hoping for when they handed us the initial mockup, with an appropriate separation between the definition of our states (CSS) and the application of those states (HTML, and JavaScript).\n\nFor completeness, here is the entirety of the example as included in `Application.svelte` from the [code on github](https://github.com/davemo/svelte-casts):\n\n``` html\n<script>\n  let users = [\n    {name: 'Danika Dywtgowm', email: 'danika.dywtgowm@email.com'},\n    {name: 'Erica Bule', email: 'erica.bule@email.com'},\n    {name: 'Jim Snales', email: 'jim.snales@email.com'},\n    {name: 'Daria Thorobox', email: 'daria.thorobox@email.com'},\n    {name: 'Mendikant Hargrove', email: 'mendikant.hargrove@email.com'},\n    {name: 'Ephraim Lischok', email: 'ephraim.lischok@email.com'},\n    {name: 'Lera Nedialkova', email: 'lera.nedialkova@email.com'},\n  ]\n\n  function selectUser(user) {\n    users[users.findIndex(u => u.name === user.name)] = {\n      ...user,\n      selected: !user.selected\n    }\n    console.log(`${user.name} was ${user.selected ? 'de-selected' : 'selected'}`);\n  }\n\n  $: hasSelection = users.some(u => u.selected)\n</script>\n\n<style>\n  :root {\n    --unchecked-box: '\\02610';\n    --checked-box: '\\02611';\n    --snowman: '\\02603';\n  }\n\n  td {\n    padding: 5px;\n  }\n\n  tr:hover, tr:hover td {\n    cursor: pointer;\n    background-color: yellow;\n  }\n\n  .icon, .template-icon {\n    display: flex;\n    justify-content: center;\n  }\n\n  .icon:after {\n    content: var(--snowman);\n  }\n\n  .selectable.hasSelection .selected .icon:after {\n    content: var(--checked-box);\n  }\n\n  .selectable:not(.hasSelection) tr:hover .icon:after,\n  .selectable.hasSelection .icon:after {\n    content: var(--unchecked-box);\n  }\n</style>\n\n<h1>Complex Multi-Select</h1>\n\n<table cellspacing=0 class:hasSelection={hasSelection} class=selectable>\n  {#each users as user}\n  <tr class:selected={user.selected} on:click={() => selectUser(user)}>\n    <td class=icon height=20 width=20></td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\n# Closing Thoughts\n\nThis is how I have tended to manage the working relationship between HTML and CSS for the last 20 years, and I think the power of thinking in this way leads to cleaner code and easier to refactor web interfaces.\n\nIf this looks completely foreign to you and you found yourself considering that the template-based conditional-logic approach made more sense, I'd recommend learning more about the capabilities of CSS features like [pseudo-selectors :not](https://developer.mozilla.org/en-US/docs/Web/CSS/var), [variables](https://developer.mozilla.org/en-US/docs/Web/CSS/var), and the [generated content: property](https://developer.mozilla.org/en-US/docs/Web/CSS/content).\n\nI've found that teams who up their level of knowledge in CSS and tend to try to split concerns like we've done here will have web applications that are easier to change over the long term.\n\nIf you are interested in learning more about this approach and seeing a live coded version of this blog post, please check out the [screencast](https://www.youtube.com/watch?v=xpnmtkjCNng) posted to my YouTube channel; it walks through all the examples and touches on a few more svelte-specific things to consider.\n\n# Learning Resources\n\n- [Svelte Tutorial](https://svelte.dev/tutorial/basics)\n- [Complex-Multi-Select Code on Github](https://github.com/davemo/svelte-casts)\n- [CSS Variables](https://developer.mozilla.org/en-US/docs/Web/CSS/var)\n- [CSS :not pseudo-selector](https://developer.mozilla.org/en-US/docs/Web/CSS/:not)\n- [CSS Generated Content](https://developer.mozilla.org/en-US/docs/Web/CSS/content)\n- [HTML Entity Symbols](https://www.toptal.com/designers/htmlarrows/symbols/)"
  },
  "attributes": {
    "title": "CSS is a visual state machine",
    "date": "2019-08-27"
  },
  "markdown": "\n> Thinking of web applications in terms of [state machines](https://en.wikipedia.org/wiki/Finite-state_machine) is [not a new idea](https://www.techrepublic.com/article/set-up-web-applications-as-finite-state-machines/); in fact, it has become so popular in the past few years that teams are spending increasingly more time breaking down their application into states managed by front-end frameworks.\n\n<iframe src=\"https://www.youtube.com/embed/xpnmtkjCNng?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nWhether you use [Redux](https://redux.js.org/), [MobX](https://mobx.js.org), or even perhaps something framework-agnostic like [xState](https://xstate.js.org), it is clear that thinking about web applications in terms of state machines is occurring much more frequently. With all this focus on state, transitions, and the benefits that come with structuring our applications like this, I've found there is still an area that is often overlooked when it comes to managing state in web applications: **the visual or presentation layer**.\n\nCSS is incredibly powerful yet frequently misunderstood by most developers, which often leads to derision of the language. I think this is mostly due to a fundamental error in the way web developers manage presentation, often focusing their efforts on conditional logic in templates instead of a more flexible application of state-specific CSS selectors to HTML elements.\n\n## A Simple Example\n\nLet us examine a simple example of a multi-selectable list for a user interface (UI) that a designer may have provided in mockup form for us as web developers to decompose into working code.\n\n![An animation of a multi-selectable list of users in tabular form. Each row has an icon which changes to indicate the selection state, defaulting to a snowman, empty checkbox on hover, and finally checked checkbox when selected.](/img/css-the-visual-state-machine/css-mockup.gif)\n\nWe can see there are a number of interactions at play, and at first glance these might seem simple enough that we would be tempted to solve the problem without putting much upfront thought into it. However, I think despite the simplicity of the example, there are enough complex states to enumerate that we should spend some time thinking about them before we dive into creating this UI.\n\n| State                            | Trigger             | Change                                                                                                 |\n| -------------------------------- | ------------------- | ------------------------------------------------------------------------------------------------------ |\n| _Selected_                       | Click               | Icon changes to a checkbox                                                                             |\n| _Unselected_                     | Click               | Icon changes to an empty box                                                                           |\n| _Hovering, No Selections_        | Hover               | The snowman icon for the hovered row changes to an empty checkbox to indicate potential for selection  |\n| _Hovering, 1 or More Selections_ | Hover               | All unselected row icons remain as empty checkboxes, and a yellow highlight appears on the hovered row |\n| _1 or more Selections Active_    | No User Interaction | All icons change to empty checkboxes to indicate the ability to select multiple rows                   |\n\nPutting aside [interaction design](https://en.wikipedia.org/wiki/Interaction_design) (IxD) and [accessibility](https://en.wikipedia.org/wiki/Web_accessibility) (a11y) concerns for the time being, after enumerating the states that we see here there is a lot to consider when building this UI! How should we manage the states? Should the logic live in our template or in our stylesheets? Let's take a brief look at the first approach, using an implementation in [Svelte](https://svelte.dev).\n\nSvelte is a compiler that takes as input one or more `.svelte` files with _regions_ of functionality based on JavaScript, HTML, and CSS; with that input it produces the minimal amount of DOM API output in JavaScript to achieve the desired result. It's a different take than something like React, Angular, or Ember, which ship substantial runtimes to the browser that execute application code. If you are interested in learning more I highly recommend watching this excellent talk called _[Rethinking Reactivity](https://www.youtube.com/watch?v=AdNJ3fydeao)_ from Rich Harris introducing some of the core ideas. The code in the following examples is intended to be simple enough that you should be able to port the ideas represented to any other framework with minimal effort.\n\n## Implementation: Templates\n\nOne of the first places a web developer might start is by crafting the template that represents the UI mockup we received from our designer friend above. This seems like a logical place to start, given we need some way to represent the data in a web browser. Let's build a template using svelte-infused HTML and see how it looks.\n\n``` html\n<table>\n  {#each users as user}\n  <tr>\n    <td class=\"icon\">\n      {#if user.selected && hasSelection}\n        {checkedBox}\n      {:else if !user.selected && hasSelection}\n        {uncheckedBox}\n      {:else}\n        {snowman}\n      {/if}\n    </td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\nAside from the svelte-specific things like the `{#each}` and `{#if}` blocks, this is probably close to what you might implement in any front-end or server-side templating solution. We've taken the list of potential states that we extracted from the mockup above and encoded them as conditional logic in our templates in order to achieve the desired result. The one special case we needed to account for was the non-interactive state \"1 or more Selections Active\"; to do this we defined a local variable in our JavaScript region called `hasSelection` which is defined using Sveltes [reactive declarations](https://svelte.dev/tutorial/reactive-declarations) as `$: hasSelection = users.some(u => u.selected)`.\n\nAlthough the code above satisfies _most_ of the user experience (UX) as detailed in the mockup, there are two problems that shake out of an implementation like this that focuses on conditional logic in templates:\n\n1. We didn't capture _all_ of the states enumerated, as we cannot effectively translate a user's `hover` action in templates alone unless we get really creative and complex\n2. This paradigm scales _very poorly_ as our templates grow, mixing concerns of `presentation` and `data` in a template, resulting in code that is much harder to read and maintain over the life of a project\n\nThe scalability concern is the more worrisome of the two, yet is a common byproduct of developers using conditional logic in templates. Increasingly thorny conditionals can lead to missed acceptance criteria, which in turn can lead to stress and tension on a team. Rather than throw blame around, it's worth focusing on whether that approach is healthy for a long-term project.\n\nI think we can do better if we shift our focus from conditional logic in templates to thinking more in terms of leveraging CSS as the language we use to define the states in our presentational state machine and using JavaScript to manage when to apply those states. Let's see what that looks like as we refactor the above example.\n\n## Implementation: Stylesheets\n\nOne of the first considerations we'll need to make is how to address both the concerns raised in the previous section. We need to handle the `hover` state properly, and we also should strive for a solution that encodes data in the template and presentation in the stylesheets. Let's start by refactoring the template to eliminate the conditional logic:\n\n``` html\n<table class:hasSelection=\"{hasSelection}\" class=\"selectable\">\n  {#each users as user}\n  <tr class:selected=\"{user.selected}\">\n    <td class=\"icon\"></td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\nThe first thing you might notice is that we removed the conditional blocks replaced them with [svelte's class element directive](https://svelte.dev/docs#class_name). This is an elegant way to control toggling of a CSS class on an element via a boolean value, which we previously defined as `{user.selected}` and `{hasSelection}`. We also added a `class=selectable` to the root table element in order to allow us to better manage the complexity of the conditional logic for states in CSS. Let's defer looking at the JavaScript that defines those values and instead look at what the definition of each state in our presentational state machine looks like when we encode it with CSS:\n\n``` css\n/*\n  CSS variables in conjunction with escaped unicode or html\n  entities are a great way to represent things like icons\n*/\n:root {\n  --unchecked-box: \"\\02610\";\n  --checked-box: \"\\02611\";\n  --snowman: \"\\02603\";\n}\n\n/*\n  Managing the hover states to show a yellow background\n*/\ntr:hover,\ntr:hover td {\n  cursor: pointer;\n  background-color: yellow;\n}\n\n/*\n  Our first state, every icon should default to the snowman\n*/\n.icon:after {\n  content: var(--snowman);\n}\n\n/*\n  A complex state, if the table has a selection,\n  then every selected items icon should be the checked box\n*/\n.selectable.hasSelection .selected .icon:after {\n  content: var(--checked-box);\n}\n\n/*\n  A combined selector to handle the alternative complex states:\n  - for a table without a selection, when the user hovers, show the unchecked box\n  - for a table with selections, swap the icon from the snowman to the unchecked box\n*/\n.selectable:not(.hasSelection) tr:hover .icon:after,\n.selectable.hasSelection .icon:after {\n  content: var(--unchecked-box);\n}\n```\n\nWith the combination of CSS and svelte-infused HTML we've achieved the result our designer was hoping for when they handed us the initial mockup, with an appropriate separation between the definition of our states (CSS) and the application of those states (HTML, and JavaScript).\n\nFor completeness, here is the entirety of the example as included in `Application.svelte` from the [code on github](https://github.com/davemo/svelte-casts):\n\n``` html\n<script>\n  let users = [\n    {name: 'Danika Dywtgowm', email: 'danika.dywtgowm@email.com'},\n    {name: 'Erica Bule', email: 'erica.bule@email.com'},\n    {name: 'Jim Snales', email: 'jim.snales@email.com'},\n    {name: 'Daria Thorobox', email: 'daria.thorobox@email.com'},\n    {name: 'Mendikant Hargrove', email: 'mendikant.hargrove@email.com'},\n    {name: 'Ephraim Lischok', email: 'ephraim.lischok@email.com'},\n    {name: 'Lera Nedialkova', email: 'lera.nedialkova@email.com'},\n  ]\n\n  function selectUser(user) {\n    users[users.findIndex(u => u.name === user.name)] = {\n      ...user,\n      selected: !user.selected\n    }\n    console.log(`${user.name} was ${user.selected ? 'de-selected' : 'selected'}`);\n  }\n\n  $: hasSelection = users.some(u => u.selected)\n</script>\n\n<style>\n  :root {\n    --unchecked-box: '\\02610';\n    --checked-box: '\\02611';\n    --snowman: '\\02603';\n  }\n\n  td {\n    padding: 5px;\n  }\n\n  tr:hover, tr:hover td {\n    cursor: pointer;\n    background-color: yellow;\n  }\n\n  .icon, .template-icon {\n    display: flex;\n    justify-content: center;\n  }\n\n  .icon:after {\n    content: var(--snowman);\n  }\n\n  .selectable.hasSelection .selected .icon:after {\n    content: var(--checked-box);\n  }\n\n  .selectable:not(.hasSelection) tr:hover .icon:after,\n  .selectable.hasSelection .icon:after {\n    content: var(--unchecked-box);\n  }\n</style>\n\n<h1>Complex Multi-Select</h1>\n\n<table cellspacing=0 class:hasSelection={hasSelection} class=selectable>\n  {#each users as user}\n  <tr class:selected={user.selected} on:click={() => selectUser(user)}>\n    <td class=icon height=20 width=20></td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\n# Closing Thoughts\n\nThis is how I have tended to manage the working relationship between HTML and CSS for the last 20 years, and I think the power of thinking in this way leads to cleaner code and easier to refactor web interfaces.\n\nIf this looks completely foreign to you and you found yourself considering that the template-based conditional-logic approach made more sense, I'd recommend learning more about the capabilities of CSS features like [pseudo-selectors :not](https://developer.mozilla.org/en-US/docs/Web/CSS/var), [variables](https://developer.mozilla.org/en-US/docs/Web/CSS/var), and the [generated content: property](https://developer.mozilla.org/en-US/docs/Web/CSS/content).\n\nI've found that teams who up their level of knowledge in CSS and tend to try to split concerns like we've done here will have web applications that are easier to change over the long term.\n\nIf you are interested in learning more about this approach and seeing a live coded version of this blog post, please check out the [screencast](https://www.youtube.com/watch?v=xpnmtkjCNng) posted to my YouTube channel; it walks through all the examples and touches on a few more svelte-specific things to consider.\n\n# Learning Resources\n\n- [Svelte Tutorial](https://svelte.dev/tutorial/basics)\n- [Complex-Multi-Select Code on Github](https://github.com/davemo/svelte-casts)\n- [CSS Variables](https://developer.mozilla.org/en-US/docs/Web/CSS/var)\n- [CSS :not pseudo-selector](https://developer.mozilla.org/en-US/docs/Web/CSS/:not)\n- [CSS Generated Content](https://developer.mozilla.org/en-US/docs/Web/CSS/content)\n- [HTML Entity Symbols](https://www.toptal.com/designers/htmlarrows/symbols/)"
}></{
  "path": "app/posts/2019-08-27-css-the-visual-state-machine.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "CSS is a visual state machine",
      "date": "2019-08-27"
    },
    "source": "\n> Thinking of web applications in terms of [state machines](https://en.wikipedia.org/wiki/Finite-state_machine) is [not a new idea](https://www.techrepublic.com/article/set-up-web-applications-as-finite-state-machines/); in fact, it has become so popular in the past few years that teams are spending increasingly more time breaking down their application into states managed by front-end frameworks.\n\n<iframe src=\"https://www.youtube.com/embed/xpnmtkjCNng?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nWhether you use [Redux](https://redux.js.org/), [MobX](https://mobx.js.org), or even perhaps something framework-agnostic like [xState](https://xstate.js.org), it is clear that thinking about web applications in terms of state machines is occurring much more frequently. With all this focus on state, transitions, and the benefits that come with structuring our applications like this, I've found there is still an area that is often overlooked when it comes to managing state in web applications: **the visual or presentation layer**.\n\nCSS is incredibly powerful yet frequently misunderstood by most developers, which often leads to derision of the language. I think this is mostly due to a fundamental error in the way web developers manage presentation, often focusing their efforts on conditional logic in templates instead of a more flexible application of state-specific CSS selectors to HTML elements.\n\n## A Simple Example\n\nLet us examine a simple example of a multi-selectable list for a user interface (UI) that a designer may have provided in mockup form for us as web developers to decompose into working code.\n\n![An animation of a multi-selectable list of users in tabular form. Each row has an icon which changes to indicate the selection state, defaulting to a snowman, empty checkbox on hover, and finally checked checkbox when selected.](/img/css-the-visual-state-machine/css-mockup.gif)\n\nWe can see there are a number of interactions at play, and at first glance these might seem simple enough that we would be tempted to solve the problem without putting much upfront thought into it. However, I think despite the simplicity of the example, there are enough complex states to enumerate that we should spend some time thinking about them before we dive into creating this UI.\n\n| State                            | Trigger             | Change                                                                                                 |\n| -------------------------------- | ------------------- | ------------------------------------------------------------------------------------------------------ |\n| _Selected_                       | Click               | Icon changes to a checkbox                                                                             |\n| _Unselected_                     | Click               | Icon changes to an empty box                                                                           |\n| _Hovering, No Selections_        | Hover               | The snowman icon for the hovered row changes to an empty checkbox to indicate potential for selection  |\n| _Hovering, 1 or More Selections_ | Hover               | All unselected row icons remain as empty checkboxes, and a yellow highlight appears on the hovered row |\n| _1 or more Selections Active_    | No User Interaction | All icons change to empty checkboxes to indicate the ability to select multiple rows                   |\n\nPutting aside [interaction design](https://en.wikipedia.org/wiki/Interaction_design) (IxD) and [accessibility](https://en.wikipedia.org/wiki/Web_accessibility) (a11y) concerns for the time being, after enumerating the states that we see here there is a lot to consider when building this UI! How should we manage the states? Should the logic live in our template or in our stylesheets? Let's take a brief look at the first approach, using an implementation in [Svelte](https://svelte.dev).\n\nSvelte is a compiler that takes as input one or more `.svelte` files with _regions_ of functionality based on JavaScript, HTML, and CSS; with that input it produces the minimal amount of DOM API output in JavaScript to achieve the desired result. It's a different take than something like React, Angular, or Ember, which ship substantial runtimes to the browser that execute application code. If you are interested in learning more I highly recommend watching this excellent talk called _[Rethinking Reactivity](https://www.youtube.com/watch?v=AdNJ3fydeao)_ from Rich Harris introducing some of the core ideas. The code in the following examples is intended to be simple enough that you should be able to port the ideas represented to any other framework with minimal effort.\n\n## Implementation: Templates\n\nOne of the first places a web developer might start is by crafting the template that represents the UI mockup we received from our designer friend above. This seems like a logical place to start, given we need some way to represent the data in a web browser. Let's build a template using svelte-infused HTML and see how it looks.\n\n``` html\n<table>\n  {#each users as user}\n  <tr>\n    <td class=\"icon\">\n      {#if user.selected && hasSelection}\n        {checkedBox}\n      {:else if !user.selected && hasSelection}\n        {uncheckedBox}\n      {:else}\n        {snowman}\n      {/if}\n    </td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\nAside from the svelte-specific things like the `{#each}` and `{#if}` blocks, this is probably close to what you might implement in any front-end or server-side templating solution. We've taken the list of potential states that we extracted from the mockup above and encoded them as conditional logic in our templates in order to achieve the desired result. The one special case we needed to account for was the non-interactive state \"1 or more Selections Active\"; to do this we defined a local variable in our JavaScript region called `hasSelection` which is defined using Sveltes [reactive declarations](https://svelte.dev/tutorial/reactive-declarations) as `$: hasSelection = users.some(u => u.selected)`.\n\nAlthough the code above satisfies _most_ of the user experience (UX) as detailed in the mockup, there are two problems that shake out of an implementation like this that focuses on conditional logic in templates:\n\n1. We didn't capture _all_ of the states enumerated, as we cannot effectively translate a user's `hover` action in templates alone unless we get really creative and complex\n2. This paradigm scales _very poorly_ as our templates grow, mixing concerns of `presentation` and `data` in a template, resulting in code that is much harder to read and maintain over the life of a project\n\nThe scalability concern is the more worrisome of the two, yet is a common byproduct of developers using conditional logic in templates. Increasingly thorny conditionals can lead to missed acceptance criteria, which in turn can lead to stress and tension on a team. Rather than throw blame around, it's worth focusing on whether that approach is healthy for a long-term project.\n\nI think we can do better if we shift our focus from conditional logic in templates to thinking more in terms of leveraging CSS as the language we use to define the states in our presentational state machine and using JavaScript to manage when to apply those states. Let's see what that looks like as we refactor the above example.\n\n## Implementation: Stylesheets\n\nOne of the first considerations we'll need to make is how to address both the concerns raised in the previous section. We need to handle the `hover` state properly, and we also should strive for a solution that encodes data in the template and presentation in the stylesheets. Let's start by refactoring the template to eliminate the conditional logic:\n\n``` html\n<table class:hasSelection=\"{hasSelection}\" class=\"selectable\">\n  {#each users as user}\n  <tr class:selected=\"{user.selected}\">\n    <td class=\"icon\"></td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\nThe first thing you might notice is that we removed the conditional blocks replaced them with [svelte's class element directive](https://svelte.dev/docs#class_name). This is an elegant way to control toggling of a CSS class on an element via a boolean value, which we previously defined as `{user.selected}` and `{hasSelection}`. We also added a `class=selectable` to the root table element in order to allow us to better manage the complexity of the conditional logic for states in CSS. Let's defer looking at the JavaScript that defines those values and instead look at what the definition of each state in our presentational state machine looks like when we encode it with CSS:\n\n``` css\n/*\n  CSS variables in conjunction with escaped unicode or html\n  entities are a great way to represent things like icons\n*/\n:root {\n  --unchecked-box: \"\\02610\";\n  --checked-box: \"\\02611\";\n  --snowman: \"\\02603\";\n}\n\n/*\n  Managing the hover states to show a yellow background\n*/\ntr:hover,\ntr:hover td {\n  cursor: pointer;\n  background-color: yellow;\n}\n\n/*\n  Our first state, every icon should default to the snowman\n*/\n.icon:after {\n  content: var(--snowman);\n}\n\n/*\n  A complex state, if the table has a selection,\n  then every selected items icon should be the checked box\n*/\n.selectable.hasSelection .selected .icon:after {\n  content: var(--checked-box);\n}\n\n/*\n  A combined selector to handle the alternative complex states:\n  - for a table without a selection, when the user hovers, show the unchecked box\n  - for a table with selections, swap the icon from the snowman to the unchecked box\n*/\n.selectable:not(.hasSelection) tr:hover .icon:after,\n.selectable.hasSelection .icon:after {\n  content: var(--unchecked-box);\n}\n```\n\nWith the combination of CSS and svelte-infused HTML we've achieved the result our designer was hoping for when they handed us the initial mockup, with an appropriate separation between the definition of our states (CSS) and the application of those states (HTML, and JavaScript).\n\nFor completeness, here is the entirety of the example as included in `Application.svelte` from the [code on github](https://github.com/davemo/svelte-casts):\n\n``` html\n<script>\n  let users = [\n    {name: 'Danika Dywtgowm', email: 'danika.dywtgowm@email.com'},\n    {name: 'Erica Bule', email: 'erica.bule@email.com'},\n    {name: 'Jim Snales', email: 'jim.snales@email.com'},\n    {name: 'Daria Thorobox', email: 'daria.thorobox@email.com'},\n    {name: 'Mendikant Hargrove', email: 'mendikant.hargrove@email.com'},\n    {name: 'Ephraim Lischok', email: 'ephraim.lischok@email.com'},\n    {name: 'Lera Nedialkova', email: 'lera.nedialkova@email.com'},\n  ]\n\n  function selectUser(user) {\n    users[users.findIndex(u => u.name === user.name)] = {\n      ...user,\n      selected: !user.selected\n    }\n    console.log(`${user.name} was ${user.selected ? 'de-selected' : 'selected'}`);\n  }\n\n  $: hasSelection = users.some(u => u.selected)\n</script>\n\n<style>\n  :root {\n    --unchecked-box: '\\02610';\n    --checked-box: '\\02611';\n    --snowman: '\\02603';\n  }\n\n  td {\n    padding: 5px;\n  }\n\n  tr:hover, tr:hover td {\n    cursor: pointer;\n    background-color: yellow;\n  }\n\n  .icon, .template-icon {\n    display: flex;\n    justify-content: center;\n  }\n\n  .icon:after {\n    content: var(--snowman);\n  }\n\n  .selectable.hasSelection .selected .icon:after {\n    content: var(--checked-box);\n  }\n\n  .selectable:not(.hasSelection) tr:hover .icon:after,\n  .selectable.hasSelection .icon:after {\n    content: var(--unchecked-box);\n  }\n</style>\n\n<h1>Complex Multi-Select</h1>\n\n<table cellspacing=0 class:hasSelection={hasSelection} class=selectable>\n  {#each users as user}\n  <tr class:selected={user.selected} on:click={() => selectUser(user)}>\n    <td class=icon height=20 width=20></td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\n# Closing Thoughts\n\nThis is how I have tended to manage the working relationship between HTML and CSS for the last 20 years, and I think the power of thinking in this way leads to cleaner code and easier to refactor web interfaces.\n\nIf this looks completely foreign to you and you found yourself considering that the template-based conditional-logic approach made more sense, I'd recommend learning more about the capabilities of CSS features like [pseudo-selectors :not](https://developer.mozilla.org/en-US/docs/Web/CSS/var), [variables](https://developer.mozilla.org/en-US/docs/Web/CSS/var), and the [generated content: property](https://developer.mozilla.org/en-US/docs/Web/CSS/content).\n\nI've found that teams who up their level of knowledge in CSS and tend to try to split concerns like we've done here will have web applications that are easier to change over the long term.\n\nIf you are interested in learning more about this approach and seeing a live coded version of this blog post, please check out the [screencast](https://www.youtube.com/watch?v=xpnmtkjCNng) posted to my YouTube channel; it walks through all the examples and touches on a few more svelte-specific things to consider.\n\n# Learning Resources\n\n- [Svelte Tutorial](https://svelte.dev/tutorial/basics)\n- [Complex-Multi-Select Code on Github](https://github.com/davemo/svelte-casts)\n- [CSS Variables](https://developer.mozilla.org/en-US/docs/Web/CSS/var)\n- [CSS :not pseudo-selector](https://developer.mozilla.org/en-US/docs/Web/CSS/:not)\n- [CSS Generated Content](https://developer.mozilla.org/en-US/docs/Web/CSS/content)\n- [HTML Entity Symbols](https://www.toptal.com/designers/htmlarrows/symbols/)"
  },
  "attributes": {
    "title": "CSS is a visual state machine",
    "date": "2019-08-27"
  },
  "markdown": "\n> Thinking of web applications in terms of [state machines](https://en.wikipedia.org/wiki/Finite-state_machine) is [not a new idea](https://www.techrepublic.com/article/set-up-web-applications-as-finite-state-machines/); in fact, it has become so popular in the past few years that teams are spending increasingly more time breaking down their application into states managed by front-end frameworks.\n\n<iframe src=\"https://www.youtube.com/embed/xpnmtkjCNng?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nWhether you use [Redux](https://redux.js.org/), [MobX](https://mobx.js.org), or even perhaps something framework-agnostic like [xState](https://xstate.js.org), it is clear that thinking about web applications in terms of state machines is occurring much more frequently. With all this focus on state, transitions, and the benefits that come with structuring our applications like this, I've found there is still an area that is often overlooked when it comes to managing state in web applications: **the visual or presentation layer**.\n\nCSS is incredibly powerful yet frequently misunderstood by most developers, which often leads to derision of the language. I think this is mostly due to a fundamental error in the way web developers manage presentation, often focusing their efforts on conditional logic in templates instead of a more flexible application of state-specific CSS selectors to HTML elements.\n\n## A Simple Example\n\nLet us examine a simple example of a multi-selectable list for a user interface (UI) that a designer may have provided in mockup form for us as web developers to decompose into working code.\n\n![An animation of a multi-selectable list of users in tabular form. Each row has an icon which changes to indicate the selection state, defaulting to a snowman, empty checkbox on hover, and finally checked checkbox when selected.](/img/css-the-visual-state-machine/css-mockup.gif)\n\nWe can see there are a number of interactions at play, and at first glance these might seem simple enough that we would be tempted to solve the problem without putting much upfront thought into it. However, I think despite the simplicity of the example, there are enough complex states to enumerate that we should spend some time thinking about them before we dive into creating this UI.\n\n| State                            | Trigger             | Change                                                                                                 |\n| -------------------------------- | ------------------- | ------------------------------------------------------------------------------------------------------ |\n| _Selected_                       | Click               | Icon changes to a checkbox                                                                             |\n| _Unselected_                     | Click               | Icon changes to an empty box                                                                           |\n| _Hovering, No Selections_        | Hover               | The snowman icon for the hovered row changes to an empty checkbox to indicate potential for selection  |\n| _Hovering, 1 or More Selections_ | Hover               | All unselected row icons remain as empty checkboxes, and a yellow highlight appears on the hovered row |\n| _1 or more Selections Active_    | No User Interaction | All icons change to empty checkboxes to indicate the ability to select multiple rows                   |\n\nPutting aside [interaction design](https://en.wikipedia.org/wiki/Interaction_design) (IxD) and [accessibility](https://en.wikipedia.org/wiki/Web_accessibility) (a11y) concerns for the time being, after enumerating the states that we see here there is a lot to consider when building this UI! How should we manage the states? Should the logic live in our template or in our stylesheets? Let's take a brief look at the first approach, using an implementation in [Svelte](https://svelte.dev).\n\nSvelte is a compiler that takes as input one or more `.svelte` files with _regions_ of functionality based on JavaScript, HTML, and CSS; with that input it produces the minimal amount of DOM API output in JavaScript to achieve the desired result. It's a different take than something like React, Angular, or Ember, which ship substantial runtimes to the browser that execute application code. If you are interested in learning more I highly recommend watching this excellent talk called _[Rethinking Reactivity](https://www.youtube.com/watch?v=AdNJ3fydeao)_ from Rich Harris introducing some of the core ideas. The code in the following examples is intended to be simple enough that you should be able to port the ideas represented to any other framework with minimal effort.\n\n## Implementation: Templates\n\nOne of the first places a web developer might start is by crafting the template that represents the UI mockup we received from our designer friend above. This seems like a logical place to start, given we need some way to represent the data in a web browser. Let's build a template using svelte-infused HTML and see how it looks.\n\n``` html\n<table>\n  {#each users as user}\n  <tr>\n    <td class=\"icon\">\n      {#if user.selected && hasSelection}\n        {checkedBox}\n      {:else if !user.selected && hasSelection}\n        {uncheckedBox}\n      {:else}\n        {snowman}\n      {/if}\n    </td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\nAside from the svelte-specific things like the `{#each}` and `{#if}` blocks, this is probably close to what you might implement in any front-end or server-side templating solution. We've taken the list of potential states that we extracted from the mockup above and encoded them as conditional logic in our templates in order to achieve the desired result. The one special case we needed to account for was the non-interactive state \"1 or more Selections Active\"; to do this we defined a local variable in our JavaScript region called `hasSelection` which is defined using Sveltes [reactive declarations](https://svelte.dev/tutorial/reactive-declarations) as `$: hasSelection = users.some(u => u.selected)`.\n\nAlthough the code above satisfies _most_ of the user experience (UX) as detailed in the mockup, there are two problems that shake out of an implementation like this that focuses on conditional logic in templates:\n\n1. We didn't capture _all_ of the states enumerated, as we cannot effectively translate a user's `hover` action in templates alone unless we get really creative and complex\n2. This paradigm scales _very poorly_ as our templates grow, mixing concerns of `presentation` and `data` in a template, resulting in code that is much harder to read and maintain over the life of a project\n\nThe scalability concern is the more worrisome of the two, yet is a common byproduct of developers using conditional logic in templates. Increasingly thorny conditionals can lead to missed acceptance criteria, which in turn can lead to stress and tension on a team. Rather than throw blame around, it's worth focusing on whether that approach is healthy for a long-term project.\n\nI think we can do better if we shift our focus from conditional logic in templates to thinking more in terms of leveraging CSS as the language we use to define the states in our presentational state machine and using JavaScript to manage when to apply those states. Let's see what that looks like as we refactor the above example.\n\n## Implementation: Stylesheets\n\nOne of the first considerations we'll need to make is how to address both the concerns raised in the previous section. We need to handle the `hover` state properly, and we also should strive for a solution that encodes data in the template and presentation in the stylesheets. Let's start by refactoring the template to eliminate the conditional logic:\n\n``` html\n<table class:hasSelection=\"{hasSelection}\" class=\"selectable\">\n  {#each users as user}\n  <tr class:selected=\"{user.selected}\">\n    <td class=\"icon\"></td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\nThe first thing you might notice is that we removed the conditional blocks replaced them with [svelte's class element directive](https://svelte.dev/docs#class_name). This is an elegant way to control toggling of a CSS class on an element via a boolean value, which we previously defined as `{user.selected}` and `{hasSelection}`. We also added a `class=selectable` to the root table element in order to allow us to better manage the complexity of the conditional logic for states in CSS. Let's defer looking at the JavaScript that defines those values and instead look at what the definition of each state in our presentational state machine looks like when we encode it with CSS:\n\n``` css\n/*\n  CSS variables in conjunction with escaped unicode or html\n  entities are a great way to represent things like icons\n*/\n:root {\n  --unchecked-box: \"\\02610\";\n  --checked-box: \"\\02611\";\n  --snowman: \"\\02603\";\n}\n\n/*\n  Managing the hover states to show a yellow background\n*/\ntr:hover,\ntr:hover td {\n  cursor: pointer;\n  background-color: yellow;\n}\n\n/*\n  Our first state, every icon should default to the snowman\n*/\n.icon:after {\n  content: var(--snowman);\n}\n\n/*\n  A complex state, if the table has a selection,\n  then every selected items icon should be the checked box\n*/\n.selectable.hasSelection .selected .icon:after {\n  content: var(--checked-box);\n}\n\n/*\n  A combined selector to handle the alternative complex states:\n  - for a table without a selection, when the user hovers, show the unchecked box\n  - for a table with selections, swap the icon from the snowman to the unchecked box\n*/\n.selectable:not(.hasSelection) tr:hover .icon:after,\n.selectable.hasSelection .icon:after {\n  content: var(--unchecked-box);\n}\n```\n\nWith the combination of CSS and svelte-infused HTML we've achieved the result our designer was hoping for when they handed us the initial mockup, with an appropriate separation between the definition of our states (CSS) and the application of those states (HTML, and JavaScript).\n\nFor completeness, here is the entirety of the example as included in `Application.svelte` from the [code on github](https://github.com/davemo/svelte-casts):\n\n``` html\n<script>\n  let users = [\n    {name: 'Danika Dywtgowm', email: 'danika.dywtgowm@email.com'},\n    {name: 'Erica Bule', email: 'erica.bule@email.com'},\n    {name: 'Jim Snales', email: 'jim.snales@email.com'},\n    {name: 'Daria Thorobox', email: 'daria.thorobox@email.com'},\n    {name: 'Mendikant Hargrove', email: 'mendikant.hargrove@email.com'},\n    {name: 'Ephraim Lischok', email: 'ephraim.lischok@email.com'},\n    {name: 'Lera Nedialkova', email: 'lera.nedialkova@email.com'},\n  ]\n\n  function selectUser(user) {\n    users[users.findIndex(u => u.name === user.name)] = {\n      ...user,\n      selected: !user.selected\n    }\n    console.log(`${user.name} was ${user.selected ? 'de-selected' : 'selected'}`);\n  }\n\n  $: hasSelection = users.some(u => u.selected)\n</script>\n\n<style>\n  :root {\n    --unchecked-box: '\\02610';\n    --checked-box: '\\02611';\n    --snowman: '\\02603';\n  }\n\n  td {\n    padding: 5px;\n  }\n\n  tr:hover, tr:hover td {\n    cursor: pointer;\n    background-color: yellow;\n  }\n\n  .icon, .template-icon {\n    display: flex;\n    justify-content: center;\n  }\n\n  .icon:after {\n    content: var(--snowman);\n  }\n\n  .selectable.hasSelection .selected .icon:after {\n    content: var(--checked-box);\n  }\n\n  .selectable:not(.hasSelection) tr:hover .icon:after,\n  .selectable.hasSelection .icon:after {\n    content: var(--unchecked-box);\n  }\n</style>\n\n<h1>Complex Multi-Select</h1>\n\n<table cellspacing=0 class:hasSelection={hasSelection} class=selectable>\n  {#each users as user}\n  <tr class:selected={user.selected} on:click={() => selectUser(user)}>\n    <td class=icon height=20 width=20></td>\n    <td>\n      {user.name}\n    </td>\n    <td>\n      {user.email}\n    </td>\n  </tr>\n  {/each}\n</table>\n```\n\n# Closing Thoughts\n\nThis is how I have tended to manage the working relationship between HTML and CSS for the last 20 years, and I think the power of thinking in this way leads to cleaner code and easier to refactor web interfaces.\n\nIf this looks completely foreign to you and you found yourself considering that the template-based conditional-logic approach made more sense, I'd recommend learning more about the capabilities of CSS features like [pseudo-selectors :not](https://developer.mozilla.org/en-US/docs/Web/CSS/var), [variables](https://developer.mozilla.org/en-US/docs/Web/CSS/var), and the [generated content: property](https://developer.mozilla.org/en-US/docs/Web/CSS/content).\n\nI've found that teams who up their level of knowledge in CSS and tend to try to split concerns like we've done here will have web applications that are easier to change over the long term.\n\nIf you are interested in learning more about this approach and seeing a live coded version of this blog post, please check out the [screencast](https://www.youtube.com/watch?v=xpnmtkjCNng) posted to my YouTube channel; it walks through all the examples and touches on a few more svelte-specific things to consider.\n\n# Learning Resources\n\n- [Svelte Tutorial](https://svelte.dev/tutorial/basics)\n- [Complex-Multi-Select Code on Github](https://github.com/davemo/svelte-casts)\n- [CSS Variables](https://developer.mozilla.org/en-US/docs/Web/CSS/var)\n- [CSS :not pseudo-selector](https://developer.mozilla.org/en-US/docs/Web/CSS/:not)\n- [CSS Generated Content](https://developer.mozilla.org/en-US/docs/Web/CSS/content)\n- [HTML Entity Symbols](https://www.toptal.com/designers/htmlarrows/symbols/)"
}></pre></div><div><a href="/posts/2018-04-06-open-source-spotlight-dependable-js.html">Open Source Spotlight: Dependable JS</a><pre><{
  "path": "app/posts/2018-04-06-open-source-spotlight-dependable-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Open Source Spotlight: Dependable JS",
      "date": "2018-04-06"
    },
    "source": "\n> Recently, [Michael Schoonmaker](https://twitter.com/Schoonology), [Joshua Starkey](https://twitter.com/primarilysnark), and [myself](https://twitter.com/dmosher) got together to brainstorm some improvements we wanted to make to an open source library called Dependable that we had used on a client project.\n\n[Dependable](https://github.com/testdouble/dependable) is billed as \"A minimalist dependency injection framework for node.js\", but I feel like it only took on the \"minimalist\" moniker after we shipped version 2.0 just a few weeks ago. As we sat down to discuss what we wanted to do there were a number of questions that shook out that I feel need to be asked by any team working on an open source project:\n\n* How can we make this smaller?\n* What features are core and what can we prune?\n* How can we write the test-suite in a way that demonstrates real-world examples?\n* What should the README communicate?\n* How are we going to maintain this going forward?\n\nAs we worked towards the backlog of features, we built up a list of _nice-to-haves_ and _must-haves_, choosing to defer the former and focus our efforts on the latter. [Github Projects](https://github.com/testdouble/dependable/projects/1) actually worked pretty well for a lightweight project management tool.\n\n![Github Projects](/img/open-source-spotlight-dependable-js/github-projects-dependable.png)\n\n# Limiting API Surface Area\n\nOne of our stated goals was to reduce the surface area of dependable in order to eliminate complexity in the codebase. The 1.0 release of dependable included a public API with 6 methods on the dependency inversion `container` and our rewrite whittled this down to 4. Choosing to have this discussion early allowed us to focus on what the most valuable parts of the API were, using our experience of real-world use within consulting projects to help guide us.\n\n| 1.0 Public API  | 2.0 Public API |\n| ------------- | ------------- |\n| `container.register(name, func)`  | `container.factory(name, func)`  |\n| `container.register(hash)` | `container.constant(name, object)` |\n| `container.load(fileOrFolder)` | removed |\n| `container.get(name, overrides = {})` | `container.get(name, overrides = {})` |\n| `container.resolve(overrides={}, cb)` | removed |\n| `container.list()` | removed |\n| non-existent | `container.getSandboxed(name, overrides={})`|\n\nWith the API sufficiently whittled down, we also set ourselves to renaming the methods in the public API in order to better reveal the intent for each method and avoid violating [SRP](https://en.wikipedia.org/wiki/Single_responsibility_principle) (which some of the 1.0 API methods had done via overloading). `container.register(hash)` became `container.constant(name, object)`, and `container.register` was renamed simply to `container.factory`. We deliberated for a while over naming but felt that `.factory` and `.constant` were terms that were familiar enough in the context of dependency injection and more descriptive than their 1.0 counterparts.\n\n# Rewriting Source and Test\n\nDependable 1.0 was written in CoffeeScript which we felt would limit options for potential future contributors. We chose to rewrite the library in ES6 and use [standard](https://standardjs.com/) to manage formatting the code for us. It becomes much easier for future contributors to submit patches when the tooling in an open source project handles formatting of the code.\n\n| 1.0 LOC (index.coffee) | 2.0 LOC (index.js) |\n| ------------- | ------------- |\n| 134 | 99 |\n\nThe test-suite took slightly longer to rewrite due to the removal of `container.load(fileOrFolder)`. We felt that this method complected the 1.0 codebase and was syntactic sugar for what could be accomplished by a user via loading one or many files externally using `require` or `import` and then invoking `container.factory(name, func)` within the context of a call to `.map`. In addition to translating the `.coffee` test sources to `.js`, we also reorganized the test examples themselves to better communicate the intended use of dependable.\n\n| 1.0 Test LOC (multiple .coffee files) | 2.0 Test LOC (test.js) |\n| ------------- | ------------- |\n| ~380 | 259 |\n\nA consistent use of objects from a real world scenario involving a `Logger`, `Router`, and `Formatter` in the context of an `App` was used throughout the test-suite. I've found that I'm much more likely to contribute to open source projects that have a well architected test suite with meaningful examples.\n\n```javascript\nit('should register a factory with a single dependency', function () {\n  subject.factory('logger', function () {\n    return 'message'\n  })\n  subject.factory('app', function (logger) {\n    return logger\n  })\n  assert.equal(subject.get('app'), 'message')\n})\n```\n\nIn addition, we added first-class support for isolation testing via `container.getSandboxed` which should be used during testing to ensure that a module under test has been completely isolated.\n\n# Closing Thoughts & Recommended Reading\n\nAt Test Double we are proud of our commitment to open source and we take pride in trying to be thoughtful in the way we approach open source stewardship. If you share these values and are interested in joining us you should [reach out](https://testdouble.com/join/), we're hiring!\n\nIf you aren't familiar with the concept or benefits of Dependency Injection these are some great followup resources to get you thinking:\n\n* [Inversion of Control Containers and the Dependency Injection pattern](https://martinfowler.com/articles/injection.html)\n* [Inversion of Control, The UI Thread and Backbone.JS Views](https://www.youtube.com/watch?v=mU1JcPikdMs)"
  },
  "attributes": {
    "title": "Open Source Spotlight: Dependable JS",
    "date": "2018-04-06"
  },
  "markdown": "\n> Recently, [Michael Schoonmaker](https://twitter.com/Schoonology), [Joshua Starkey](https://twitter.com/primarilysnark), and [myself](https://twitter.com/dmosher) got together to brainstorm some improvements we wanted to make to an open source library called Dependable that we had used on a client project.\n\n[Dependable](https://github.com/testdouble/dependable) is billed as \"A minimalist dependency injection framework for node.js\", but I feel like it only took on the \"minimalist\" moniker after we shipped version 2.0 just a few weeks ago. As we sat down to discuss what we wanted to do there were a number of questions that shook out that I feel need to be asked by any team working on an open source project:\n\n* How can we make this smaller?\n* What features are core and what can we prune?\n* How can we write the test-suite in a way that demonstrates real-world examples?\n* What should the README communicate?\n* How are we going to maintain this going forward?\n\nAs we worked towards the backlog of features, we built up a list of _nice-to-haves_ and _must-haves_, choosing to defer the former and focus our efforts on the latter. [Github Projects](https://github.com/testdouble/dependable/projects/1) actually worked pretty well for a lightweight project management tool.\n\n![Github Projects](/img/open-source-spotlight-dependable-js/github-projects-dependable.png)\n\n# Limiting API Surface Area\n\nOne of our stated goals was to reduce the surface area of dependable in order to eliminate complexity in the codebase. The 1.0 release of dependable included a public API with 6 methods on the dependency inversion `container` and our rewrite whittled this down to 4. Choosing to have this discussion early allowed us to focus on what the most valuable parts of the API were, using our experience of real-world use within consulting projects to help guide us.\n\n| 1.0 Public API  | 2.0 Public API |\n| ------------- | ------------- |\n| `container.register(name, func)`  | `container.factory(name, func)`  |\n| `container.register(hash)` | `container.constant(name, object)` |\n| `container.load(fileOrFolder)` | removed |\n| `container.get(name, overrides = {})` | `container.get(name, overrides = {})` |\n| `container.resolve(overrides={}, cb)` | removed |\n| `container.list()` | removed |\n| non-existent | `container.getSandboxed(name, overrides={})`|\n\nWith the API sufficiently whittled down, we also set ourselves to renaming the methods in the public API in order to better reveal the intent for each method and avoid violating [SRP](https://en.wikipedia.org/wiki/Single_responsibility_principle) (which some of the 1.0 API methods had done via overloading). `container.register(hash)` became `container.constant(name, object)`, and `container.register` was renamed simply to `container.factory`. We deliberated for a while over naming but felt that `.factory` and `.constant` were terms that were familiar enough in the context of dependency injection and more descriptive than their 1.0 counterparts.\n\n# Rewriting Source and Test\n\nDependable 1.0 was written in CoffeeScript which we felt would limit options for potential future contributors. We chose to rewrite the library in ES6 and use [standard](https://standardjs.com/) to manage formatting the code for us. It becomes much easier for future contributors to submit patches when the tooling in an open source project handles formatting of the code.\n\n| 1.0 LOC (index.coffee) | 2.0 LOC (index.js) |\n| ------------- | ------------- |\n| 134 | 99 |\n\nThe test-suite took slightly longer to rewrite due to the removal of `container.load(fileOrFolder)`. We felt that this method complected the 1.0 codebase and was syntactic sugar for what could be accomplished by a user via loading one or many files externally using `require` or `import` and then invoking `container.factory(name, func)` within the context of a call to `.map`. In addition to translating the `.coffee` test sources to `.js`, we also reorganized the test examples themselves to better communicate the intended use of dependable.\n\n| 1.0 Test LOC (multiple .coffee files) | 2.0 Test LOC (test.js) |\n| ------------- | ------------- |\n| ~380 | 259 |\n\nA consistent use of objects from a real world scenario involving a `Logger`, `Router`, and `Formatter` in the context of an `App` was used throughout the test-suite. I've found that I'm much more likely to contribute to open source projects that have a well architected test suite with meaningful examples.\n\n```javascript\nit('should register a factory with a single dependency', function () {\n  subject.factory('logger', function () {\n    return 'message'\n  })\n  subject.factory('app', function (logger) {\n    return logger\n  })\n  assert.equal(subject.get('app'), 'message')\n})\n```\n\nIn addition, we added first-class support for isolation testing via `container.getSandboxed` which should be used during testing to ensure that a module under test has been completely isolated.\n\n# Closing Thoughts & Recommended Reading\n\nAt Test Double we are proud of our commitment to open source and we take pride in trying to be thoughtful in the way we approach open source stewardship. If you share these values and are interested in joining us you should [reach out](https://testdouble.com/join/), we're hiring!\n\nIf you aren't familiar with the concept or benefits of Dependency Injection these are some great followup resources to get you thinking:\n\n* [Inversion of Control Containers and the Dependency Injection pattern](https://martinfowler.com/articles/injection.html)\n* [Inversion of Control, The UI Thread and Backbone.JS Views](https://www.youtube.com/watch?v=mU1JcPikdMs)"
}></{
  "path": "app/posts/2018-04-06-open-source-spotlight-dependable-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Open Source Spotlight: Dependable JS",
      "date": "2018-04-06"
    },
    "source": "\n> Recently, [Michael Schoonmaker](https://twitter.com/Schoonology), [Joshua Starkey](https://twitter.com/primarilysnark), and [myself](https://twitter.com/dmosher) got together to brainstorm some improvements we wanted to make to an open source library called Dependable that we had used on a client project.\n\n[Dependable](https://github.com/testdouble/dependable) is billed as \"A minimalist dependency injection framework for node.js\", but I feel like it only took on the \"minimalist\" moniker after we shipped version 2.0 just a few weeks ago. As we sat down to discuss what we wanted to do there were a number of questions that shook out that I feel need to be asked by any team working on an open source project:\n\n* How can we make this smaller?\n* What features are core and what can we prune?\n* How can we write the test-suite in a way that demonstrates real-world examples?\n* What should the README communicate?\n* How are we going to maintain this going forward?\n\nAs we worked towards the backlog of features, we built up a list of _nice-to-haves_ and _must-haves_, choosing to defer the former and focus our efforts on the latter. [Github Projects](https://github.com/testdouble/dependable/projects/1) actually worked pretty well for a lightweight project management tool.\n\n![Github Projects](/img/open-source-spotlight-dependable-js/github-projects-dependable.png)\n\n# Limiting API Surface Area\n\nOne of our stated goals was to reduce the surface area of dependable in order to eliminate complexity in the codebase. The 1.0 release of dependable included a public API with 6 methods on the dependency inversion `container` and our rewrite whittled this down to 4. Choosing to have this discussion early allowed us to focus on what the most valuable parts of the API were, using our experience of real-world use within consulting projects to help guide us.\n\n| 1.0 Public API  | 2.0 Public API |\n| ------------- | ------------- |\n| `container.register(name, func)`  | `container.factory(name, func)`  |\n| `container.register(hash)` | `container.constant(name, object)` |\n| `container.load(fileOrFolder)` | removed |\n| `container.get(name, overrides = {})` | `container.get(name, overrides = {})` |\n| `container.resolve(overrides={}, cb)` | removed |\n| `container.list()` | removed |\n| non-existent | `container.getSandboxed(name, overrides={})`|\n\nWith the API sufficiently whittled down, we also set ourselves to renaming the methods in the public API in order to better reveal the intent for each method and avoid violating [SRP](https://en.wikipedia.org/wiki/Single_responsibility_principle) (which some of the 1.0 API methods had done via overloading). `container.register(hash)` became `container.constant(name, object)`, and `container.register` was renamed simply to `container.factory`. We deliberated for a while over naming but felt that `.factory` and `.constant` were terms that were familiar enough in the context of dependency injection and more descriptive than their 1.0 counterparts.\n\n# Rewriting Source and Test\n\nDependable 1.0 was written in CoffeeScript which we felt would limit options for potential future contributors. We chose to rewrite the library in ES6 and use [standard](https://standardjs.com/) to manage formatting the code for us. It becomes much easier for future contributors to submit patches when the tooling in an open source project handles formatting of the code.\n\n| 1.0 LOC (index.coffee) | 2.0 LOC (index.js) |\n| ------------- | ------------- |\n| 134 | 99 |\n\nThe test-suite took slightly longer to rewrite due to the removal of `container.load(fileOrFolder)`. We felt that this method complected the 1.0 codebase and was syntactic sugar for what could be accomplished by a user via loading one or many files externally using `require` or `import` and then invoking `container.factory(name, func)` within the context of a call to `.map`. In addition to translating the `.coffee` test sources to `.js`, we also reorganized the test examples themselves to better communicate the intended use of dependable.\n\n| 1.0 Test LOC (multiple .coffee files) | 2.0 Test LOC (test.js) |\n| ------------- | ------------- |\n| ~380 | 259 |\n\nA consistent use of objects from a real world scenario involving a `Logger`, `Router`, and `Formatter` in the context of an `App` was used throughout the test-suite. I've found that I'm much more likely to contribute to open source projects that have a well architected test suite with meaningful examples.\n\n```javascript\nit('should register a factory with a single dependency', function () {\n  subject.factory('logger', function () {\n    return 'message'\n  })\n  subject.factory('app', function (logger) {\n    return logger\n  })\n  assert.equal(subject.get('app'), 'message')\n})\n```\n\nIn addition, we added first-class support for isolation testing via `container.getSandboxed` which should be used during testing to ensure that a module under test has been completely isolated.\n\n# Closing Thoughts & Recommended Reading\n\nAt Test Double we are proud of our commitment to open source and we take pride in trying to be thoughtful in the way we approach open source stewardship. If you share these values and are interested in joining us you should [reach out](https://testdouble.com/join/), we're hiring!\n\nIf you aren't familiar with the concept or benefits of Dependency Injection these are some great followup resources to get you thinking:\n\n* [Inversion of Control Containers and the Dependency Injection pattern](https://martinfowler.com/articles/injection.html)\n* [Inversion of Control, The UI Thread and Backbone.JS Views](https://www.youtube.com/watch?v=mU1JcPikdMs)"
  },
  "attributes": {
    "title": "Open Source Spotlight: Dependable JS",
    "date": "2018-04-06"
  },
  "markdown": "\n> Recently, [Michael Schoonmaker](https://twitter.com/Schoonology), [Joshua Starkey](https://twitter.com/primarilysnark), and [myself](https://twitter.com/dmosher) got together to brainstorm some improvements we wanted to make to an open source library called Dependable that we had used on a client project.\n\n[Dependable](https://github.com/testdouble/dependable) is billed as \"A minimalist dependency injection framework for node.js\", but I feel like it only took on the \"minimalist\" moniker after we shipped version 2.0 just a few weeks ago. As we sat down to discuss what we wanted to do there were a number of questions that shook out that I feel need to be asked by any team working on an open source project:\n\n* How can we make this smaller?\n* What features are core and what can we prune?\n* How can we write the test-suite in a way that demonstrates real-world examples?\n* What should the README communicate?\n* How are we going to maintain this going forward?\n\nAs we worked towards the backlog of features, we built up a list of _nice-to-haves_ and _must-haves_, choosing to defer the former and focus our efforts on the latter. [Github Projects](https://github.com/testdouble/dependable/projects/1) actually worked pretty well for a lightweight project management tool.\n\n![Github Projects](/img/open-source-spotlight-dependable-js/github-projects-dependable.png)\n\n# Limiting API Surface Area\n\nOne of our stated goals was to reduce the surface area of dependable in order to eliminate complexity in the codebase. The 1.0 release of dependable included a public API with 6 methods on the dependency inversion `container` and our rewrite whittled this down to 4. Choosing to have this discussion early allowed us to focus on what the most valuable parts of the API were, using our experience of real-world use within consulting projects to help guide us.\n\n| 1.0 Public API  | 2.0 Public API |\n| ------------- | ------------- |\n| `container.register(name, func)`  | `container.factory(name, func)`  |\n| `container.register(hash)` | `container.constant(name, object)` |\n| `container.load(fileOrFolder)` | removed |\n| `container.get(name, overrides = {})` | `container.get(name, overrides = {})` |\n| `container.resolve(overrides={}, cb)` | removed |\n| `container.list()` | removed |\n| non-existent | `container.getSandboxed(name, overrides={})`|\n\nWith the API sufficiently whittled down, we also set ourselves to renaming the methods in the public API in order to better reveal the intent for each method and avoid violating [SRP](https://en.wikipedia.org/wiki/Single_responsibility_principle) (which some of the 1.0 API methods had done via overloading). `container.register(hash)` became `container.constant(name, object)`, and `container.register` was renamed simply to `container.factory`. We deliberated for a while over naming but felt that `.factory` and `.constant` were terms that were familiar enough in the context of dependency injection and more descriptive than their 1.0 counterparts.\n\n# Rewriting Source and Test\n\nDependable 1.0 was written in CoffeeScript which we felt would limit options for potential future contributors. We chose to rewrite the library in ES6 and use [standard](https://standardjs.com/) to manage formatting the code for us. It becomes much easier for future contributors to submit patches when the tooling in an open source project handles formatting of the code.\n\n| 1.0 LOC (index.coffee) | 2.0 LOC (index.js) |\n| ------------- | ------------- |\n| 134 | 99 |\n\nThe test-suite took slightly longer to rewrite due to the removal of `container.load(fileOrFolder)`. We felt that this method complected the 1.0 codebase and was syntactic sugar for what could be accomplished by a user via loading one or many files externally using `require` or `import` and then invoking `container.factory(name, func)` within the context of a call to `.map`. In addition to translating the `.coffee` test sources to `.js`, we also reorganized the test examples themselves to better communicate the intended use of dependable.\n\n| 1.0 Test LOC (multiple .coffee files) | 2.0 Test LOC (test.js) |\n| ------------- | ------------- |\n| ~380 | 259 |\n\nA consistent use of objects from a real world scenario involving a `Logger`, `Router`, and `Formatter` in the context of an `App` was used throughout the test-suite. I've found that I'm much more likely to contribute to open source projects that have a well architected test suite with meaningful examples.\n\n```javascript\nit('should register a factory with a single dependency', function () {\n  subject.factory('logger', function () {\n    return 'message'\n  })\n  subject.factory('app', function (logger) {\n    return logger\n  })\n  assert.equal(subject.get('app'), 'message')\n})\n```\n\nIn addition, we added first-class support for isolation testing via `container.getSandboxed` which should be used during testing to ensure that a module under test has been completely isolated.\n\n# Closing Thoughts & Recommended Reading\n\nAt Test Double we are proud of our commitment to open source and we take pride in trying to be thoughtful in the way we approach open source stewardship. If you share these values and are interested in joining us you should [reach out](https://testdouble.com/join/), we're hiring!\n\nIf you aren't familiar with the concept or benefits of Dependency Injection these are some great followup resources to get you thinking:\n\n* [Inversion of Control Containers and the Dependency Injection pattern](https://martinfowler.com/articles/injection.html)\n* [Inversion of Control, The UI Thread and Backbone.JS Views](https://www.youtube.com/watch?v=mU1JcPikdMs)"
}></pre></div><div><a href="/posts/2018-02-01-the-consultants-code.html">The Consultants Code</a><pre><{
  "path": "app/posts/2018-02-01-the-consultants-code.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The Consultants Code",
      "date": "2018-02-01"
    },
    "source": "\n> I wish we could have built it right the first time but we were learning along the way.\n>\n> Ugh, we got handed this mess and now we have to figure out what to do with it.\n>\n> What do you think we should do?\n\nSound familiar? If any of these statements resonates with you then you've most likely been in the shoes of the person making the statement _or_ as a consultant engaged with a client in a similar predicament. The phrase \"Software Consulting\" generally evokes feelings of **praise** or **disdain**, or perhaps both depending on the circumstances. As consultants, we are often positioned as experts and typically engaged during times of crisis or uncertainty; so it should come as no surprise that our ability to deliver in the midst of that environment is the primary measure of our effectiveness.\n\nExpectations about what we are hired to deliver generally set the scale by which we are judged; frequently that involves analysis, reporting, recommendations but also training, mentoring, and code. The world is a big enough place that it's plausible to think of a scenario where the opening statements above were made by someone dealing with the aftermath of a poor experience with a previous software consultancy, typically measured by the state or quality of \"the code\".\n\nWhile it would be interesting to attempt an objective look at what typifies \"quality\" as it relates to \"code\", I think there is a _more_ interesting vector to approach the quality valuation that also pertains to \"code\" of a different kind; call it the code of conduct, or the way we interact with our clients as consultants, or perhaps even our ability to relate and help them rise out of the midst of chaos and uncertainty&mdash;this type of consultant's code is less frequently explored, which is a shame, because I firmly believe it has a more direct impact on the physical code we write than our technical expertise.\n\n## Hostile Takeover\n\nConsultants in any industry are often vilified from the start of an engagement due to a perceived \"us vs them\" mentality. Depending on the how the engagement was initiated, trust was likely extended from key decision makers but generally does _not_ extend from the rank and file employees of the company. This puts an immediate burden of responsibility on the consultant to become adept at earning that trust inclusively and at discerning barriers which would prevent that from happening.\n\nThe key to building this trust starts with establishing relationships with _everyone_ on the team. It might be easy to think of ourselves as only accountable to the primary stakeholders, but unless we earn the trust of our peers and treat them as equals, it will be challenging to avoid the perception of a hostile takeover. In essence we should think of ourselves as partners, invested in the success of the company and each member of the team. Finding opportunities to mentor team members and attribute wins to others is a great way foster a positive consulting environment.\n\n## Cooperation & Commiseration\n\nAt some point any consulting engagement will involve hearing about the technical failures, company problems, personnel issues, and every other negative thing under the sun; people like to complain. Good consultants know how to view these conversations as opportunities to build trust without becoming embroiled in corporate politics. It is a balancing act to be able to participate in just enough commiseration to demonstrate understanding without fostering a negative cycle. I believe a critical component to developing this skill is the ability to hone one's capacity for [active listening](https://en.wikipedia.org/wiki/Active_listening).\n\nThere is a fine line between commiserating and ruminating, and good consultants know how to empathize and then steer the conversation towards solutions instead of ruminating on past failures.\n\n## Technical Overdrive\n\nDepending on the nature of the team and the consulting engagement, it may prove more effective to lead by example and jump into what I like to call \"technical overdrive\". I've seen many teams become derailed in endless technical round-table discussions and talk themselves into a corner before ever trying to code up a prototype or draft solution. In these scenarios I have found it best to move forward with quick prototypes of solutions proposed by the team, enabling them to have more concrete discussion points and base decisions on actual implementations. Working code and a good demo can unblock many teams.\n\nLike every piece of advice, when to jump into technical overdrive is highly context-sensitive; sometimes it is more appropriate to employ the opposite strategy and slow things down. Some teams have a bad habit of shipping their prototypes to production, and it is in this scenario where good consultants will try and introduce better habits around technical design, architecture discussions and how to effectively prototype. In some ways the slow-things-down scenario also involves technical overdrive, as it might mean taking the lead on demonstrating what these good habits look like for the team.\n\n# Closing Thoughts & Recommended Reading\n\nAs a consultant, building trust should be our number one goal, but we have to remember that it takes time and is a skill that needs to be cultivated over the course of many engagements. If you are interested in spending time honing your skills and improving your \"consultant's code\" I would recommend investing in the following resources:\n\n* [The Secrets of Consulting: A Guide to Giving and Getting Advice Successfully](https://www.amazon.ca/Secrets-Consulting-Giving-Getting-Successfully/dp/0932633013)\n* [More Secrets of Consulting: The Consultant's Tool Kit](https://www.amazon.com/More-Secrets-Consulting-Consultants-Tool-ebook/dp/B004J35LH6)\n* [Crucial Conversations: Tools for Talking When Stakes Are High](https://www.amazon.ca/Crucial-Conversations-Talking-Stakes-Second/dp/0071771328)\n* [Influencer: The New Science of Leading Change](https://www.amazon.com/Influencer-Science-Leading-Change-Second/dp/0071808868)\n* [How to Win Friends & Influence People](https://www.amazon.com/How-Win-Friends-Influence-People/dp/0671027034)\n* [Spin Selling](https://www.amazon.ca/SPIN-Selling-Neil-Rackham/dp/0070511136)\n\nAlso, if you're looking for a great opportunity to develop your consulting skills, they are hiring at Test Double, you should [apply](https://testdouble.com/join/). :)"
  },
  "attributes": {
    "title": "The Consultants Code",
    "date": "2018-02-01"
  },
  "markdown": "\n> I wish we could have built it right the first time but we were learning along the way.\n>\n> Ugh, we got handed this mess and now we have to figure out what to do with it.\n>\n> What do you think we should do?\n\nSound familiar? If any of these statements resonates with you then you've most likely been in the shoes of the person making the statement _or_ as a consultant engaged with a client in a similar predicament. The phrase \"Software Consulting\" generally evokes feelings of **praise** or **disdain**, or perhaps both depending on the circumstances. As consultants, we are often positioned as experts and typically engaged during times of crisis or uncertainty; so it should come as no surprise that our ability to deliver in the midst of that environment is the primary measure of our effectiveness.\n\nExpectations about what we are hired to deliver generally set the scale by which we are judged; frequently that involves analysis, reporting, recommendations but also training, mentoring, and code. The world is a big enough place that it's plausible to think of a scenario where the opening statements above were made by someone dealing with the aftermath of a poor experience with a previous software consultancy, typically measured by the state or quality of \"the code\".\n\nWhile it would be interesting to attempt an objective look at what typifies \"quality\" as it relates to \"code\", I think there is a _more_ interesting vector to approach the quality valuation that also pertains to \"code\" of a different kind; call it the code of conduct, or the way we interact with our clients as consultants, or perhaps even our ability to relate and help them rise out of the midst of chaos and uncertainty&mdash;this type of consultant's code is less frequently explored, which is a shame, because I firmly believe it has a more direct impact on the physical code we write than our technical expertise.\n\n## Hostile Takeover\n\nConsultants in any industry are often vilified from the start of an engagement due to a perceived \"us vs them\" mentality. Depending on the how the engagement was initiated, trust was likely extended from key decision makers but generally does _not_ extend from the rank and file employees of the company. This puts an immediate burden of responsibility on the consultant to become adept at earning that trust inclusively and at discerning barriers which would prevent that from happening.\n\nThe key to building this trust starts with establishing relationships with _everyone_ on the team. It might be easy to think of ourselves as only accountable to the primary stakeholders, but unless we earn the trust of our peers and treat them as equals, it will be challenging to avoid the perception of a hostile takeover. In essence we should think of ourselves as partners, invested in the success of the company and each member of the team. Finding opportunities to mentor team members and attribute wins to others is a great way foster a positive consulting environment.\n\n## Cooperation & Commiseration\n\nAt some point any consulting engagement will involve hearing about the technical failures, company problems, personnel issues, and every other negative thing under the sun; people like to complain. Good consultants know how to view these conversations as opportunities to build trust without becoming embroiled in corporate politics. It is a balancing act to be able to participate in just enough commiseration to demonstrate understanding without fostering a negative cycle. I believe a critical component to developing this skill is the ability to hone one's capacity for [active listening](https://en.wikipedia.org/wiki/Active_listening).\n\nThere is a fine line between commiserating and ruminating, and good consultants know how to empathize and then steer the conversation towards solutions instead of ruminating on past failures.\n\n## Technical Overdrive\n\nDepending on the nature of the team and the consulting engagement, it may prove more effective to lead by example and jump into what I like to call \"technical overdrive\". I've seen many teams become derailed in endless technical round-table discussions and talk themselves into a corner before ever trying to code up a prototype or draft solution. In these scenarios I have found it best to move forward with quick prototypes of solutions proposed by the team, enabling them to have more concrete discussion points and base decisions on actual implementations. Working code and a good demo can unblock many teams.\n\nLike every piece of advice, when to jump into technical overdrive is highly context-sensitive; sometimes it is more appropriate to employ the opposite strategy and slow things down. Some teams have a bad habit of shipping their prototypes to production, and it is in this scenario where good consultants will try and introduce better habits around technical design, architecture discussions and how to effectively prototype. In some ways the slow-things-down scenario also involves technical overdrive, as it might mean taking the lead on demonstrating what these good habits look like for the team.\n\n# Closing Thoughts & Recommended Reading\n\nAs a consultant, building trust should be our number one goal, but we have to remember that it takes time and is a skill that needs to be cultivated over the course of many engagements. If you are interested in spending time honing your skills and improving your \"consultant's code\" I would recommend investing in the following resources:\n\n* [The Secrets of Consulting: A Guide to Giving and Getting Advice Successfully](https://www.amazon.ca/Secrets-Consulting-Giving-Getting-Successfully/dp/0932633013)\n* [More Secrets of Consulting: The Consultant's Tool Kit](https://www.amazon.com/More-Secrets-Consulting-Consultants-Tool-ebook/dp/B004J35LH6)\n* [Crucial Conversations: Tools for Talking When Stakes Are High](https://www.amazon.ca/Crucial-Conversations-Talking-Stakes-Second/dp/0071771328)\n* [Influencer: The New Science of Leading Change](https://www.amazon.com/Influencer-Science-Leading-Change-Second/dp/0071808868)\n* [How to Win Friends & Influence People](https://www.amazon.com/How-Win-Friends-Influence-People/dp/0671027034)\n* [Spin Selling](https://www.amazon.ca/SPIN-Selling-Neil-Rackham/dp/0070511136)\n\nAlso, if you're looking for a great opportunity to develop your consulting skills, they are hiring at Test Double, you should [apply](https://testdouble.com/join/). :)"
}></{
  "path": "app/posts/2018-02-01-the-consultants-code.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The Consultants Code",
      "date": "2018-02-01"
    },
    "source": "\n> I wish we could have built it right the first time but we were learning along the way.\n>\n> Ugh, we got handed this mess and now we have to figure out what to do with it.\n>\n> What do you think we should do?\n\nSound familiar? If any of these statements resonates with you then you've most likely been in the shoes of the person making the statement _or_ as a consultant engaged with a client in a similar predicament. The phrase \"Software Consulting\" generally evokes feelings of **praise** or **disdain**, or perhaps both depending on the circumstances. As consultants, we are often positioned as experts and typically engaged during times of crisis or uncertainty; so it should come as no surprise that our ability to deliver in the midst of that environment is the primary measure of our effectiveness.\n\nExpectations about what we are hired to deliver generally set the scale by which we are judged; frequently that involves analysis, reporting, recommendations but also training, mentoring, and code. The world is a big enough place that it's plausible to think of a scenario where the opening statements above were made by someone dealing with the aftermath of a poor experience with a previous software consultancy, typically measured by the state or quality of \"the code\".\n\nWhile it would be interesting to attempt an objective look at what typifies \"quality\" as it relates to \"code\", I think there is a _more_ interesting vector to approach the quality valuation that also pertains to \"code\" of a different kind; call it the code of conduct, or the way we interact with our clients as consultants, or perhaps even our ability to relate and help them rise out of the midst of chaos and uncertainty&mdash;this type of consultant's code is less frequently explored, which is a shame, because I firmly believe it has a more direct impact on the physical code we write than our technical expertise.\n\n## Hostile Takeover\n\nConsultants in any industry are often vilified from the start of an engagement due to a perceived \"us vs them\" mentality. Depending on the how the engagement was initiated, trust was likely extended from key decision makers but generally does _not_ extend from the rank and file employees of the company. This puts an immediate burden of responsibility on the consultant to become adept at earning that trust inclusively and at discerning barriers which would prevent that from happening.\n\nThe key to building this trust starts with establishing relationships with _everyone_ on the team. It might be easy to think of ourselves as only accountable to the primary stakeholders, but unless we earn the trust of our peers and treat them as equals, it will be challenging to avoid the perception of a hostile takeover. In essence we should think of ourselves as partners, invested in the success of the company and each member of the team. Finding opportunities to mentor team members and attribute wins to others is a great way foster a positive consulting environment.\n\n## Cooperation & Commiseration\n\nAt some point any consulting engagement will involve hearing about the technical failures, company problems, personnel issues, and every other negative thing under the sun; people like to complain. Good consultants know how to view these conversations as opportunities to build trust without becoming embroiled in corporate politics. It is a balancing act to be able to participate in just enough commiseration to demonstrate understanding without fostering a negative cycle. I believe a critical component to developing this skill is the ability to hone one's capacity for [active listening](https://en.wikipedia.org/wiki/Active_listening).\n\nThere is a fine line between commiserating and ruminating, and good consultants know how to empathize and then steer the conversation towards solutions instead of ruminating on past failures.\n\n## Technical Overdrive\n\nDepending on the nature of the team and the consulting engagement, it may prove more effective to lead by example and jump into what I like to call \"technical overdrive\". I've seen many teams become derailed in endless technical round-table discussions and talk themselves into a corner before ever trying to code up a prototype or draft solution. In these scenarios I have found it best to move forward with quick prototypes of solutions proposed by the team, enabling them to have more concrete discussion points and base decisions on actual implementations. Working code and a good demo can unblock many teams.\n\nLike every piece of advice, when to jump into technical overdrive is highly context-sensitive; sometimes it is more appropriate to employ the opposite strategy and slow things down. Some teams have a bad habit of shipping their prototypes to production, and it is in this scenario where good consultants will try and introduce better habits around technical design, architecture discussions and how to effectively prototype. In some ways the slow-things-down scenario also involves technical overdrive, as it might mean taking the lead on demonstrating what these good habits look like for the team.\n\n# Closing Thoughts & Recommended Reading\n\nAs a consultant, building trust should be our number one goal, but we have to remember that it takes time and is a skill that needs to be cultivated over the course of many engagements. If you are interested in spending time honing your skills and improving your \"consultant's code\" I would recommend investing in the following resources:\n\n* [The Secrets of Consulting: A Guide to Giving and Getting Advice Successfully](https://www.amazon.ca/Secrets-Consulting-Giving-Getting-Successfully/dp/0932633013)\n* [More Secrets of Consulting: The Consultant's Tool Kit](https://www.amazon.com/More-Secrets-Consulting-Consultants-Tool-ebook/dp/B004J35LH6)\n* [Crucial Conversations: Tools for Talking When Stakes Are High](https://www.amazon.ca/Crucial-Conversations-Talking-Stakes-Second/dp/0071771328)\n* [Influencer: The New Science of Leading Change](https://www.amazon.com/Influencer-Science-Leading-Change-Second/dp/0071808868)\n* [How to Win Friends & Influence People](https://www.amazon.com/How-Win-Friends-Influence-People/dp/0671027034)\n* [Spin Selling](https://www.amazon.ca/SPIN-Selling-Neil-Rackham/dp/0070511136)\n\nAlso, if you're looking for a great opportunity to develop your consulting skills, they are hiring at Test Double, you should [apply](https://testdouble.com/join/). :)"
  },
  "attributes": {
    "title": "The Consultants Code",
    "date": "2018-02-01"
  },
  "markdown": "\n> I wish we could have built it right the first time but we were learning along the way.\n>\n> Ugh, we got handed this mess and now we have to figure out what to do with it.\n>\n> What do you think we should do?\n\nSound familiar? If any of these statements resonates with you then you've most likely been in the shoes of the person making the statement _or_ as a consultant engaged with a client in a similar predicament. The phrase \"Software Consulting\" generally evokes feelings of **praise** or **disdain**, or perhaps both depending on the circumstances. As consultants, we are often positioned as experts and typically engaged during times of crisis or uncertainty; so it should come as no surprise that our ability to deliver in the midst of that environment is the primary measure of our effectiveness.\n\nExpectations about what we are hired to deliver generally set the scale by which we are judged; frequently that involves analysis, reporting, recommendations but also training, mentoring, and code. The world is a big enough place that it's plausible to think of a scenario where the opening statements above were made by someone dealing with the aftermath of a poor experience with a previous software consultancy, typically measured by the state or quality of \"the code\".\n\nWhile it would be interesting to attempt an objective look at what typifies \"quality\" as it relates to \"code\", I think there is a _more_ interesting vector to approach the quality valuation that also pertains to \"code\" of a different kind; call it the code of conduct, or the way we interact with our clients as consultants, or perhaps even our ability to relate and help them rise out of the midst of chaos and uncertainty&mdash;this type of consultant's code is less frequently explored, which is a shame, because I firmly believe it has a more direct impact on the physical code we write than our technical expertise.\n\n## Hostile Takeover\n\nConsultants in any industry are often vilified from the start of an engagement due to a perceived \"us vs them\" mentality. Depending on the how the engagement was initiated, trust was likely extended from key decision makers but generally does _not_ extend from the rank and file employees of the company. This puts an immediate burden of responsibility on the consultant to become adept at earning that trust inclusively and at discerning barriers which would prevent that from happening.\n\nThe key to building this trust starts with establishing relationships with _everyone_ on the team. It might be easy to think of ourselves as only accountable to the primary stakeholders, but unless we earn the trust of our peers and treat them as equals, it will be challenging to avoid the perception of a hostile takeover. In essence we should think of ourselves as partners, invested in the success of the company and each member of the team. Finding opportunities to mentor team members and attribute wins to others is a great way foster a positive consulting environment.\n\n## Cooperation & Commiseration\n\nAt some point any consulting engagement will involve hearing about the technical failures, company problems, personnel issues, and every other negative thing under the sun; people like to complain. Good consultants know how to view these conversations as opportunities to build trust without becoming embroiled in corporate politics. It is a balancing act to be able to participate in just enough commiseration to demonstrate understanding without fostering a negative cycle. I believe a critical component to developing this skill is the ability to hone one's capacity for [active listening](https://en.wikipedia.org/wiki/Active_listening).\n\nThere is a fine line between commiserating and ruminating, and good consultants know how to empathize and then steer the conversation towards solutions instead of ruminating on past failures.\n\n## Technical Overdrive\n\nDepending on the nature of the team and the consulting engagement, it may prove more effective to lead by example and jump into what I like to call \"technical overdrive\". I've seen many teams become derailed in endless technical round-table discussions and talk themselves into a corner before ever trying to code up a prototype or draft solution. In these scenarios I have found it best to move forward with quick prototypes of solutions proposed by the team, enabling them to have more concrete discussion points and base decisions on actual implementations. Working code and a good demo can unblock many teams.\n\nLike every piece of advice, when to jump into technical overdrive is highly context-sensitive; sometimes it is more appropriate to employ the opposite strategy and slow things down. Some teams have a bad habit of shipping their prototypes to production, and it is in this scenario where good consultants will try and introduce better habits around technical design, architecture discussions and how to effectively prototype. In some ways the slow-things-down scenario also involves technical overdrive, as it might mean taking the lead on demonstrating what these good habits look like for the team.\n\n# Closing Thoughts & Recommended Reading\n\nAs a consultant, building trust should be our number one goal, but we have to remember that it takes time and is a skill that needs to be cultivated over the course of many engagements. If you are interested in spending time honing your skills and improving your \"consultant's code\" I would recommend investing in the following resources:\n\n* [The Secrets of Consulting: A Guide to Giving and Getting Advice Successfully](https://www.amazon.ca/Secrets-Consulting-Giving-Getting-Successfully/dp/0932633013)\n* [More Secrets of Consulting: The Consultant's Tool Kit](https://www.amazon.com/More-Secrets-Consulting-Consultants-Tool-ebook/dp/B004J35LH6)\n* [Crucial Conversations: Tools for Talking When Stakes Are High](https://www.amazon.ca/Crucial-Conversations-Talking-Stakes-Second/dp/0071771328)\n* [Influencer: The New Science of Leading Change](https://www.amazon.com/Influencer-Science-Leading-Change-Second/dp/0071808868)\n* [How to Win Friends & Influence People](https://www.amazon.com/How-Win-Friends-Influence-People/dp/0671027034)\n* [Spin Selling](https://www.amazon.ca/SPIN-Selling-Neil-Rackham/dp/0070511136)\n\nAlso, if you're looking for a great opportunity to develop your consulting skills, they are hiring at Test Double, you should [apply](https://testdouble.com/join/). :)"
}></pre></div><div><a href="/posts/2017-11-07-react-performance-analysis.html">React Performance Analysis</a><pre><{
  "path": "app/posts/2017-11-07-react-performance-analysis.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "React Performance Analysis",
      "date": "2017-11-07"
    },
    "source": "\n> React is frequently touted as being performant due to the optimizations of its Virtual DOM technique, yet all to often this is used by developers as a crutch to avoid thinking about the performance of their code _at all_. This generally leads to performance problems in React apps of any significant scale.\n\n<iframe src=\"https://www.youtube.com/embed/sVDnCMIkmTM?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nWith the proliferation of React applications in the wild, I thought it would be a good idea to examine some techniques for evaluating the performance of React Components.\n\nThis screencast covers a number of techniques for constructing components, but also shows how to evaluate performance objectively and make informed refactoring decisions.\n\n# Screencast Outline\n\n1. Introduction\n\n  * A Common UI Scenario for React Components -> Large Data Tables\n  * Developer Default: Google/Stack Overflow Driven Development\n  * The Quest for a pre-built Library\n\n2. Performance Goals\n\n  * Important Metrics: TTI (time to interactive), TTFMP (time to first meaningful paint)\n  * Setting a Frame Budget: (60fps / 16.7ms) might not always be feasible\n  * The Feedback Loop: Experiment, Evaluate\n\n3. React Development Patterns\n\n  * Start BIG: 1 component, 1 render method, then profile\n  * Decompose: limit the surface area of your component by thinking hard about props, then profile\n  * Optimize by:\n    * Reducing JS Execution: work the browser doesn't have to do doesn't need to be optimized\n    * Reducing Surface Area for Change: small components, limited surface area, small lists of props\n    * Keep `render` methods simple and _mostly_ static\n\n# Code\n\nhttps://github.com/davemo/react-performance-analysis"
  },
  "attributes": {
    "title": "React Performance Analysis",
    "date": "2017-11-07"
  },
  "markdown": "\n> React is frequently touted as being performant due to the optimizations of its Virtual DOM technique, yet all to often this is used by developers as a crutch to avoid thinking about the performance of their code _at all_. This generally leads to performance problems in React apps of any significant scale.\n\n<iframe src=\"https://www.youtube.com/embed/sVDnCMIkmTM?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nWith the proliferation of React applications in the wild, I thought it would be a good idea to examine some techniques for evaluating the performance of React Components.\n\nThis screencast covers a number of techniques for constructing components, but also shows how to evaluate performance objectively and make informed refactoring decisions.\n\n# Screencast Outline\n\n1. Introduction\n\n  * A Common UI Scenario for React Components -> Large Data Tables\n  * Developer Default: Google/Stack Overflow Driven Development\n  * The Quest for a pre-built Library\n\n2. Performance Goals\n\n  * Important Metrics: TTI (time to interactive), TTFMP (time to first meaningful paint)\n  * Setting a Frame Budget: (60fps / 16.7ms) might not always be feasible\n  * The Feedback Loop: Experiment, Evaluate\n\n3. React Development Patterns\n\n  * Start BIG: 1 component, 1 render method, then profile\n  * Decompose: limit the surface area of your component by thinking hard about props, then profile\n  * Optimize by:\n    * Reducing JS Execution: work the browser doesn't have to do doesn't need to be optimized\n    * Reducing Surface Area for Change: small components, limited surface area, small lists of props\n    * Keep `render` methods simple and _mostly_ static\n\n# Code\n\nhttps://github.com/davemo/react-performance-analysis"
}></{
  "path": "app/posts/2017-11-07-react-performance-analysis.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "React Performance Analysis",
      "date": "2017-11-07"
    },
    "source": "\n> React is frequently touted as being performant due to the optimizations of its Virtual DOM technique, yet all to often this is used by developers as a crutch to avoid thinking about the performance of their code _at all_. This generally leads to performance problems in React apps of any significant scale.\n\n<iframe src=\"https://www.youtube.com/embed/sVDnCMIkmTM?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nWith the proliferation of React applications in the wild, I thought it would be a good idea to examine some techniques for evaluating the performance of React Components.\n\nThis screencast covers a number of techniques for constructing components, but also shows how to evaluate performance objectively and make informed refactoring decisions.\n\n# Screencast Outline\n\n1. Introduction\n\n  * A Common UI Scenario for React Components -> Large Data Tables\n  * Developer Default: Google/Stack Overflow Driven Development\n  * The Quest for a pre-built Library\n\n2. Performance Goals\n\n  * Important Metrics: TTI (time to interactive), TTFMP (time to first meaningful paint)\n  * Setting a Frame Budget: (60fps / 16.7ms) might not always be feasible\n  * The Feedback Loop: Experiment, Evaluate\n\n3. React Development Patterns\n\n  * Start BIG: 1 component, 1 render method, then profile\n  * Decompose: limit the surface area of your component by thinking hard about props, then profile\n  * Optimize by:\n    * Reducing JS Execution: work the browser doesn't have to do doesn't need to be optimized\n    * Reducing Surface Area for Change: small components, limited surface area, small lists of props\n    * Keep `render` methods simple and _mostly_ static\n\n# Code\n\nhttps://github.com/davemo/react-performance-analysis"
  },
  "attributes": {
    "title": "React Performance Analysis",
    "date": "2017-11-07"
  },
  "markdown": "\n> React is frequently touted as being performant due to the optimizations of its Virtual DOM technique, yet all to often this is used by developers as a crutch to avoid thinking about the performance of their code _at all_. This generally leads to performance problems in React apps of any significant scale.\n\n<iframe src=\"https://www.youtube.com/embed/sVDnCMIkmTM?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nWith the proliferation of React applications in the wild, I thought it would be a good idea to examine some techniques for evaluating the performance of React Components.\n\nThis screencast covers a number of techniques for constructing components, but also shows how to evaluate performance objectively and make informed refactoring decisions.\n\n# Screencast Outline\n\n1. Introduction\n\n  * A Common UI Scenario for React Components -> Large Data Tables\n  * Developer Default: Google/Stack Overflow Driven Development\n  * The Quest for a pre-built Library\n\n2. Performance Goals\n\n  * Important Metrics: TTI (time to interactive), TTFMP (time to first meaningful paint)\n  * Setting a Frame Budget: (60fps / 16.7ms) might not always be feasible\n  * The Feedback Loop: Experiment, Evaluate\n\n3. React Development Patterns\n\n  * Start BIG: 1 component, 1 render method, then profile\n  * Decompose: limit the surface area of your component by thinking hard about props, then profile\n  * Optimize by:\n    * Reducing JS Execution: work the browser doesn't have to do doesn't need to be optimized\n    * Reducing Surface Area for Change: small components, limited surface area, small lists of props\n    * Keep `render` methods simple and _mostly_ static\n\n# Code\n\nhttps://github.com/davemo/react-performance-analysis"
}></pre></div><div><a href="/posts/2017-04-17-makefile-usability-tips.html">Makefile Usability Tips</a><pre><{
  "path": "app/posts/2017-04-17-makefile-usability-tips.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Makefile Usability Tips",
      "date": "2017-04-17"
    },
    "source": "\n> It has been but a [few short years](/build-automation-holy-war.png) since _web developers_ chose a side and took up arms in the holy war of <a href=\"https://en.wikipedia.org/wiki/Make_(software)\">build automation tools</a>; this is only one of [many](https://en.wikipedia.org/wiki/Editor_war) [wars](https://en.wikipedia.org/wiki/Browser_wars) that have been fought [countless times](https://en.wikipedia.org/wiki/Indent_style) since the dawn of computing. In the grim darkness of the far future, there is only war.\n\nMeh. War is tiresome and I have had enough of war. This post is about some small usability improvements you can add to your Makefiles if you are using Make. Let's dig in!\n\n# The Makefile\n\nMake has been around for a <a href=\"https://en.wikipedia.org/wiki/Make_(software)\">long time</a>. It has some neat features but it's not always the friendliest to neophytes. Imagine you have a new developer joining your team, and your project has a Makefile that looks something like this:\n\n```Makefile\nVERSION ?= $(shell cat VERSION)\n\n.PHONY: version clean bump release\n\nbuild:\n  @echo \"building...\"\n  # build the app here\n\nclean:\n  # rm -rf build\n\nrelease:\n  # bump\n  # make push -e VERSION=$(shell cat VERSION)\n\npush:\n  # push the build artifact at a given version somewhere\n\nversion:\n  # cat VERSION\n\nbump:\n  # using semver, bump the version by a major, minor or patch increment\n```\n\nAt first glance this Makefile isn't all that complicated but chances are your build automation process is composed of many more lines of code or even split into multiple places. The wise aged veteran developer on your team tells the new member \"to build this project just clone this repo and run `make`\" after which the new developer sees:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nbuilding...\n```\n\nNow, assuming new dev didn't encounter any snags with project setup and installing dependencies (hah! unlikely) this still doesn't present a great picture of how the project is assembled or the bits of the lifecycle that are involved at first glance. Let's see if we can improve this initial Makefile developer experience.\n\n## Step 1: Add a DEFAULT_GOAL\n\nIn Make semantics, _goals_ are targets that `make` should strive to update. The docs give us a nice [explanation of goals](https://www.gnu.org/software/make/manual/html_node/Goals.html) as well as some hints about how we can manage which goal is run first:\n\n> By default, the goal is the first target in the makefile (not counting targets that start with a period). Therefore, makefiles are usually written so that the first target is for compiling the entire program or programs they describe. If the first rule in the makefile has several targets, only the first target in the rule becomes the default goal, not the whole list. You can manage the selection of the default goal from within your makefile using the .DEFAULT_GOAL variable (see [Other Special Variables](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html#Special-Variables)).\n\nEven though the docs give us some informal conventions about the first target in our Makefile I think it _makes_ (heh) for a better experience if we add some sort of help target that spits out some information to the terminal. Make doesn't have any facility to display help messages like some [other build automation tools](https://rake.rubyforge.org/Rake/Application.html), but it won't be too hard to add one. First, let's add a default goal of help:\n\n```Makefile\n.DEFAULT_GOAL := help\n\nhelp:\n  @echo \"Welcome to the Project!\"\n```\n<caption>\n  <strong>Tip:</strong> prefixing a line in your make target with `@` suppresses output of that line to stdout.\n</caption>\n\n<br />With this in place our new developer sees the following:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nWelcome to the Project!\n```\n\nOk, this is a little more friendly but still not very useful. We can do better!\n\n## Step 2: Annotate Makefile Targets\n\nLet's update our Makefile to add helpful annotations to _some_ of our targets using comment blocks prefixed with `##`:\n\n```Makefile\nbuild: ## builds the application\n  @echo \"building...\"\n\nclean: ## gets you back to a clean working state\n  # rm -rf build\n\nrelease: bump ## bump the VERSION file, git tags, and push to github\n  # make push -e VERSION=$(shell cat VERSION)\n```\n\nThis annotation scheme works pretty well but doesn't buy us anything on its own, to make this truly useful we need to parse the Makefile, look for lines prefixed with `##` and format them in a pretty way and write them to `stdout`\n\n## Step 3: Parse Annotations\n\nMake includes a handy [list of special variables](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html#Special-Variables) that can be used for all sorts of handy things. In this case we can use the `MAKEFILE_LIST` variable along with `grep`, `sort` and `awk` to get a list of annotated targets and display them on `stdout` in a user-friendly way:\n\n```Makefile\nhelp:\n  @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n```\n<caption>\n  <strong>Tip: </strong>Wondering what the `help` target is doing? See this [explain shell](https://explainshell.com/explain?cmd=grep+-E+%27%5E%5Ba-zA-Z_-%5D%2B%3A.*%3F%23%23+.*%24%24%27+%24%28MAKEFILE_LIST%29+%7C+sort+%7C+awk+%27BEGIN+%7BFS+%3D+%22%3A.*%3F%23%23+%22%7D%3B+%7Bprintf+%22%5C033%5B36m%25-30s%5C033%5B0m+%25s%5Cn%22%2C+%24%241%2C+%24%242%7D%27).\n</caption>\n\n<br />With that in place our new developer would run `make` from the command-line and see:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nbuild                          builds the application\nclean                          gets you back to a clean working state\nrelease                        bump the VERSION file, git tags, and push to github\n```\n\nYay! This is a much nicer developer-experience than what we started with. To take it even further I might suggest annotating only a subset of tasks that are most commonly used.\n\n# Acknowledgements / Links\n\nThere are a few sources that come up when you google for \"self-documenting makefile\" along with a few different ways of solving this problem. I drew inspiration for this post mostly from [this marmelab entry](https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html), but felt like there were enough interesting points and general make tips added that it was worth another post.\n\nOther links you may find useful:\n\n- [Full Makefile as Gist](https://gist.github.com/davemo/c0462e8196289e0fb0210ee63ff02962)\n- [VERSION bump script as Gist](https://gist.github.com/davemo/88de90577a57698dd72d722bcfc44964)\n- [GNU Make](https://www.gnu.org/software/make/)\n- [Self Documenting Makefiles](https://www.cmcrossroads.com/print/article/self-documenting-makefiles)\n- [Explain Shell](https://explainshell.com)"
  },
  "attributes": {
    "title": "Makefile Usability Tips",
    "date": "2017-04-17"
  },
  "markdown": "\n> It has been but a [few short years](/build-automation-holy-war.png) since _web developers_ chose a side and took up arms in the holy war of <a href=\"https://en.wikipedia.org/wiki/Make_(software)\">build automation tools</a>; this is only one of [many](https://en.wikipedia.org/wiki/Editor_war) [wars](https://en.wikipedia.org/wiki/Browser_wars) that have been fought [countless times](https://en.wikipedia.org/wiki/Indent_style) since the dawn of computing. In the grim darkness of the far future, there is only war.\n\nMeh. War is tiresome and I have had enough of war. This post is about some small usability improvements you can add to your Makefiles if you are using Make. Let's dig in!\n\n# The Makefile\n\nMake has been around for a <a href=\"https://en.wikipedia.org/wiki/Make_(software)\">long time</a>. It has some neat features but it's not always the friendliest to neophytes. Imagine you have a new developer joining your team, and your project has a Makefile that looks something like this:\n\n```Makefile\nVERSION ?= $(shell cat VERSION)\n\n.PHONY: version clean bump release\n\nbuild:\n  @echo \"building...\"\n  # build the app here\n\nclean:\n  # rm -rf build\n\nrelease:\n  # bump\n  # make push -e VERSION=$(shell cat VERSION)\n\npush:\n  # push the build artifact at a given version somewhere\n\nversion:\n  # cat VERSION\n\nbump:\n  # using semver, bump the version by a major, minor or patch increment\n```\n\nAt first glance this Makefile isn't all that complicated but chances are your build automation process is composed of many more lines of code or even split into multiple places. The wise aged veteran developer on your team tells the new member \"to build this project just clone this repo and run `make`\" after which the new developer sees:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nbuilding...\n```\n\nNow, assuming new dev didn't encounter any snags with project setup and installing dependencies (hah! unlikely) this still doesn't present a great picture of how the project is assembled or the bits of the lifecycle that are involved at first glance. Let's see if we can improve this initial Makefile developer experience.\n\n## Step 1: Add a DEFAULT_GOAL\n\nIn Make semantics, _goals_ are targets that `make` should strive to update. The docs give us a nice [explanation of goals](https://www.gnu.org/software/make/manual/html_node/Goals.html) as well as some hints about how we can manage which goal is run first:\n\n> By default, the goal is the first target in the makefile (not counting targets that start with a period). Therefore, makefiles are usually written so that the first target is for compiling the entire program or programs they describe. If the first rule in the makefile has several targets, only the first target in the rule becomes the default goal, not the whole list. You can manage the selection of the default goal from within your makefile using the .DEFAULT_GOAL variable (see [Other Special Variables](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html#Special-Variables)).\n\nEven though the docs give us some informal conventions about the first target in our Makefile I think it _makes_ (heh) for a better experience if we add some sort of help target that spits out some information to the terminal. Make doesn't have any facility to display help messages like some [other build automation tools](https://rake.rubyforge.org/Rake/Application.html), but it won't be too hard to add one. First, let's add a default goal of help:\n\n```Makefile\n.DEFAULT_GOAL := help\n\nhelp:\n  @echo \"Welcome to the Project!\"\n```\n<caption>\n  <strong>Tip:</strong> prefixing a line in your make target with `@` suppresses output of that line to stdout.\n</caption>\n\n<br />With this in place our new developer sees the following:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nWelcome to the Project!\n```\n\nOk, this is a little more friendly but still not very useful. We can do better!\n\n## Step 2: Annotate Makefile Targets\n\nLet's update our Makefile to add helpful annotations to _some_ of our targets using comment blocks prefixed with `##`:\n\n```Makefile\nbuild: ## builds the application\n  @echo \"building...\"\n\nclean: ## gets you back to a clean working state\n  # rm -rf build\n\nrelease: bump ## bump the VERSION file, git tags, and push to github\n  # make push -e VERSION=$(shell cat VERSION)\n```\n\nThis annotation scheme works pretty well but doesn't buy us anything on its own, to make this truly useful we need to parse the Makefile, look for lines prefixed with `##` and format them in a pretty way and write them to `stdout`\n\n## Step 3: Parse Annotations\n\nMake includes a handy [list of special variables](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html#Special-Variables) that can be used for all sorts of handy things. In this case we can use the `MAKEFILE_LIST` variable along with `grep`, `sort` and `awk` to get a list of annotated targets and display them on `stdout` in a user-friendly way:\n\n```Makefile\nhelp:\n  @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n```\n<caption>\n  <strong>Tip: </strong>Wondering what the `help` target is doing? See this [explain shell](https://explainshell.com/explain?cmd=grep+-E+%27%5E%5Ba-zA-Z_-%5D%2B%3A.*%3F%23%23+.*%24%24%27+%24%28MAKEFILE_LIST%29+%7C+sort+%7C+awk+%27BEGIN+%7BFS+%3D+%22%3A.*%3F%23%23+%22%7D%3B+%7Bprintf+%22%5C033%5B36m%25-30s%5C033%5B0m+%25s%5Cn%22%2C+%24%241%2C+%24%242%7D%27).\n</caption>\n\n<br />With that in place our new developer would run `make` from the command-line and see:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nbuild                          builds the application\nclean                          gets you back to a clean working state\nrelease                        bump the VERSION file, git tags, and push to github\n```\n\nYay! This is a much nicer developer-experience than what we started with. To take it even further I might suggest annotating only a subset of tasks that are most commonly used.\n\n# Acknowledgements / Links\n\nThere are a few sources that come up when you google for \"self-documenting makefile\" along with a few different ways of solving this problem. I drew inspiration for this post mostly from [this marmelab entry](https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html), but felt like there were enough interesting points and general make tips added that it was worth another post.\n\nOther links you may find useful:\n\n- [Full Makefile as Gist](https://gist.github.com/davemo/c0462e8196289e0fb0210ee63ff02962)\n- [VERSION bump script as Gist](https://gist.github.com/davemo/88de90577a57698dd72d722bcfc44964)\n- [GNU Make](https://www.gnu.org/software/make/)\n- [Self Documenting Makefiles](https://www.cmcrossroads.com/print/article/self-documenting-makefiles)\n- [Explain Shell](https://explainshell.com)"
}></{
  "path": "app/posts/2017-04-17-makefile-usability-tips.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Makefile Usability Tips",
      "date": "2017-04-17"
    },
    "source": "\n> It has been but a [few short years](/build-automation-holy-war.png) since _web developers_ chose a side and took up arms in the holy war of <a href=\"https://en.wikipedia.org/wiki/Make_(software)\">build automation tools</a>; this is only one of [many](https://en.wikipedia.org/wiki/Editor_war) [wars](https://en.wikipedia.org/wiki/Browser_wars) that have been fought [countless times](https://en.wikipedia.org/wiki/Indent_style) since the dawn of computing. In the grim darkness of the far future, there is only war.\n\nMeh. War is tiresome and I have had enough of war. This post is about some small usability improvements you can add to your Makefiles if you are using Make. Let's dig in!\n\n# The Makefile\n\nMake has been around for a <a href=\"https://en.wikipedia.org/wiki/Make_(software)\">long time</a>. It has some neat features but it's not always the friendliest to neophytes. Imagine you have a new developer joining your team, and your project has a Makefile that looks something like this:\n\n```Makefile\nVERSION ?= $(shell cat VERSION)\n\n.PHONY: version clean bump release\n\nbuild:\n  @echo \"building...\"\n  # build the app here\n\nclean:\n  # rm -rf build\n\nrelease:\n  # bump\n  # make push -e VERSION=$(shell cat VERSION)\n\npush:\n  # push the build artifact at a given version somewhere\n\nversion:\n  # cat VERSION\n\nbump:\n  # using semver, bump the version by a major, minor or patch increment\n```\n\nAt first glance this Makefile isn't all that complicated but chances are your build automation process is composed of many more lines of code or even split into multiple places. The wise aged veteran developer on your team tells the new member \"to build this project just clone this repo and run `make`\" after which the new developer sees:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nbuilding...\n```\n\nNow, assuming new dev didn't encounter any snags with project setup and installing dependencies (hah! unlikely) this still doesn't present a great picture of how the project is assembled or the bits of the lifecycle that are involved at first glance. Let's see if we can improve this initial Makefile developer experience.\n\n## Step 1: Add a DEFAULT_GOAL\n\nIn Make semantics, _goals_ are targets that `make` should strive to update. The docs give us a nice [explanation of goals](https://www.gnu.org/software/make/manual/html_node/Goals.html) as well as some hints about how we can manage which goal is run first:\n\n> By default, the goal is the first target in the makefile (not counting targets that start with a period). Therefore, makefiles are usually written so that the first target is for compiling the entire program or programs they describe. If the first rule in the makefile has several targets, only the first target in the rule becomes the default goal, not the whole list. You can manage the selection of the default goal from within your makefile using the .DEFAULT_GOAL variable (see [Other Special Variables](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html#Special-Variables)).\n\nEven though the docs give us some informal conventions about the first target in our Makefile I think it _makes_ (heh) for a better experience if we add some sort of help target that spits out some information to the terminal. Make doesn't have any facility to display help messages like some [other build automation tools](https://rake.rubyforge.org/Rake/Application.html), but it won't be too hard to add one. First, let's add a default goal of help:\n\n```Makefile\n.DEFAULT_GOAL := help\n\nhelp:\n  @echo \"Welcome to the Project!\"\n```\n<caption>\n  <strong>Tip:</strong> prefixing a line in your make target with `@` suppresses output of that line to stdout.\n</caption>\n\n<br />With this in place our new developer sees the following:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nWelcome to the Project!\n```\n\nOk, this is a little more friendly but still not very useful. We can do better!\n\n## Step 2: Annotate Makefile Targets\n\nLet's update our Makefile to add helpful annotations to _some_ of our targets using comment blocks prefixed with `##`:\n\n```Makefile\nbuild: ## builds the application\n  @echo \"building...\"\n\nclean: ## gets you back to a clean working state\n  # rm -rf build\n\nrelease: bump ## bump the VERSION file, git tags, and push to github\n  # make push -e VERSION=$(shell cat VERSION)\n```\n\nThis annotation scheme works pretty well but doesn't buy us anything on its own, to make this truly useful we need to parse the Makefile, look for lines prefixed with `##` and format them in a pretty way and write them to `stdout`\n\n## Step 3: Parse Annotations\n\nMake includes a handy [list of special variables](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html#Special-Variables) that can be used for all sorts of handy things. In this case we can use the `MAKEFILE_LIST` variable along with `grep`, `sort` and `awk` to get a list of annotated targets and display them on `stdout` in a user-friendly way:\n\n```Makefile\nhelp:\n  @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n```\n<caption>\n  <strong>Tip: </strong>Wondering what the `help` target is doing? See this [explain shell](https://explainshell.com/explain?cmd=grep+-E+%27%5E%5Ba-zA-Z_-%5D%2B%3A.*%3F%23%23+.*%24%24%27+%24%28MAKEFILE_LIST%29+%7C+sort+%7C+awk+%27BEGIN+%7BFS+%3D+%22%3A.*%3F%23%23+%22%7D%3B+%7Bprintf+%22%5C033%5B36m%25-30s%5C033%5B0m+%25s%5Cn%22%2C+%24%241%2C+%24%242%7D%27).\n</caption>\n\n<br />With that in place our new developer would run `make` from the command-line and see:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nbuild                          builds the application\nclean                          gets you back to a clean working state\nrelease                        bump the VERSION file, git tags, and push to github\n```\n\nYay! This is a much nicer developer-experience than what we started with. To take it even further I might suggest annotating only a subset of tasks that are most commonly used.\n\n# Acknowledgements / Links\n\nThere are a few sources that come up when you google for \"self-documenting makefile\" along with a few different ways of solving this problem. I drew inspiration for this post mostly from [this marmelab entry](https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html), but felt like there were enough interesting points and general make tips added that it was worth another post.\n\nOther links you may find useful:\n\n- [Full Makefile as Gist](https://gist.github.com/davemo/c0462e8196289e0fb0210ee63ff02962)\n- [VERSION bump script as Gist](https://gist.github.com/davemo/88de90577a57698dd72d722bcfc44964)\n- [GNU Make](https://www.gnu.org/software/make/)\n- [Self Documenting Makefiles](https://www.cmcrossroads.com/print/article/self-documenting-makefiles)\n- [Explain Shell](https://explainshell.com)"
  },
  "attributes": {
    "title": "Makefile Usability Tips",
    "date": "2017-04-17"
  },
  "markdown": "\n> It has been but a [few short years](/build-automation-holy-war.png) since _web developers_ chose a side and took up arms in the holy war of <a href=\"https://en.wikipedia.org/wiki/Make_(software)\">build automation tools</a>; this is only one of [many](https://en.wikipedia.org/wiki/Editor_war) [wars](https://en.wikipedia.org/wiki/Browser_wars) that have been fought [countless times](https://en.wikipedia.org/wiki/Indent_style) since the dawn of computing. In the grim darkness of the far future, there is only war.\n\nMeh. War is tiresome and I have had enough of war. This post is about some small usability improvements you can add to your Makefiles if you are using Make. Let's dig in!\n\n# The Makefile\n\nMake has been around for a <a href=\"https://en.wikipedia.org/wiki/Make_(software)\">long time</a>. It has some neat features but it's not always the friendliest to neophytes. Imagine you have a new developer joining your team, and your project has a Makefile that looks something like this:\n\n```Makefile\nVERSION ?= $(shell cat VERSION)\n\n.PHONY: version clean bump release\n\nbuild:\n  @echo \"building...\"\n  # build the app here\n\nclean:\n  # rm -rf build\n\nrelease:\n  # bump\n  # make push -e VERSION=$(shell cat VERSION)\n\npush:\n  # push the build artifact at a given version somewhere\n\nversion:\n  # cat VERSION\n\nbump:\n  # using semver, bump the version by a major, minor or patch increment\n```\n\nAt first glance this Makefile isn't all that complicated but chances are your build automation process is composed of many more lines of code or even split into multiple places. The wise aged veteran developer on your team tells the new member \"to build this project just clone this repo and run `make`\" after which the new developer sees:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nbuilding...\n```\n\nNow, assuming new dev didn't encounter any snags with project setup and installing dependencies (hah! unlikely) this still doesn't present a great picture of how the project is assembled or the bits of the lifecycle that are involved at first glance. Let's see if we can improve this initial Makefile developer experience.\n\n## Step 1: Add a DEFAULT_GOAL\n\nIn Make semantics, _goals_ are targets that `make` should strive to update. The docs give us a nice [explanation of goals](https://www.gnu.org/software/make/manual/html_node/Goals.html) as well as some hints about how we can manage which goal is run first:\n\n> By default, the goal is the first target in the makefile (not counting targets that start with a period). Therefore, makefiles are usually written so that the first target is for compiling the entire program or programs they describe. If the first rule in the makefile has several targets, only the first target in the rule becomes the default goal, not the whole list. You can manage the selection of the default goal from within your makefile using the .DEFAULT_GOAL variable (see [Other Special Variables](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html#Special-Variables)).\n\nEven though the docs give us some informal conventions about the first target in our Makefile I think it _makes_ (heh) for a better experience if we add some sort of help target that spits out some information to the terminal. Make doesn't have any facility to display help messages like some [other build automation tools](https://rake.rubyforge.org/Rake/Application.html), but it won't be too hard to add one. First, let's add a default goal of help:\n\n```Makefile\n.DEFAULT_GOAL := help\n\nhelp:\n  @echo \"Welcome to the Project!\"\n```\n<caption>\n  <strong>Tip:</strong> prefixing a line in your make target with `@` suppresses output of that line to stdout.\n</caption>\n\n<br />With this in place our new developer sees the following:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nWelcome to the Project!\n```\n\nOk, this is a little more friendly but still not very useful. We can do better!\n\n## Step 2: Annotate Makefile Targets\n\nLet's update our Makefile to add helpful annotations to _some_ of our targets using comment blocks prefixed with `##`:\n\n```Makefile\nbuild: ## builds the application\n  @echo \"building...\"\n\nclean: ## gets you back to a clean working state\n  # rm -rf build\n\nrelease: bump ## bump the VERSION file, git tags, and push to github\n  # make push -e VERSION=$(shell cat VERSION)\n```\n\nThis annotation scheme works pretty well but doesn't buy us anything on its own, to make this truly useful we need to parse the Makefile, look for lines prefixed with `##` and format them in a pretty way and write them to `stdout`\n\n## Step 3: Parse Annotations\n\nMake includes a handy [list of special variables](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html#Special-Variables) that can be used for all sorts of handy things. In this case we can use the `MAKEFILE_LIST` variable along with `grep`, `sort` and `awk` to get a list of annotated targets and display them on `stdout` in a user-friendly way:\n\n```Makefile\nhelp:\n  @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n```\n<caption>\n  <strong>Tip: </strong>Wondering what the `help` target is doing? See this [explain shell](https://explainshell.com/explain?cmd=grep+-E+%27%5E%5Ba-zA-Z_-%5D%2B%3A.*%3F%23%23+.*%24%24%27+%24%28MAKEFILE_LIST%29+%7C+sort+%7C+awk+%27BEGIN+%7BFS+%3D+%22%3A.*%3F%23%23+%22%7D%3B+%7Bprintf+%22%5C033%5B36m%25-30s%5C033%5B0m+%25s%5Cn%22%2C+%24%241%2C+%24%242%7D%27).\n</caption>\n\n<br />With that in place our new developer would run `make` from the command-line and see:\n\n```shell\nneophyte@newbie:~/code/project\n$ make\nbuild                          builds the application\nclean                          gets you back to a clean working state\nrelease                        bump the VERSION file, git tags, and push to github\n```\n\nYay! This is a much nicer developer-experience than what we started with. To take it even further I might suggest annotating only a subset of tasks that are most commonly used.\n\n# Acknowledgements / Links\n\nThere are a few sources that come up when you google for \"self-documenting makefile\" along with a few different ways of solving this problem. I drew inspiration for this post mostly from [this marmelab entry](https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html), but felt like there were enough interesting points and general make tips added that it was worth another post.\n\nOther links you may find useful:\n\n- [Full Makefile as Gist](https://gist.github.com/davemo/c0462e8196289e0fb0210ee63ff02962)\n- [VERSION bump script as Gist](https://gist.github.com/davemo/88de90577a57698dd72d722bcfc44964)\n- [GNU Make](https://www.gnu.org/software/make/)\n- [Self Documenting Makefiles](https://www.cmcrossroads.com/print/article/self-documenting-makefiles)\n- [Explain Shell](https://explainshell.com)"
}></pre></div><div><a href="/posts/2017-03-07-advanced-directives-with-angular-js-part-2.html">Advanced Directives with AngularJS (Part 2)</a><pre><{
  "path": "app/posts/2017-03-07-advanced-directives-with-angular-js-part-2.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Advanced Directives with AngularJS (Part 2)",
      "date": "2017-03-07"
    },
    "source": "\n> Two years in the making; just released and fresh off the presses it's yet another screencast covering everybodys favorite enterprise JS framework: Angular JS!\n\n<iframe src=\"https://www.youtube.com/embed/4zG8SfucUzg?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIn all seriousness, I had a hard time considering whether or not to publish this screencast because I found myself questioning whether the content would still be relevant almost two years later. However, in revisiting all the comments and questions about the alluded-to \"part 2\" from the first video I felt like there were still valuable things to talk about. At the heart of this screencast is discussion around what I consider **one of the most valuable features of angular**: the ability to use custom elements as a domain-specific language (DSL) to ease the **wrapping and use of 3rd party libraries**.\n\nThis screencast continues the examination of some of the advanced features in Angular from [Advanced Directives with Angular JS](https://blog.davemo.com/posts/2015-02-13-advanced-directives-with-angular-js) and expands by tackling some of the issues raised in Part 1 including:\n\n- bugfixes for the inline editor\n- auto toggling of editing state using CSS content generation and the angular $scope\n- leveraging the DSL from the first screencast as an interface to a 3rd party JavaScript data grid component: js-grid\n\nIf you're interested in some more context prior to watching, check out my other [angular screencasts](https://www.youtube.com/c/DavidMosher) and an earlier post on the [power of web components as abstractions](https://blog.davemo.com/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks).\n\nHopefully the next screencast series won't take 2 years to complete ;)\n\n# Code\n\n- bugfix: don’t re-add and compile editors https://github.com/davemo/advanced-directives-with-angular-js/commit/4efc9edfacc3cee791f155d52bf517a7ab251586\n- feature: swap arrow on editor state https://github.com/davemo/advanced-directives-with-angular-js/commit/2f046f51dda4b54891353b7ec047b3a6e381792d\n- feature: leverage a 3rd party lib using the same DSL https://github.com/davemo/advanced-directives-with-angular-js/pull/2/files\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
  },
  "attributes": {
    "title": "Advanced Directives with AngularJS (Part 2)",
    "date": "2017-03-07"
  },
  "markdown": "\n> Two years in the making; just released and fresh off the presses it's yet another screencast covering everybodys favorite enterprise JS framework: Angular JS!\n\n<iframe src=\"https://www.youtube.com/embed/4zG8SfucUzg?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIn all seriousness, I had a hard time considering whether or not to publish this screencast because I found myself questioning whether the content would still be relevant almost two years later. However, in revisiting all the comments and questions about the alluded-to \"part 2\" from the first video I felt like there were still valuable things to talk about. At the heart of this screencast is discussion around what I consider **one of the most valuable features of angular**: the ability to use custom elements as a domain-specific language (DSL) to ease the **wrapping and use of 3rd party libraries**.\n\nThis screencast continues the examination of some of the advanced features in Angular from [Advanced Directives with Angular JS](https://blog.davemo.com/posts/2015-02-13-advanced-directives-with-angular-js) and expands by tackling some of the issues raised in Part 1 including:\n\n- bugfixes for the inline editor\n- auto toggling of editing state using CSS content generation and the angular $scope\n- leveraging the DSL from the first screencast as an interface to a 3rd party JavaScript data grid component: js-grid\n\nIf you're interested in some more context prior to watching, check out my other [angular screencasts](https://www.youtube.com/c/DavidMosher) and an earlier post on the [power of web components as abstractions](https://blog.davemo.com/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks).\n\nHopefully the next screencast series won't take 2 years to complete ;)\n\n# Code\n\n- bugfix: don’t re-add and compile editors https://github.com/davemo/advanced-directives-with-angular-js/commit/4efc9edfacc3cee791f155d52bf517a7ab251586\n- feature: swap arrow on editor state https://github.com/davemo/advanced-directives-with-angular-js/commit/2f046f51dda4b54891353b7ec047b3a6e381792d\n- feature: leverage a 3rd party lib using the same DSL https://github.com/davemo/advanced-directives-with-angular-js/pull/2/files\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
}></{
  "path": "app/posts/2017-03-07-advanced-directives-with-angular-js-part-2.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Advanced Directives with AngularJS (Part 2)",
      "date": "2017-03-07"
    },
    "source": "\n> Two years in the making; just released and fresh off the presses it's yet another screencast covering everybodys favorite enterprise JS framework: Angular JS!\n\n<iframe src=\"https://www.youtube.com/embed/4zG8SfucUzg?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIn all seriousness, I had a hard time considering whether or not to publish this screencast because I found myself questioning whether the content would still be relevant almost two years later. However, in revisiting all the comments and questions about the alluded-to \"part 2\" from the first video I felt like there were still valuable things to talk about. At the heart of this screencast is discussion around what I consider **one of the most valuable features of angular**: the ability to use custom elements as a domain-specific language (DSL) to ease the **wrapping and use of 3rd party libraries**.\n\nThis screencast continues the examination of some of the advanced features in Angular from [Advanced Directives with Angular JS](https://blog.davemo.com/posts/2015-02-13-advanced-directives-with-angular-js) and expands by tackling some of the issues raised in Part 1 including:\n\n- bugfixes for the inline editor\n- auto toggling of editing state using CSS content generation and the angular $scope\n- leveraging the DSL from the first screencast as an interface to a 3rd party JavaScript data grid component: js-grid\n\nIf you're interested in some more context prior to watching, check out my other [angular screencasts](https://www.youtube.com/c/DavidMosher) and an earlier post on the [power of web components as abstractions](https://blog.davemo.com/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks).\n\nHopefully the next screencast series won't take 2 years to complete ;)\n\n# Code\n\n- bugfix: don’t re-add and compile editors https://github.com/davemo/advanced-directives-with-angular-js/commit/4efc9edfacc3cee791f155d52bf517a7ab251586\n- feature: swap arrow on editor state https://github.com/davemo/advanced-directives-with-angular-js/commit/2f046f51dda4b54891353b7ec047b3a6e381792d\n- feature: leverage a 3rd party lib using the same DSL https://github.com/davemo/advanced-directives-with-angular-js/pull/2/files\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
  },
  "attributes": {
    "title": "Advanced Directives with AngularJS (Part 2)",
    "date": "2017-03-07"
  },
  "markdown": "\n> Two years in the making; just released and fresh off the presses it's yet another screencast covering everybodys favorite enterprise JS framework: Angular JS!\n\n<iframe src=\"https://www.youtube.com/embed/4zG8SfucUzg?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIn all seriousness, I had a hard time considering whether or not to publish this screencast because I found myself questioning whether the content would still be relevant almost two years later. However, in revisiting all the comments and questions about the alluded-to \"part 2\" from the first video I felt like there were still valuable things to talk about. At the heart of this screencast is discussion around what I consider **one of the most valuable features of angular**: the ability to use custom elements as a domain-specific language (DSL) to ease the **wrapping and use of 3rd party libraries**.\n\nThis screencast continues the examination of some of the advanced features in Angular from [Advanced Directives with Angular JS](https://blog.davemo.com/posts/2015-02-13-advanced-directives-with-angular-js) and expands by tackling some of the issues raised in Part 1 including:\n\n- bugfixes for the inline editor\n- auto toggling of editing state using CSS content generation and the angular $scope\n- leveraging the DSL from the first screencast as an interface to a 3rd party JavaScript data grid component: js-grid\n\nIf you're interested in some more context prior to watching, check out my other [angular screencasts](https://www.youtube.com/c/DavidMosher) and an earlier post on the [power of web components as abstractions](https://blog.davemo.com/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks).\n\nHopefully the next screencast series won't take 2 years to complete ;)\n\n# Code\n\n- bugfix: don’t re-add and compile editors https://github.com/davemo/advanced-directives-with-angular-js/commit/4efc9edfacc3cee791f155d52bf517a7ab251586\n- feature: swap arrow on editor state https://github.com/davemo/advanced-directives-with-angular-js/commit/2f046f51dda4b54891353b7ec047b3a6e381792d\n- feature: leverage a 3rd party lib using the same DSL https://github.com/davemo/advanced-directives-with-angular-js/pull/2/files\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
}></pre></div><div><a href="/posts/2016-12-30-reasons-not-to-quit-your-job.html">Reasons not to quit your job</a><pre><{
  "path": "app/posts/2016-12-30-reasons-not-to-quit-your-job.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Reasons not to quit your job",
      "date": "2016-12-30"
    },
    "source": "\n> 2016 was a year of ups and (if you agree with many of the social media channels in the last month) a significantly larger number of downs. I'm not sure  _exactly_ what it is about this time of year that causes us to reflect so much more than the rest of the year; I suspect it _mostly_ has to do with a heightened sense of awareness as we approach boundaries.\n\nAs children, we know they are there because our parents tell us and we frequently come close to them often by virtue of desiring to push past to see what is beyond. As parents, we know they are there because we create them; often intending to protect our children from things that are dangerous or to set parameters for healthy  age-appropriate interaction. As software developers we encounter [boundaries](https://www.destroyallsoftware.com/talks/boundaries) in tests, the design of our code as it relates to components in a system, API's, the list goes on and on. Being in constant consideration of boundaries, whether consciously or subconsciously, has the side-effect of switching our brain into analysis and reflection mode.\n\nI recently had some friends reach out for advice as they were contemplating a transition at a critical boundary: quitting their job.\n\n> \"It's time for a change\"\n\n...\n\n> \"I've been restless but I'm trying to be cautious\"\n\nThese exchanges, coupled with the time of year and my brain switching into reflection mode, have had me considering reasons I left jobs in the past. The more I thought about it the more my brain kept telling me that those reasons were often _not_ valid reasons to justify leaving. I wrestled with it and tried to move onto other thoughts but it just kept nagging at me; this is usually an indication I need to deal with those thoughts in a positive way. So, here I am attempting to impart some wisdom about reasons _not_ to quit your job in 2017 (but mostly just typing as an exercise to free my brain up to move onto other things!) ;)\n\n# Technology\n\nOn April 3rd, 2014 I wrote [some of the reasons](https://blog.davemo.com/posts/2014-04-03-the-magnetic-core-philosophy.html) I left the last job I was at. I've re-read that post a dozen times trying to mine some fragments of wisdom, mostly to attempt to justify the decisions at that time. The only conclusions I've come up with at this point are: there are a lot of emotions in my writing that stemmed _mainly_ from too much focus on Technology as one of the reasons I quit.\n\nTechnology is seductive; it attempts to woo us through flashy demos from paid evangelists or conference talks from influential heroes. Technology is like the trench-coat wearing crook on the street corner who promises us the Rolex and ends up delivering a cheap imitation. When the tech-stack you work with (or _want_ to work with) becomes the justification for a career change it has the potential to snowball into a full on addiction to newness that sets your brain up for a dependence on switching tech in the same way a drug addict depends on their narcotic of choice.\n\nThe truth is that most systems that we work on move slowly towards [disorder and complexity](https://en.wikipedia.org/wiki/Software_entropy), so it is no surprise that the promise of a fresh-start in a new technology stack is appealing. An entire generation of software developers have become so accustomed to quitting their job based on technology that I suspect the coming decades will yield a significant need for people who have experience dealing with systems over a long period of time. If we don't deal with our addiction to newness, the recruiter pitch of \"Junior Developer Wanted, 5 years experience Node.JS/Rails/...\" that we so frequently deride will turn into \"Senior Developer Wanted, 10 years experience dealing with software entropy\" and there will be no one to answer the call.\n\nDon't get sucked into the new tech cycle; learn to embrace what you're working on now and strive to work the best with the technology constraints you've been handed.\n\n# Scale\n\nSo, you've thought considerably about your current job and ruled out technology as the main reason for leaving. In fact, you're sticking with the tried and true tech-stack you've always known, but there's just been that nagging feeling that you'd be so much better off if you could experience working with your stack at a larger scale. Oh to be able to understand the constraints of systems at an order-of-magnitude or two beyond where you are working now; that's the ticket!\n\nScale is subtle; on the surface it promises a similar thing to the tech-stack switch: an opportunity to learn new things that your current scale of operations can't teach you. Chances are you will probably actually learn some new technical things by increasing scale; the reality is that we tend to focus more on the _technical_ and less on the _human_ side of software development which often affects increases in scale much more. In his book, [Predictable Success](https://www.predictablesuccess.com/books/predictable-success/), Les McKeown gives some wisdom about how scale affects success in an operation:\n\n> Predictable Success is defined as one of the seven stages of organizational development. It can be attained by any organization or group that acts as a human machine, well-oiled, working in concert, not without challenge, but focused and \"in the zone\" where growth is attainable _and_ sustainable. It is not about size or the age of an organization. It has nothing to do with resources, culture or industry.\n\n![The Whole Picture of Organizational Development according to Predicable Success](/img/reasons-not-to-quit-your-job/predictable.success.whole.picture.png)\n\nI particularly like his focus on the \"human\" factors and exclusion of the traditionally technical things we tend to focus on. While the book is targeted towards business growth and the reasons why companies tend to fail, it can be broadly applied to _any_ group or organization (including software development orgs). Ask the following questions about the organization you're contemplating joining:\n\n* What [stage of organizational development](/img/reasons-not-to-quit-your-job/predictable.success.whole.picture.png) are they in?\n* Can I really grow the way I want to there, not just technically but also in my capacity as a human?\n* Will the scale inhibit or promote my growth?\n* What potential problems will exist at the new operating scale?\n\nIn my experience working as a consultant the only constant I've observed is that the same problems (and the same trend towards entropy) exist regardless of the scale of the company and how they use their technology.\n\nThink hard about using scale as justification for quitting your job; chances are you haven't considered the _human_ factors involved.\n\n# Adversity\n\nRuling out both scale and technology as reasons for quitting a job is great, but to be honest they aren't the most common reasons I've quit in the past. Typically that honor is reserved for a more sinister and damaging character-trait: an inability to handle adversity.\n\nAdversity is double-edged; it shows us the best _and_ worst of ourselves, sometimes at the same time! If I take a step back and examine times when I left jobs because things just got too challenging I truly feel like there was _always_ an opportunity to overcome _in spite of_ the challenging situation and emerge a stronger human. How we respond to challenges in our workplace says a lot about our character:\n\n![Calvin Builds Character Shoveling Snow](/img/reasons-not-to-quit-your-job/calvin.character.building.png)\n\n![Calvin Builds Character Eating Dinner](/img/reasons-not-to-quit-your-job/calvin.character.building.2.gif)\n\n![Calvin Builds Character Being Cold (and Frugal)](/img/reasons-not-to-quit-your-job/calvin.character.building.3.gif)\n\nBefore you quit your job because it's just \"too damned hard\" I would encourage you to take a moment and step outside yourself; reflect on the situation and the facts -- [take the emotion out of it](https://www.vitalsmarts.com/crucialskills/2009/04/how-to-control-your-emotion/) and be objective.\n\nIf you can turn a challenging situation from a painful pity-party into an opportunity to conquer and emerge better you will be amazed at what you can come through.\n\n# Still Ready to Quit?\n\nThere are valid reasons to quit your job, but I think we tend to dwell on them far too often before considering the reasons _not_ to. My hope for you at the end of 2016 is that as you approach the boundary and transition leading into 2017 that you would be prompted to introspect and reflect on what it is you truly want. Set some goals, list some objectives for your life and above all ask yourself some tough questions before throwing in the towel; as a wise friend of mine once said:\n\n> If the grass is greener on the other side, then you'd better water your own lawn.\n"
  },
  "attributes": {
    "title": "Reasons not to quit your job",
    "date": "2016-12-30"
  },
  "markdown": "\n> 2016 was a year of ups and (if you agree with many of the social media channels in the last month) a significantly larger number of downs. I'm not sure  _exactly_ what it is about this time of year that causes us to reflect so much more than the rest of the year; I suspect it _mostly_ has to do with a heightened sense of awareness as we approach boundaries.\n\nAs children, we know they are there because our parents tell us and we frequently come close to them often by virtue of desiring to push past to see what is beyond. As parents, we know they are there because we create them; often intending to protect our children from things that are dangerous or to set parameters for healthy  age-appropriate interaction. As software developers we encounter [boundaries](https://www.destroyallsoftware.com/talks/boundaries) in tests, the design of our code as it relates to components in a system, API's, the list goes on and on. Being in constant consideration of boundaries, whether consciously or subconsciously, has the side-effect of switching our brain into analysis and reflection mode.\n\nI recently had some friends reach out for advice as they were contemplating a transition at a critical boundary: quitting their job.\n\n> \"It's time for a change\"\n\n...\n\n> \"I've been restless but I'm trying to be cautious\"\n\nThese exchanges, coupled with the time of year and my brain switching into reflection mode, have had me considering reasons I left jobs in the past. The more I thought about it the more my brain kept telling me that those reasons were often _not_ valid reasons to justify leaving. I wrestled with it and tried to move onto other thoughts but it just kept nagging at me; this is usually an indication I need to deal with those thoughts in a positive way. So, here I am attempting to impart some wisdom about reasons _not_ to quit your job in 2017 (but mostly just typing as an exercise to free my brain up to move onto other things!) ;)\n\n# Technology\n\nOn April 3rd, 2014 I wrote [some of the reasons](https://blog.davemo.com/posts/2014-04-03-the-magnetic-core-philosophy.html) I left the last job I was at. I've re-read that post a dozen times trying to mine some fragments of wisdom, mostly to attempt to justify the decisions at that time. The only conclusions I've come up with at this point are: there are a lot of emotions in my writing that stemmed _mainly_ from too much focus on Technology as one of the reasons I quit.\n\nTechnology is seductive; it attempts to woo us through flashy demos from paid evangelists or conference talks from influential heroes. Technology is like the trench-coat wearing crook on the street corner who promises us the Rolex and ends up delivering a cheap imitation. When the tech-stack you work with (or _want_ to work with) becomes the justification for a career change it has the potential to snowball into a full on addiction to newness that sets your brain up for a dependence on switching tech in the same way a drug addict depends on their narcotic of choice.\n\nThe truth is that most systems that we work on move slowly towards [disorder and complexity](https://en.wikipedia.org/wiki/Software_entropy), so it is no surprise that the promise of a fresh-start in a new technology stack is appealing. An entire generation of software developers have become so accustomed to quitting their job based on technology that I suspect the coming decades will yield a significant need for people who have experience dealing with systems over a long period of time. If we don't deal with our addiction to newness, the recruiter pitch of \"Junior Developer Wanted, 5 years experience Node.JS/Rails/...\" that we so frequently deride will turn into \"Senior Developer Wanted, 10 years experience dealing with software entropy\" and there will be no one to answer the call.\n\nDon't get sucked into the new tech cycle; learn to embrace what you're working on now and strive to work the best with the technology constraints you've been handed.\n\n# Scale\n\nSo, you've thought considerably about your current job and ruled out technology as the main reason for leaving. In fact, you're sticking with the tried and true tech-stack you've always known, but there's just been that nagging feeling that you'd be so much better off if you could experience working with your stack at a larger scale. Oh to be able to understand the constraints of systems at an order-of-magnitude or two beyond where you are working now; that's the ticket!\n\nScale is subtle; on the surface it promises a similar thing to the tech-stack switch: an opportunity to learn new things that your current scale of operations can't teach you. Chances are you will probably actually learn some new technical things by increasing scale; the reality is that we tend to focus more on the _technical_ and less on the _human_ side of software development which often affects increases in scale much more. In his book, [Predictable Success](https://www.predictablesuccess.com/books/predictable-success/), Les McKeown gives some wisdom about how scale affects success in an operation:\n\n> Predictable Success is defined as one of the seven stages of organizational development. It can be attained by any organization or group that acts as a human machine, well-oiled, working in concert, not without challenge, but focused and \"in the zone\" where growth is attainable _and_ sustainable. It is not about size or the age of an organization. It has nothing to do with resources, culture or industry.\n\n![The Whole Picture of Organizational Development according to Predicable Success](/img/reasons-not-to-quit-your-job/predictable.success.whole.picture.png)\n\nI particularly like his focus on the \"human\" factors and exclusion of the traditionally technical things we tend to focus on. While the book is targeted towards business growth and the reasons why companies tend to fail, it can be broadly applied to _any_ group or organization (including software development orgs). Ask the following questions about the organization you're contemplating joining:\n\n* What [stage of organizational development](/img/reasons-not-to-quit-your-job/predictable.success.whole.picture.png) are they in?\n* Can I really grow the way I want to there, not just technically but also in my capacity as a human?\n* Will the scale inhibit or promote my growth?\n* What potential problems will exist at the new operating scale?\n\nIn my experience working as a consultant the only constant I've observed is that the same problems (and the same trend towards entropy) exist regardless of the scale of the company and how they use their technology.\n\nThink hard about using scale as justification for quitting your job; chances are you haven't considered the _human_ factors involved.\n\n# Adversity\n\nRuling out both scale and technology as reasons for quitting a job is great, but to be honest they aren't the most common reasons I've quit in the past. Typically that honor is reserved for a more sinister and damaging character-trait: an inability to handle adversity.\n\nAdversity is double-edged; it shows us the best _and_ worst of ourselves, sometimes at the same time! If I take a step back and examine times when I left jobs because things just got too challenging I truly feel like there was _always_ an opportunity to overcome _in spite of_ the challenging situation and emerge a stronger human. How we respond to challenges in our workplace says a lot about our character:\n\n![Calvin Builds Character Shoveling Snow](/img/reasons-not-to-quit-your-job/calvin.character.building.png)\n\n![Calvin Builds Character Eating Dinner](/img/reasons-not-to-quit-your-job/calvin.character.building.2.gif)\n\n![Calvin Builds Character Being Cold (and Frugal)](/img/reasons-not-to-quit-your-job/calvin.character.building.3.gif)\n\nBefore you quit your job because it's just \"too damned hard\" I would encourage you to take a moment and step outside yourself; reflect on the situation and the facts -- [take the emotion out of it](https://www.vitalsmarts.com/crucialskills/2009/04/how-to-control-your-emotion/) and be objective.\n\nIf you can turn a challenging situation from a painful pity-party into an opportunity to conquer and emerge better you will be amazed at what you can come through.\n\n# Still Ready to Quit?\n\nThere are valid reasons to quit your job, but I think we tend to dwell on them far too often before considering the reasons _not_ to. My hope for you at the end of 2016 is that as you approach the boundary and transition leading into 2017 that you would be prompted to introspect and reflect on what it is you truly want. Set some goals, list some objectives for your life and above all ask yourself some tough questions before throwing in the towel; as a wise friend of mine once said:\n\n> If the grass is greener on the other side, then you'd better water your own lawn.\n"
}></{
  "path": "app/posts/2016-12-30-reasons-not-to-quit-your-job.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Reasons not to quit your job",
      "date": "2016-12-30"
    },
    "source": "\n> 2016 was a year of ups and (if you agree with many of the social media channels in the last month) a significantly larger number of downs. I'm not sure  _exactly_ what it is about this time of year that causes us to reflect so much more than the rest of the year; I suspect it _mostly_ has to do with a heightened sense of awareness as we approach boundaries.\n\nAs children, we know they are there because our parents tell us and we frequently come close to them often by virtue of desiring to push past to see what is beyond. As parents, we know they are there because we create them; often intending to protect our children from things that are dangerous or to set parameters for healthy  age-appropriate interaction. As software developers we encounter [boundaries](https://www.destroyallsoftware.com/talks/boundaries) in tests, the design of our code as it relates to components in a system, API's, the list goes on and on. Being in constant consideration of boundaries, whether consciously or subconsciously, has the side-effect of switching our brain into analysis and reflection mode.\n\nI recently had some friends reach out for advice as they were contemplating a transition at a critical boundary: quitting their job.\n\n> \"It's time for a change\"\n\n...\n\n> \"I've been restless but I'm trying to be cautious\"\n\nThese exchanges, coupled with the time of year and my brain switching into reflection mode, have had me considering reasons I left jobs in the past. The more I thought about it the more my brain kept telling me that those reasons were often _not_ valid reasons to justify leaving. I wrestled with it and tried to move onto other thoughts but it just kept nagging at me; this is usually an indication I need to deal with those thoughts in a positive way. So, here I am attempting to impart some wisdom about reasons _not_ to quit your job in 2017 (but mostly just typing as an exercise to free my brain up to move onto other things!) ;)\n\n# Technology\n\nOn April 3rd, 2014 I wrote [some of the reasons](https://blog.davemo.com/posts/2014-04-03-the-magnetic-core-philosophy.html) I left the last job I was at. I've re-read that post a dozen times trying to mine some fragments of wisdom, mostly to attempt to justify the decisions at that time. The only conclusions I've come up with at this point are: there are a lot of emotions in my writing that stemmed _mainly_ from too much focus on Technology as one of the reasons I quit.\n\nTechnology is seductive; it attempts to woo us through flashy demos from paid evangelists or conference talks from influential heroes. Technology is like the trench-coat wearing crook on the street corner who promises us the Rolex and ends up delivering a cheap imitation. When the tech-stack you work with (or _want_ to work with) becomes the justification for a career change it has the potential to snowball into a full on addiction to newness that sets your brain up for a dependence on switching tech in the same way a drug addict depends on their narcotic of choice.\n\nThe truth is that most systems that we work on move slowly towards [disorder and complexity](https://en.wikipedia.org/wiki/Software_entropy), so it is no surprise that the promise of a fresh-start in a new technology stack is appealing. An entire generation of software developers have become so accustomed to quitting their job based on technology that I suspect the coming decades will yield a significant need for people who have experience dealing with systems over a long period of time. If we don't deal with our addiction to newness, the recruiter pitch of \"Junior Developer Wanted, 5 years experience Node.JS/Rails/...\" that we so frequently deride will turn into \"Senior Developer Wanted, 10 years experience dealing with software entropy\" and there will be no one to answer the call.\n\nDon't get sucked into the new tech cycle; learn to embrace what you're working on now and strive to work the best with the technology constraints you've been handed.\n\n# Scale\n\nSo, you've thought considerably about your current job and ruled out technology as the main reason for leaving. In fact, you're sticking with the tried and true tech-stack you've always known, but there's just been that nagging feeling that you'd be so much better off if you could experience working with your stack at a larger scale. Oh to be able to understand the constraints of systems at an order-of-magnitude or two beyond where you are working now; that's the ticket!\n\nScale is subtle; on the surface it promises a similar thing to the tech-stack switch: an opportunity to learn new things that your current scale of operations can't teach you. Chances are you will probably actually learn some new technical things by increasing scale; the reality is that we tend to focus more on the _technical_ and less on the _human_ side of software development which often affects increases in scale much more. In his book, [Predictable Success](https://www.predictablesuccess.com/books/predictable-success/), Les McKeown gives some wisdom about how scale affects success in an operation:\n\n> Predictable Success is defined as one of the seven stages of organizational development. It can be attained by any organization or group that acts as a human machine, well-oiled, working in concert, not without challenge, but focused and \"in the zone\" where growth is attainable _and_ sustainable. It is not about size or the age of an organization. It has nothing to do with resources, culture or industry.\n\n![The Whole Picture of Organizational Development according to Predicable Success](/img/reasons-not-to-quit-your-job/predictable.success.whole.picture.png)\n\nI particularly like his focus on the \"human\" factors and exclusion of the traditionally technical things we tend to focus on. While the book is targeted towards business growth and the reasons why companies tend to fail, it can be broadly applied to _any_ group or organization (including software development orgs). Ask the following questions about the organization you're contemplating joining:\n\n* What [stage of organizational development](/img/reasons-not-to-quit-your-job/predictable.success.whole.picture.png) are they in?\n* Can I really grow the way I want to there, not just technically but also in my capacity as a human?\n* Will the scale inhibit or promote my growth?\n* What potential problems will exist at the new operating scale?\n\nIn my experience working as a consultant the only constant I've observed is that the same problems (and the same trend towards entropy) exist regardless of the scale of the company and how they use their technology.\n\nThink hard about using scale as justification for quitting your job; chances are you haven't considered the _human_ factors involved.\n\n# Adversity\n\nRuling out both scale and technology as reasons for quitting a job is great, but to be honest they aren't the most common reasons I've quit in the past. Typically that honor is reserved for a more sinister and damaging character-trait: an inability to handle adversity.\n\nAdversity is double-edged; it shows us the best _and_ worst of ourselves, sometimes at the same time! If I take a step back and examine times when I left jobs because things just got too challenging I truly feel like there was _always_ an opportunity to overcome _in spite of_ the challenging situation and emerge a stronger human. How we respond to challenges in our workplace says a lot about our character:\n\n![Calvin Builds Character Shoveling Snow](/img/reasons-not-to-quit-your-job/calvin.character.building.png)\n\n![Calvin Builds Character Eating Dinner](/img/reasons-not-to-quit-your-job/calvin.character.building.2.gif)\n\n![Calvin Builds Character Being Cold (and Frugal)](/img/reasons-not-to-quit-your-job/calvin.character.building.3.gif)\n\nBefore you quit your job because it's just \"too damned hard\" I would encourage you to take a moment and step outside yourself; reflect on the situation and the facts -- [take the emotion out of it](https://www.vitalsmarts.com/crucialskills/2009/04/how-to-control-your-emotion/) and be objective.\n\nIf you can turn a challenging situation from a painful pity-party into an opportunity to conquer and emerge better you will be amazed at what you can come through.\n\n# Still Ready to Quit?\n\nThere are valid reasons to quit your job, but I think we tend to dwell on them far too often before considering the reasons _not_ to. My hope for you at the end of 2016 is that as you approach the boundary and transition leading into 2017 that you would be prompted to introspect and reflect on what it is you truly want. Set some goals, list some objectives for your life and above all ask yourself some tough questions before throwing in the towel; as a wise friend of mine once said:\n\n> If the grass is greener on the other side, then you'd better water your own lawn.\n"
  },
  "attributes": {
    "title": "Reasons not to quit your job",
    "date": "2016-12-30"
  },
  "markdown": "\n> 2016 was a year of ups and (if you agree with many of the social media channels in the last month) a significantly larger number of downs. I'm not sure  _exactly_ what it is about this time of year that causes us to reflect so much more than the rest of the year; I suspect it _mostly_ has to do with a heightened sense of awareness as we approach boundaries.\n\nAs children, we know they are there because our parents tell us and we frequently come close to them often by virtue of desiring to push past to see what is beyond. As parents, we know they are there because we create them; often intending to protect our children from things that are dangerous or to set parameters for healthy  age-appropriate interaction. As software developers we encounter [boundaries](https://www.destroyallsoftware.com/talks/boundaries) in tests, the design of our code as it relates to components in a system, API's, the list goes on and on. Being in constant consideration of boundaries, whether consciously or subconsciously, has the side-effect of switching our brain into analysis and reflection mode.\n\nI recently had some friends reach out for advice as they were contemplating a transition at a critical boundary: quitting their job.\n\n> \"It's time for a change\"\n\n...\n\n> \"I've been restless but I'm trying to be cautious\"\n\nThese exchanges, coupled with the time of year and my brain switching into reflection mode, have had me considering reasons I left jobs in the past. The more I thought about it the more my brain kept telling me that those reasons were often _not_ valid reasons to justify leaving. I wrestled with it and tried to move onto other thoughts but it just kept nagging at me; this is usually an indication I need to deal with those thoughts in a positive way. So, here I am attempting to impart some wisdom about reasons _not_ to quit your job in 2017 (but mostly just typing as an exercise to free my brain up to move onto other things!) ;)\n\n# Technology\n\nOn April 3rd, 2014 I wrote [some of the reasons](https://blog.davemo.com/posts/2014-04-03-the-magnetic-core-philosophy.html) I left the last job I was at. I've re-read that post a dozen times trying to mine some fragments of wisdom, mostly to attempt to justify the decisions at that time. The only conclusions I've come up with at this point are: there are a lot of emotions in my writing that stemmed _mainly_ from too much focus on Technology as one of the reasons I quit.\n\nTechnology is seductive; it attempts to woo us through flashy demos from paid evangelists or conference talks from influential heroes. Technology is like the trench-coat wearing crook on the street corner who promises us the Rolex and ends up delivering a cheap imitation. When the tech-stack you work with (or _want_ to work with) becomes the justification for a career change it has the potential to snowball into a full on addiction to newness that sets your brain up for a dependence on switching tech in the same way a drug addict depends on their narcotic of choice.\n\nThe truth is that most systems that we work on move slowly towards [disorder and complexity](https://en.wikipedia.org/wiki/Software_entropy), so it is no surprise that the promise of a fresh-start in a new technology stack is appealing. An entire generation of software developers have become so accustomed to quitting their job based on technology that I suspect the coming decades will yield a significant need for people who have experience dealing with systems over a long period of time. If we don't deal with our addiction to newness, the recruiter pitch of \"Junior Developer Wanted, 5 years experience Node.JS/Rails/...\" that we so frequently deride will turn into \"Senior Developer Wanted, 10 years experience dealing with software entropy\" and there will be no one to answer the call.\n\nDon't get sucked into the new tech cycle; learn to embrace what you're working on now and strive to work the best with the technology constraints you've been handed.\n\n# Scale\n\nSo, you've thought considerably about your current job and ruled out technology as the main reason for leaving. In fact, you're sticking with the tried and true tech-stack you've always known, but there's just been that nagging feeling that you'd be so much better off if you could experience working with your stack at a larger scale. Oh to be able to understand the constraints of systems at an order-of-magnitude or two beyond where you are working now; that's the ticket!\n\nScale is subtle; on the surface it promises a similar thing to the tech-stack switch: an opportunity to learn new things that your current scale of operations can't teach you. Chances are you will probably actually learn some new technical things by increasing scale; the reality is that we tend to focus more on the _technical_ and less on the _human_ side of software development which often affects increases in scale much more. In his book, [Predictable Success](https://www.predictablesuccess.com/books/predictable-success/), Les McKeown gives some wisdom about how scale affects success in an operation:\n\n> Predictable Success is defined as one of the seven stages of organizational development. It can be attained by any organization or group that acts as a human machine, well-oiled, working in concert, not without challenge, but focused and \"in the zone\" where growth is attainable _and_ sustainable. It is not about size or the age of an organization. It has nothing to do with resources, culture or industry.\n\n![The Whole Picture of Organizational Development according to Predicable Success](/img/reasons-not-to-quit-your-job/predictable.success.whole.picture.png)\n\nI particularly like his focus on the \"human\" factors and exclusion of the traditionally technical things we tend to focus on. While the book is targeted towards business growth and the reasons why companies tend to fail, it can be broadly applied to _any_ group or organization (including software development orgs). Ask the following questions about the organization you're contemplating joining:\n\n* What [stage of organizational development](/img/reasons-not-to-quit-your-job/predictable.success.whole.picture.png) are they in?\n* Can I really grow the way I want to there, not just technically but also in my capacity as a human?\n* Will the scale inhibit or promote my growth?\n* What potential problems will exist at the new operating scale?\n\nIn my experience working as a consultant the only constant I've observed is that the same problems (and the same trend towards entropy) exist regardless of the scale of the company and how they use their technology.\n\nThink hard about using scale as justification for quitting your job; chances are you haven't considered the _human_ factors involved.\n\n# Adversity\n\nRuling out both scale and technology as reasons for quitting a job is great, but to be honest they aren't the most common reasons I've quit in the past. Typically that honor is reserved for a more sinister and damaging character-trait: an inability to handle adversity.\n\nAdversity is double-edged; it shows us the best _and_ worst of ourselves, sometimes at the same time! If I take a step back and examine times when I left jobs because things just got too challenging I truly feel like there was _always_ an opportunity to overcome _in spite of_ the challenging situation and emerge a stronger human. How we respond to challenges in our workplace says a lot about our character:\n\n![Calvin Builds Character Shoveling Snow](/img/reasons-not-to-quit-your-job/calvin.character.building.png)\n\n![Calvin Builds Character Eating Dinner](/img/reasons-not-to-quit-your-job/calvin.character.building.2.gif)\n\n![Calvin Builds Character Being Cold (and Frugal)](/img/reasons-not-to-quit-your-job/calvin.character.building.3.gif)\n\nBefore you quit your job because it's just \"too damned hard\" I would encourage you to take a moment and step outside yourself; reflect on the situation and the facts -- [take the emotion out of it](https://www.vitalsmarts.com/crucialskills/2009/04/how-to-control-your-emotion/) and be objective.\n\nIf you can turn a challenging situation from a painful pity-party into an opportunity to conquer and emerge better you will be amazed at what you can come through.\n\n# Still Ready to Quit?\n\nThere are valid reasons to quit your job, but I think we tend to dwell on them far too often before considering the reasons _not_ to. My hope for you at the end of 2016 is that as you approach the boundary and transition leading into 2017 that you would be prompted to introspect and reflect on what it is you truly want. Set some goals, list some objectives for your life and above all ask yourself some tough questions before throwing in the towel; as a wise friend of mine once said:\n\n> If the grass is greener on the other side, then you'd better water your own lawn.\n"
}></pre></div><div><a href="/posts/2015-04-10-introduction-to-react-native.html">Introduction to React Native</a><pre><{
  "path": "app/posts/2015-04-10-introduction-to-react-native.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Introduction to React Native",
      "date": "2015-04-10"
    },
    "source": "\n> This is a basic introduction to getting started with React Native; this screencast shows how to get setup, development workflow, and building the first cut at a ListView to show some images and meta data for [Hearthstone](https://playhearthstone.com/en-us) cards in the React Native application workflow.\n\n<iframe src=\"https://www.youtube.com/embed/n5RhAYhTxCk?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\nhttps://facebook.github.io/react-native/\n"
  },
  "attributes": {
    "title": "Introduction to React Native",
    "date": "2015-04-10"
  },
  "markdown": "\n> This is a basic introduction to getting started with React Native; this screencast shows how to get setup, development workflow, and building the first cut at a ListView to show some images and meta data for [Hearthstone](https://playhearthstone.com/en-us) cards in the React Native application workflow.\n\n<iframe src=\"https://www.youtube.com/embed/n5RhAYhTxCk?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\nhttps://facebook.github.io/react-native/\n"
}></{
  "path": "app/posts/2015-04-10-introduction-to-react-native.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Introduction to React Native",
      "date": "2015-04-10"
    },
    "source": "\n> This is a basic introduction to getting started with React Native; this screencast shows how to get setup, development workflow, and building the first cut at a ListView to show some images and meta data for [Hearthstone](https://playhearthstone.com/en-us) cards in the React Native application workflow.\n\n<iframe src=\"https://www.youtube.com/embed/n5RhAYhTxCk?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\nhttps://facebook.github.io/react-native/\n"
  },
  "attributes": {
    "title": "Introduction to React Native",
    "date": "2015-04-10"
  },
  "markdown": "\n> This is a basic introduction to getting started with React Native; this screencast shows how to get setup, development workflow, and building the first cut at a ListView to show some images and meta data for [Hearthstone](https://playhearthstone.com/en-us) cards in the React Native application workflow.\n\n<iframe src=\"https://www.youtube.com/embed/n5RhAYhTxCk?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\nhttps://facebook.github.io/react-native/\n"
}></pre></div><div><a href="/posts/2015-03-06-building-dsls-with-javascript-and-coffeescript.html">Building DSLs with JavaScript &amp; CoffeeScript</a><pre><{
  "path": "app/posts/2015-03-06-building-dsls-with-javascript-and-coffeescript.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Building DSLs with JavaScript & CoffeeScript",
      "date": "2015-03-06"
    },
    "source": "\n> Web developers are integration specialists—tying plugins, scripts and frameworks together into a web application that works. Thinking in terms of abstractions—by condensing many low-level ideas into fewer high-level ideas—allows us to simplify our code and reason about it with less cognitive overhead.\n\n<iframe src=\"https://www.youtube.com/embed/EOksrrySfwI?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIn this screencast, recorded at [Prairie Dev Con 2015](prairiedevcon.com), we examine a few techniques for building abstractions on top of popular JavaScript frameworks by learning about Domain Specific Languages and bringing some convention to our code.\n\n# Code\n\nhttps://github.com/davemo/jsdsl"
  },
  "attributes": {
    "title": "Building DSLs with JavaScript & CoffeeScript",
    "date": "2015-03-06"
  },
  "markdown": "\n> Web developers are integration specialists—tying plugins, scripts and frameworks together into a web application that works. Thinking in terms of abstractions—by condensing many low-level ideas into fewer high-level ideas—allows us to simplify our code and reason about it with less cognitive overhead.\n\n<iframe src=\"https://www.youtube.com/embed/EOksrrySfwI?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIn this screencast, recorded at [Prairie Dev Con 2015](prairiedevcon.com), we examine a few techniques for building abstractions on top of popular JavaScript frameworks by learning about Domain Specific Languages and bringing some convention to our code.\n\n# Code\n\nhttps://github.com/davemo/jsdsl"
}></{
  "path": "app/posts/2015-03-06-building-dsls-with-javascript-and-coffeescript.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Building DSLs with JavaScript & CoffeeScript",
      "date": "2015-03-06"
    },
    "source": "\n> Web developers are integration specialists—tying plugins, scripts and frameworks together into a web application that works. Thinking in terms of abstractions—by condensing many low-level ideas into fewer high-level ideas—allows us to simplify our code and reason about it with less cognitive overhead.\n\n<iframe src=\"https://www.youtube.com/embed/EOksrrySfwI?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIn this screencast, recorded at [Prairie Dev Con 2015](prairiedevcon.com), we examine a few techniques for building abstractions on top of popular JavaScript frameworks by learning about Domain Specific Languages and bringing some convention to our code.\n\n# Code\n\nhttps://github.com/davemo/jsdsl"
  },
  "attributes": {
    "title": "Building DSLs with JavaScript & CoffeeScript",
    "date": "2015-03-06"
  },
  "markdown": "\n> Web developers are integration specialists—tying plugins, scripts and frameworks together into a web application that works. Thinking in terms of abstractions—by condensing many low-level ideas into fewer high-level ideas—allows us to simplify our code and reason about it with less cognitive overhead.\n\n<iframe src=\"https://www.youtube.com/embed/EOksrrySfwI?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIn this screencast, recorded at [Prairie Dev Con 2015](prairiedevcon.com), we examine a few techniques for building abstractions on top of popular JavaScript frameworks by learning about Domain Specific Languages and bringing some convention to our code.\n\n# Code\n\nhttps://github.com/davemo/jsdsl"
}></pre></div><div><a href="/posts/2015-02-13-advanced-directives-with-angular-js.html">Advanced Directives with AngularJS (Part 1)</a><pre><{
  "path": "app/posts/2015-02-13-advanced-directives-with-angular-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Advanced Directives with AngularJS (Part 1)",
      "date": "2015-02-13"
    },
    "source": "\n> This screencast examines some of the more advanced features in Angular, specifically Directives. We'll see how we can leverage the power of custom elements and attributes to map Domain Specific concepts through HTML and translate those into Value Objects in our Domain, resulting in cleaner HTML output. Also discussed: complexity, creating a DSL with directives, debugging techniques, and other tips and tricks.\n\n<iframe src=\"https://www.youtube.com/embed/Ty8XcASK9js?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIf you're interested in some more context prior to watching, check out my other [angular screencasts](https://www.youtube.com/user/vidjadavemo/videos) and an earlier post on the [power of web components as abstractions](https://blog.davemo.com/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks). This screencast covers:\n\n* html as a dsl\n* abstractions in html\n* [$compile](https://docs.angularjs.org/api/ng/service/$compile)\n* [$templateRequest](https://docs.angularjs.org/api/ng/service/$templateRequest)\n* [$templateCache](https://docs.angularjs.org/api/ng/service/$templateCache)\n* [directive definition object](https://docs.angularjs.org/api/ng/service/$compile#directive-definition-object)\n* [requiring other directives](https://docs.angularjs.org/api/ng/service/$compile#-require-)\n* [directive communication ($scope.$broadcast, $scope.$on)](https://docs.angularjs.org/guide/scope#scope-events-propagation)\n\n# Code\n\nhttps://github.com/davemo/advanced-directives-with-angular-js\n\n# Extra Credit\n\nSome things in the screencast aren't complete and some things could definitely done better. This section is a challenge to you, the reader/watcher to improve the code and level up your knowledge in the process! Try and tackle some of these challenges if you want:\n\n* Bugfix: the editor currently shows up multiple times, fix it so this doesn't happen (hint: maybe an 'edit' state that's tracked could help the directive know if it should execute `.insertAfter`)\n* Feature: make the expandy arrow thing point down when expanded and to the right when collapsed.\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
  },
  "attributes": {
    "title": "Advanced Directives with AngularJS (Part 1)",
    "date": "2015-02-13"
  },
  "markdown": "\n> This screencast examines some of the more advanced features in Angular, specifically Directives. We'll see how we can leverage the power of custom elements and attributes to map Domain Specific concepts through HTML and translate those into Value Objects in our Domain, resulting in cleaner HTML output. Also discussed: complexity, creating a DSL with directives, debugging techniques, and other tips and tricks.\n\n<iframe src=\"https://www.youtube.com/embed/Ty8XcASK9js?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIf you're interested in some more context prior to watching, check out my other [angular screencasts](https://www.youtube.com/user/vidjadavemo/videos) and an earlier post on the [power of web components as abstractions](https://blog.davemo.com/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks). This screencast covers:\n\n* html as a dsl\n* abstractions in html\n* [$compile](https://docs.angularjs.org/api/ng/service/$compile)\n* [$templateRequest](https://docs.angularjs.org/api/ng/service/$templateRequest)\n* [$templateCache](https://docs.angularjs.org/api/ng/service/$templateCache)\n* [directive definition object](https://docs.angularjs.org/api/ng/service/$compile#directive-definition-object)\n* [requiring other directives](https://docs.angularjs.org/api/ng/service/$compile#-require-)\n* [directive communication ($scope.$broadcast, $scope.$on)](https://docs.angularjs.org/guide/scope#scope-events-propagation)\n\n# Code\n\nhttps://github.com/davemo/advanced-directives-with-angular-js\n\n# Extra Credit\n\nSome things in the screencast aren't complete and some things could definitely done better. This section is a challenge to you, the reader/watcher to improve the code and level up your knowledge in the process! Try and tackle some of these challenges if you want:\n\n* Bugfix: the editor currently shows up multiple times, fix it so this doesn't happen (hint: maybe an 'edit' state that's tracked could help the directive know if it should execute `.insertAfter`)\n* Feature: make the expandy arrow thing point down when expanded and to the right when collapsed.\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
}></{
  "path": "app/posts/2015-02-13-advanced-directives-with-angular-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Advanced Directives with AngularJS (Part 1)",
      "date": "2015-02-13"
    },
    "source": "\n> This screencast examines some of the more advanced features in Angular, specifically Directives. We'll see how we can leverage the power of custom elements and attributes to map Domain Specific concepts through HTML and translate those into Value Objects in our Domain, resulting in cleaner HTML output. Also discussed: complexity, creating a DSL with directives, debugging techniques, and other tips and tricks.\n\n<iframe src=\"https://www.youtube.com/embed/Ty8XcASK9js?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIf you're interested in some more context prior to watching, check out my other [angular screencasts](https://www.youtube.com/user/vidjadavemo/videos) and an earlier post on the [power of web components as abstractions](https://blog.davemo.com/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks). This screencast covers:\n\n* html as a dsl\n* abstractions in html\n* [$compile](https://docs.angularjs.org/api/ng/service/$compile)\n* [$templateRequest](https://docs.angularjs.org/api/ng/service/$templateRequest)\n* [$templateCache](https://docs.angularjs.org/api/ng/service/$templateCache)\n* [directive definition object](https://docs.angularjs.org/api/ng/service/$compile#directive-definition-object)\n* [requiring other directives](https://docs.angularjs.org/api/ng/service/$compile#-require-)\n* [directive communication ($scope.$broadcast, $scope.$on)](https://docs.angularjs.org/guide/scope#scope-events-propagation)\n\n# Code\n\nhttps://github.com/davemo/advanced-directives-with-angular-js\n\n# Extra Credit\n\nSome things in the screencast aren't complete and some things could definitely done better. This section is a challenge to you, the reader/watcher to improve the code and level up your knowledge in the process! Try and tackle some of these challenges if you want:\n\n* Bugfix: the editor currently shows up multiple times, fix it so this doesn't happen (hint: maybe an 'edit' state that's tracked could help the directive know if it should execute `.insertAfter`)\n* Feature: make the expandy arrow thing point down when expanded and to the right when collapsed.\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
  },
  "attributes": {
    "title": "Advanced Directives with AngularJS (Part 1)",
    "date": "2015-02-13"
  },
  "markdown": "\n> This screencast examines some of the more advanced features in Angular, specifically Directives. We'll see how we can leverage the power of custom elements and attributes to map Domain Specific concepts through HTML and translate those into Value Objects in our Domain, resulting in cleaner HTML output. Also discussed: complexity, creating a DSL with directives, debugging techniques, and other tips and tricks.\n\n<iframe src=\"https://www.youtube.com/embed/Ty8XcASK9js?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nIf you're interested in some more context prior to watching, check out my other [angular screencasts](https://www.youtube.com/user/vidjadavemo/videos) and an earlier post on the [power of web components as abstractions](https://blog.davemo.com/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks). This screencast covers:\n\n* html as a dsl\n* abstractions in html\n* [$compile](https://docs.angularjs.org/api/ng/service/$compile)\n* [$templateRequest](https://docs.angularjs.org/api/ng/service/$templateRequest)\n* [$templateCache](https://docs.angularjs.org/api/ng/service/$templateCache)\n* [directive definition object](https://docs.angularjs.org/api/ng/service/$compile#directive-definition-object)\n* [requiring other directives](https://docs.angularjs.org/api/ng/service/$compile#-require-)\n* [directive communication ($scope.$broadcast, $scope.$on)](https://docs.angularjs.org/guide/scope#scope-events-propagation)\n\n# Code\n\nhttps://github.com/davemo/advanced-directives-with-angular-js\n\n# Extra Credit\n\nSome things in the screencast aren't complete and some things could definitely done better. This section is a challenge to you, the reader/watcher to improve the code and level up your knowledge in the process! Try and tackle some of these challenges if you want:\n\n* Bugfix: the editor currently shows up multiple times, fix it so this doesn't happen (hint: maybe an 'edit' state that's tracked could help the directive know if it should execute `.insertAfter`)\n* Feature: make the expandy arrow thing point down when expanded and to the right when collapsed.\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
}></pre></div><div><a href="/posts/2014-04-03-the-magnetic-core-philosophy.html">The Magnetic Core Philosophy</a><pre><{
  "path": "app/posts/2014-04-03-the-magnetic-core-philosophy.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The Magnetic Core Philosophy",
      "date": "2014-04-03"
    },
    "source": "\n> Do software companies succeed because of the **technology** they use or is it due to the **discipline and talent** of their engineering and design teams? Is it the right combination of **vision and direction** from leadership that leads to success or just simply being in the right place at the right time? All of these things are potential contributing factors to the success of a software company but none of them stand alone as reasons for success.\n\nThe companies that succeed are the ones who solve their customers business problems with excellence, regardless of technology, leadership, or team composition. To attribute success to any one dimension, such as technology choice, is at best naive and at worst renders that dimension untouchable.\n\n## Alignment Challenges\n\nWhen technology is given all of the credit for success it becomes the gravitational center that all further technology decisions _must_ orbit. Evaluating alternatives becomes fruitless; anything that has the potential to drift too far from the ideals of this magnetic core is viewed with skepticism. This makes it challenging for companies to adapt, or even recognize, that there are changes in technology choice that could benefit them greatly.\n\nWorse still, this magnetic core philosophy creates an environment where _all_ choices are evaluated through the reality-warping magnetic field surrounding the technology core. Process changes, HR policies, culture; all these things are influenced by the gravitational pull of the core and often by the community of _other_ companies who have chosen to embrace its ideals.\n\n## Untouchable Icons\n\nIn a company where the magnetic core of technology is viewed as the sole basis for success, there become untouchable icons (the technology, and its supporters) who are unable to be challenged. This often creates a sense of fear (and paralyzes objective thinking) as any idea that deviates from core ideals is viewed as having the potential to veer the company out of orbit and cause a cascade of failure.\n\nThere becomes an identity mismatch between team members who have good ideas and those who espouse core ideals; the framework of trust used to identify an individuals success often selects the latter.\n\n## Technical Depth at the expense of Empathy\n\nCompanies that align their success with the magnetic core of technology often over-value technical depth and promote from within those individuals who have demonstrated alignment with core ideals. When technical depth is put in this position of importance it creates an environment where empathy is seen as a less valuable skillset. The challenges that these companies face, and the challenges our industry continues to face are often a direct result of a commonly repeated failure that too closely aligns success with technology.\n\n## Moving Forward\n\nAll of this paints a pretty bleak picture about the state of technology and the software industry and it is easy to list problems without solutions; where do we go from here? I firmly believe that there are simple solutions to the problems listed above.\n\nFirst, we need to balance the success equation in our companies so that it places more emphasis on _people_ being the reason for success instead of technology choice.\n\nSecond, We need to foster an open environment that allows people to feel like they can contribute ideas, any ideas, without feeling paralyzed by the fear of being viewed as counter-culture when ideas differ from core ideals.\n\nLastly, and most importantly, we need to balance the framework we use to promote leaders in our companies so that empathy will be considered more important than technical depth.\n"
  },
  "attributes": {
    "title": "The Magnetic Core Philosophy",
    "date": "2014-04-03"
  },
  "markdown": "\n> Do software companies succeed because of the **technology** they use or is it due to the **discipline and talent** of their engineering and design teams? Is it the right combination of **vision and direction** from leadership that leads to success or just simply being in the right place at the right time? All of these things are potential contributing factors to the success of a software company but none of them stand alone as reasons for success.\n\nThe companies that succeed are the ones who solve their customers business problems with excellence, regardless of technology, leadership, or team composition. To attribute success to any one dimension, such as technology choice, is at best naive and at worst renders that dimension untouchable.\n\n## Alignment Challenges\n\nWhen technology is given all of the credit for success it becomes the gravitational center that all further technology decisions _must_ orbit. Evaluating alternatives becomes fruitless; anything that has the potential to drift too far from the ideals of this magnetic core is viewed with skepticism. This makes it challenging for companies to adapt, or even recognize, that there are changes in technology choice that could benefit them greatly.\n\nWorse still, this magnetic core philosophy creates an environment where _all_ choices are evaluated through the reality-warping magnetic field surrounding the technology core. Process changes, HR policies, culture; all these things are influenced by the gravitational pull of the core and often by the community of _other_ companies who have chosen to embrace its ideals.\n\n## Untouchable Icons\n\nIn a company where the magnetic core of technology is viewed as the sole basis for success, there become untouchable icons (the technology, and its supporters) who are unable to be challenged. This often creates a sense of fear (and paralyzes objective thinking) as any idea that deviates from core ideals is viewed as having the potential to veer the company out of orbit and cause a cascade of failure.\n\nThere becomes an identity mismatch between team members who have good ideas and those who espouse core ideals; the framework of trust used to identify an individuals success often selects the latter.\n\n## Technical Depth at the expense of Empathy\n\nCompanies that align their success with the magnetic core of technology often over-value technical depth and promote from within those individuals who have demonstrated alignment with core ideals. When technical depth is put in this position of importance it creates an environment where empathy is seen as a less valuable skillset. The challenges that these companies face, and the challenges our industry continues to face are often a direct result of a commonly repeated failure that too closely aligns success with technology.\n\n## Moving Forward\n\nAll of this paints a pretty bleak picture about the state of technology and the software industry and it is easy to list problems without solutions; where do we go from here? I firmly believe that there are simple solutions to the problems listed above.\n\nFirst, we need to balance the success equation in our companies so that it places more emphasis on _people_ being the reason for success instead of technology choice.\n\nSecond, We need to foster an open environment that allows people to feel like they can contribute ideas, any ideas, without feeling paralyzed by the fear of being viewed as counter-culture when ideas differ from core ideals.\n\nLastly, and most importantly, we need to balance the framework we use to promote leaders in our companies so that empathy will be considered more important than technical depth.\n"
}></{
  "path": "app/posts/2014-04-03-the-magnetic-core-philosophy.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The Magnetic Core Philosophy",
      "date": "2014-04-03"
    },
    "source": "\n> Do software companies succeed because of the **technology** they use or is it due to the **discipline and talent** of their engineering and design teams? Is it the right combination of **vision and direction** from leadership that leads to success or just simply being in the right place at the right time? All of these things are potential contributing factors to the success of a software company but none of them stand alone as reasons for success.\n\nThe companies that succeed are the ones who solve their customers business problems with excellence, regardless of technology, leadership, or team composition. To attribute success to any one dimension, such as technology choice, is at best naive and at worst renders that dimension untouchable.\n\n## Alignment Challenges\n\nWhen technology is given all of the credit for success it becomes the gravitational center that all further technology decisions _must_ orbit. Evaluating alternatives becomes fruitless; anything that has the potential to drift too far from the ideals of this magnetic core is viewed with skepticism. This makes it challenging for companies to adapt, or even recognize, that there are changes in technology choice that could benefit them greatly.\n\nWorse still, this magnetic core philosophy creates an environment where _all_ choices are evaluated through the reality-warping magnetic field surrounding the technology core. Process changes, HR policies, culture; all these things are influenced by the gravitational pull of the core and often by the community of _other_ companies who have chosen to embrace its ideals.\n\n## Untouchable Icons\n\nIn a company where the magnetic core of technology is viewed as the sole basis for success, there become untouchable icons (the technology, and its supporters) who are unable to be challenged. This often creates a sense of fear (and paralyzes objective thinking) as any idea that deviates from core ideals is viewed as having the potential to veer the company out of orbit and cause a cascade of failure.\n\nThere becomes an identity mismatch between team members who have good ideas and those who espouse core ideals; the framework of trust used to identify an individuals success often selects the latter.\n\n## Technical Depth at the expense of Empathy\n\nCompanies that align their success with the magnetic core of technology often over-value technical depth and promote from within those individuals who have demonstrated alignment with core ideals. When technical depth is put in this position of importance it creates an environment where empathy is seen as a less valuable skillset. The challenges that these companies face, and the challenges our industry continues to face are often a direct result of a commonly repeated failure that too closely aligns success with technology.\n\n## Moving Forward\n\nAll of this paints a pretty bleak picture about the state of technology and the software industry and it is easy to list problems without solutions; where do we go from here? I firmly believe that there are simple solutions to the problems listed above.\n\nFirst, we need to balance the success equation in our companies so that it places more emphasis on _people_ being the reason for success instead of technology choice.\n\nSecond, We need to foster an open environment that allows people to feel like they can contribute ideas, any ideas, without feeling paralyzed by the fear of being viewed as counter-culture when ideas differ from core ideals.\n\nLastly, and most importantly, we need to balance the framework we use to promote leaders in our companies so that empathy will be considered more important than technical depth.\n"
  },
  "attributes": {
    "title": "The Magnetic Core Philosophy",
    "date": "2014-04-03"
  },
  "markdown": "\n> Do software companies succeed because of the **technology** they use or is it due to the **discipline and talent** of their engineering and design teams? Is it the right combination of **vision and direction** from leadership that leads to success or just simply being in the right place at the right time? All of these things are potential contributing factors to the success of a software company but none of them stand alone as reasons for success.\n\nThe companies that succeed are the ones who solve their customers business problems with excellence, regardless of technology, leadership, or team composition. To attribute success to any one dimension, such as technology choice, is at best naive and at worst renders that dimension untouchable.\n\n## Alignment Challenges\n\nWhen technology is given all of the credit for success it becomes the gravitational center that all further technology decisions _must_ orbit. Evaluating alternatives becomes fruitless; anything that has the potential to drift too far from the ideals of this magnetic core is viewed with skepticism. This makes it challenging for companies to adapt, or even recognize, that there are changes in technology choice that could benefit them greatly.\n\nWorse still, this magnetic core philosophy creates an environment where _all_ choices are evaluated through the reality-warping magnetic field surrounding the technology core. Process changes, HR policies, culture; all these things are influenced by the gravitational pull of the core and often by the community of _other_ companies who have chosen to embrace its ideals.\n\n## Untouchable Icons\n\nIn a company where the magnetic core of technology is viewed as the sole basis for success, there become untouchable icons (the technology, and its supporters) who are unable to be challenged. This often creates a sense of fear (and paralyzes objective thinking) as any idea that deviates from core ideals is viewed as having the potential to veer the company out of orbit and cause a cascade of failure.\n\nThere becomes an identity mismatch between team members who have good ideas and those who espouse core ideals; the framework of trust used to identify an individuals success often selects the latter.\n\n## Technical Depth at the expense of Empathy\n\nCompanies that align their success with the magnetic core of technology often over-value technical depth and promote from within those individuals who have demonstrated alignment with core ideals. When technical depth is put in this position of importance it creates an environment where empathy is seen as a less valuable skillset. The challenges that these companies face, and the challenges our industry continues to face are often a direct result of a commonly repeated failure that too closely aligns success with technology.\n\n## Moving Forward\n\nAll of this paints a pretty bleak picture about the state of technology and the software industry and it is easy to list problems without solutions; where do we go from here? I firmly believe that there are simple solutions to the problems listed above.\n\nFirst, we need to balance the success equation in our companies so that it places more emphasis on _people_ being the reason for success instead of technology choice.\n\nSecond, We need to foster an open environment that allows people to feel like they can contribute ideas, any ideas, without feeling paralyzed by the fear of being viewed as counter-culture when ideas differ from core ideals.\n\nLastly, and most importantly, we need to balance the framework we use to promote leaders in our companies so that empathy will be considered more important than technical depth.\n"
}></pre></div><div><a href="/posts/2013-08-08-testing-strategies-for-angular-js.html">Testing Strategies for Angular JS</a><pre><{
  "path": "app/posts/2013-08-08-testing-strategies-for-angular-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Testing Strategies for Angular JS",
      "date": "2013-08-08"
    },
    "source": "\n> This screencast examines low and high fidelity testing strategies for Angular JS, and demonstrates examples of how to write tests with these strategies using Protractor, Testem, and Jasmine.\n\n<iframe src=\"https://www.youtube.com/embed/UYVcY9EJcRs?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n\n# Code\n\nhttps://github.com/davemo/lineman-angular-template\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
  },
  "attributes": {
    "title": "Testing Strategies for Angular JS",
    "date": "2013-08-08"
  },
  "markdown": "\n> This screencast examines low and high fidelity testing strategies for Angular JS, and demonstrates examples of how to write tests with these strategies using Protractor, Testem, and Jasmine.\n\n<iframe src=\"https://www.youtube.com/embed/UYVcY9EJcRs?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n\n# Code\n\nhttps://github.com/davemo/lineman-angular-template\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
}></{
  "path": "app/posts/2013-08-08-testing-strategies-for-angular-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Testing Strategies for Angular JS",
      "date": "2013-08-08"
    },
    "source": "\n> This screencast examines low and high fidelity testing strategies for Angular JS, and demonstrates examples of how to write tests with these strategies using Protractor, Testem, and Jasmine.\n\n<iframe src=\"https://www.youtube.com/embed/UYVcY9EJcRs?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n\n# Code\n\nhttps://github.com/davemo/lineman-angular-template\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
  },
  "attributes": {
    "title": "Testing Strategies for Angular JS",
    "date": "2013-08-08"
  },
  "markdown": "\n> This screencast examines low and high fidelity testing strategies for Angular JS, and demonstrates examples of how to write tests with these strategies using Protractor, Testem, and Jasmine.\n\n<iframe src=\"https://www.youtube.com/embed/UYVcY9EJcRs?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n\n# Code\n\nhttps://github.com/davemo/lineman-angular-template\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n"
}></pre></div><div><a href="/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks.html">What Polymer and Angular tell us about the future success of the Web Platform and JavaScript Frameworks</a><pre><{
  "path": "app/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "What Polymer and Angular tell us about the future success of the Web Platform and JavaScript Frameworks",
      "date": "2013-08-08"
    },
    "source": "\n> Yehuda Katz recently gave a talk entitled [\"The Future of the Client-Side\nWeb\"](https://www.youtube.com/watch?v=EcyxXPILO8E) in which he detailed the\ncurrent challenges that web standards bodies face when trying to design APIs\nfor web developers to use. In this talk, Yehuda also highlighted Google's\nrecently announced [Polymer Project](https://www.polymer-project.org/) as a good\nexample of the right way to push the web platform forward.\n\nPolymer provides a \"low enough\" level API that gives web developers the power\nto redefine the way they write markup using the power of newer features coming\nto JavaScript in [ES6](https://tc39wiki.calculist.org/es6/). The specifics of\nthe implementation aren't relevant to what I want to say here, but Yehuda does\na great job covering the details at a high level in the video; I suggest you\nwatch it if they interest you.\n\nWhat I found interesting was the _message_ that was at the heart of the talk,\nhere's my paraphrased version:\n\n> Web Platform standards bodies need to focus less on getting implementations\n> of new APIs right the first time (hello\n> [AppCache](https://www.w3.org/Bugs/Public/show_bug.cgi?id=14702)) and instead\n> provide web developers with a set of lower level APIs that are exposed to\n> JavaScript. When this approach has been followed, developers are capable of\n> iterating far faster than standards bodies which results in consensus on API\n> design being reached faster and with less upfront design.\n\nThis is a fundamental shift in thinking that should be embraced and I believe\nthis approach has already been validated by a number of well-known JavaScript\nlibraries.\n\n# The Backbone Lesson\n\nSince its release, [Backbone](https://documentcloud.github.io/backbone/) has\nexploded in popularity and many [other](https://github.com/chaplinjs/chaplin)\n[frameworks](https://github.com/marionettejs/backbone.marionette) have since\nbeen built on top of the low-level components it provides. [Jeremy\nAshkenas](https://www.twitter.com/jashkenas) and the team at [Document\nCloud](https://www.documentcloud.org) did an amazing job of releasing a set of\ncomponents that can be adapted to fit almost any scenario when building a web\napplication&mdash;from simple uses of Backbone.View inside an existing legacy\napplication all the way up to writing a self-contained application that runs in\nthe browser.\n\nWhen I first started working in Backbone almost two years ago, I remember\nfeeling overwhelmed at how I was supposed to use all the pieces provided. I\nbelieve this speaks to the essence of how Backbone was created, and looking\nback now it is clear to me that Backbone follows the design model that Yehuda\npraises in his talk; it gave us a low-level set of components and didn't really\nenforce any particular design decisions on how to use them&mdash;aside from an\nimportant guiding principle: get your data out of the DOM.\n\n# The Ember Conundrum\n\nA recent blog post comparing [Ember](https://emberjs.com/) and\nAngular&mdash;originally entitled [\"AngularJS vs Ember, It's not even\nclose\"](https://eviltrout.com/2013/06/15/ember-vs-angular-its-not-even-close.html)&mdash;highlights\nsome perceived shortcomings of Angular, chief among them being there are too\nmany pitfalls in the simplistic features Angular provides and the Angular team\nshould strive to provide higher-level conventions/components that developers\ncan follow. While Yehuda didn't write the comparison post, the point of view\nexpressed by the author really struck me as being in stark contrast to the\ndecentralized/low-level API design approach that Yehuda extols the virtues of\nin his talk: success is realized when developers are given access to low-level\ncomponents without many opinions on how they should be used. Designing a\npowerful, approachable, easy-to-learn-difficult-to-master framework _is_ hard,\nbut Ember is _very_ opinionated.\n\nIt seems to me like the Ember team and contributors would be better served by\nfollowing these design goals; spending more time observing how web developers\nuse their low-level APIs when crafting solutions and less time trying to get a\nhigh-level rich-web application framework right the first time. Perhaps this is\nwhy the path to Ember's 1.0 release has been so full of frequent, [backwards\ncompatibility breaking](https://meta.stackoverflow.com/a/163861) API changes.\n\n# The Angular Approach\n\nInitially I was skeptical about the power of\n[Angular](https://www.angularjs.org), having spent a good 18 months of my life\ninvested in writing applications with Backbone I wasn't eager to make a jump to\nanother framework. Thankfully my skepticism was quickly swept aside as I\ndiscovered the beauty in the simplicity of the Angular API. With Angular, I\ndon't have to extend framework built-in objects or methods; I can just use\nPOJSO's (Plain Old JavaScript Objects) and functions. I also don't have to\nspend a lot of time thinking about how to structure my application thanks to\n[`angular.module`](https://docs.angularjs.org/guide/module) and built-in\n[dependency injection](https://docs.angularjs.org/guide/di). Angular _really_\nhits the sweet spot between low-level components and _tightly scoped_\nhigh-level abstractions. It provides high-level features that each have a\nsingular focus as well as low-level components that I can craft into\ndomain-specific solutions within my applications.\n\nThe ability to craft custom markup through\n[`angular.directive`](https://docs.angularjs.org/guide/directive) is an\ninteresting high-level piece in that it has the power to create custom\ncomponents that are as coarse or granular as you need them to be. Angular is\n_just_ opinionated enough that it allows developers to work with the low-level\ncomponents provided to craft higher level abstractions. In fact, I think that\nis the core benefit of Angular. Having the power to abstract:\n\n```html\n<div id=\"chart\" data-type=\"bar\">\n  <div class=\"legend\"></div>\n  ... lots of other stuff\n</div>\n```\n\ninto\n\n```html\n<bar-chart></bar-chart>\n```\n\nis an incredibly powerful idea.\n\n# Web Components and the future of Markup\n\nOne of the most exciting changes to the Web Platform in the last five years is\nthe upcoming [Web\nComponents](https://www.w3.org/TR/2013/WD-components-intro-20130606/) spec.\n[Eric\nBidelman](https://www.google.ca/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CC0QFjAA&url=https%3A%2F%2Ftwitter.com%2Febidel&ei=_EDLUbuIK8iHywGUuYHoDg&usg=AFQjCNHgffvpgL9vHcpCK96uvkRqTmUkzg&bvm=bv.48340889,d.aWc)\ngave a [great overview](https://www.youtube.com/watch?v=fqULJBBEVQE) of it\nduring Google IO this year and [Alex Komoroske](https://twitter.com/jkomoros)\nand [Matthew McNulty](https://twitter.com/mattsmcnulty) had an [amazing\ndemo](https://www.youtube.com/watch?v=0g0oOOT86NY) that showcased some of the\ncapabilities. I'm excited about Web Components because it will allow web\ndevelopers to experiment at a lower-level by reshaping the way that we write\nmarkup. It will also offer true encapsulation on the web, a feature that has\nbeen sorely lacking.\n\nIt seems like the lessons the Angular team have learned are helping to shape\nthe direction of Web Components. In fact, [Miško\nHevery](https://twitter.com/mhevery) from the Angular team has [this to\nsay](https://groups.google.com/forum/#!msg/polymer-dev/4RSYaKmbtEk/uYnY3900wpIJ)\non Angular + Web Components:\n\n> Web Components (Polymer, Ember, or any other framework/library) will work\n seamlessly within Angular apps and directives.\n\n> Components written in Angular will export to Web Components (to be used by\n Polymer, Ember, or any other framework/library).\n\nThe awesome thing about Angular and Polymer is that you can use them to achieve\nthese kinds of markup abstractions in your applications right now, along with\nall the other great features they provide. I'm eager to see how the lower-level\nfeatures in ES6 and low-level libraries like Polymer are going to be used by\ndevelopers to create even more amazing frameworks in the future.\n\n# Moving the Web Forward with Low-Level APIs\n\nI think Yehuda has it right; standards bodies need to focus less on getting\nhigh-level APIs right up front and more on providing developers with enough\nlow-level APIs with which to experiment. The same principle applies to the\ndesign of JavaScript application frameworks. My hope is that the standards\nbodies _and_ JavaScript framework authors embrace this decentralized approach\nto design going forward. Ideally this will move the web development community\nbeyond rhetoric and zero-sum thinking, and into an age of innovation.\n"
  },
  "attributes": {
    "title": "What Polymer and Angular tell us about the future success of the Web Platform and JavaScript Frameworks",
    "date": "2013-08-08"
  },
  "markdown": "\n> Yehuda Katz recently gave a talk entitled [\"The Future of the Client-Side\nWeb\"](https://www.youtube.com/watch?v=EcyxXPILO8E) in which he detailed the\ncurrent challenges that web standards bodies face when trying to design APIs\nfor web developers to use. In this talk, Yehuda also highlighted Google's\nrecently announced [Polymer Project](https://www.polymer-project.org/) as a good\nexample of the right way to push the web platform forward.\n\nPolymer provides a \"low enough\" level API that gives web developers the power\nto redefine the way they write markup using the power of newer features coming\nto JavaScript in [ES6](https://tc39wiki.calculist.org/es6/). The specifics of\nthe implementation aren't relevant to what I want to say here, but Yehuda does\na great job covering the details at a high level in the video; I suggest you\nwatch it if they interest you.\n\nWhat I found interesting was the _message_ that was at the heart of the talk,\nhere's my paraphrased version:\n\n> Web Platform standards bodies need to focus less on getting implementations\n> of new APIs right the first time (hello\n> [AppCache](https://www.w3.org/Bugs/Public/show_bug.cgi?id=14702)) and instead\n> provide web developers with a set of lower level APIs that are exposed to\n> JavaScript. When this approach has been followed, developers are capable of\n> iterating far faster than standards bodies which results in consensus on API\n> design being reached faster and with less upfront design.\n\nThis is a fundamental shift in thinking that should be embraced and I believe\nthis approach has already been validated by a number of well-known JavaScript\nlibraries.\n\n# The Backbone Lesson\n\nSince its release, [Backbone](https://documentcloud.github.io/backbone/) has\nexploded in popularity and many [other](https://github.com/chaplinjs/chaplin)\n[frameworks](https://github.com/marionettejs/backbone.marionette) have since\nbeen built on top of the low-level components it provides. [Jeremy\nAshkenas](https://www.twitter.com/jashkenas) and the team at [Document\nCloud](https://www.documentcloud.org) did an amazing job of releasing a set of\ncomponents that can be adapted to fit almost any scenario when building a web\napplication&mdash;from simple uses of Backbone.View inside an existing legacy\napplication all the way up to writing a self-contained application that runs in\nthe browser.\n\nWhen I first started working in Backbone almost two years ago, I remember\nfeeling overwhelmed at how I was supposed to use all the pieces provided. I\nbelieve this speaks to the essence of how Backbone was created, and looking\nback now it is clear to me that Backbone follows the design model that Yehuda\npraises in his talk; it gave us a low-level set of components and didn't really\nenforce any particular design decisions on how to use them&mdash;aside from an\nimportant guiding principle: get your data out of the DOM.\n\n# The Ember Conundrum\n\nA recent blog post comparing [Ember](https://emberjs.com/) and\nAngular&mdash;originally entitled [\"AngularJS vs Ember, It's not even\nclose\"](https://eviltrout.com/2013/06/15/ember-vs-angular-its-not-even-close.html)&mdash;highlights\nsome perceived shortcomings of Angular, chief among them being there are too\nmany pitfalls in the simplistic features Angular provides and the Angular team\nshould strive to provide higher-level conventions/components that developers\ncan follow. While Yehuda didn't write the comparison post, the point of view\nexpressed by the author really struck me as being in stark contrast to the\ndecentralized/low-level API design approach that Yehuda extols the virtues of\nin his talk: success is realized when developers are given access to low-level\ncomponents without many opinions on how they should be used. Designing a\npowerful, approachable, easy-to-learn-difficult-to-master framework _is_ hard,\nbut Ember is _very_ opinionated.\n\nIt seems to me like the Ember team and contributors would be better served by\nfollowing these design goals; spending more time observing how web developers\nuse their low-level APIs when crafting solutions and less time trying to get a\nhigh-level rich-web application framework right the first time. Perhaps this is\nwhy the path to Ember's 1.0 release has been so full of frequent, [backwards\ncompatibility breaking](https://meta.stackoverflow.com/a/163861) API changes.\n\n# The Angular Approach\n\nInitially I was skeptical about the power of\n[Angular](https://www.angularjs.org), having spent a good 18 months of my life\ninvested in writing applications with Backbone I wasn't eager to make a jump to\nanother framework. Thankfully my skepticism was quickly swept aside as I\ndiscovered the beauty in the simplicity of the Angular API. With Angular, I\ndon't have to extend framework built-in objects or methods; I can just use\nPOJSO's (Plain Old JavaScript Objects) and functions. I also don't have to\nspend a lot of time thinking about how to structure my application thanks to\n[`angular.module`](https://docs.angularjs.org/guide/module) and built-in\n[dependency injection](https://docs.angularjs.org/guide/di). Angular _really_\nhits the sweet spot between low-level components and _tightly scoped_\nhigh-level abstractions. It provides high-level features that each have a\nsingular focus as well as low-level components that I can craft into\ndomain-specific solutions within my applications.\n\nThe ability to craft custom markup through\n[`angular.directive`](https://docs.angularjs.org/guide/directive) is an\ninteresting high-level piece in that it has the power to create custom\ncomponents that are as coarse or granular as you need them to be. Angular is\n_just_ opinionated enough that it allows developers to work with the low-level\ncomponents provided to craft higher level abstractions. In fact, I think that\nis the core benefit of Angular. Having the power to abstract:\n\n```html\n<div id=\"chart\" data-type=\"bar\">\n  <div class=\"legend\"></div>\n  ... lots of other stuff\n</div>\n```\n\ninto\n\n```html\n<bar-chart></bar-chart>\n```\n\nis an incredibly powerful idea.\n\n# Web Components and the future of Markup\n\nOne of the most exciting changes to the Web Platform in the last five years is\nthe upcoming [Web\nComponents](https://www.w3.org/TR/2013/WD-components-intro-20130606/) spec.\n[Eric\nBidelman](https://www.google.ca/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CC0QFjAA&url=https%3A%2F%2Ftwitter.com%2Febidel&ei=_EDLUbuIK8iHywGUuYHoDg&usg=AFQjCNHgffvpgL9vHcpCK96uvkRqTmUkzg&bvm=bv.48340889,d.aWc)\ngave a [great overview](https://www.youtube.com/watch?v=fqULJBBEVQE) of it\nduring Google IO this year and [Alex Komoroske](https://twitter.com/jkomoros)\nand [Matthew McNulty](https://twitter.com/mattsmcnulty) had an [amazing\ndemo](https://www.youtube.com/watch?v=0g0oOOT86NY) that showcased some of the\ncapabilities. I'm excited about Web Components because it will allow web\ndevelopers to experiment at a lower-level by reshaping the way that we write\nmarkup. It will also offer true encapsulation on the web, a feature that has\nbeen sorely lacking.\n\nIt seems like the lessons the Angular team have learned are helping to shape\nthe direction of Web Components. In fact, [Miško\nHevery](https://twitter.com/mhevery) from the Angular team has [this to\nsay](https://groups.google.com/forum/#!msg/polymer-dev/4RSYaKmbtEk/uYnY3900wpIJ)\non Angular + Web Components:\n\n> Web Components (Polymer, Ember, or any other framework/library) will work\n seamlessly within Angular apps and directives.\n\n> Components written in Angular will export to Web Components (to be used by\n Polymer, Ember, or any other framework/library).\n\nThe awesome thing about Angular and Polymer is that you can use them to achieve\nthese kinds of markup abstractions in your applications right now, along with\nall the other great features they provide. I'm eager to see how the lower-level\nfeatures in ES6 and low-level libraries like Polymer are going to be used by\ndevelopers to create even more amazing frameworks in the future.\n\n# Moving the Web Forward with Low-Level APIs\n\nI think Yehuda has it right; standards bodies need to focus less on getting\nhigh-level APIs right up front and more on providing developers with enough\nlow-level APIs with which to experiment. The same principle applies to the\ndesign of JavaScript application frameworks. My hope is that the standards\nbodies _and_ JavaScript framework authors embrace this decentralized approach\nto design going forward. Ideally this will move the web development community\nbeyond rhetoric and zero-sum thinking, and into an age of innovation.\n"
}></{
  "path": "app/posts/2013-06-26-what-polymer-and-angular-tell-us-about-the-future-success-of-the-web-platform-and-javascript-frameworks.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "What Polymer and Angular tell us about the future success of the Web Platform and JavaScript Frameworks",
      "date": "2013-08-08"
    },
    "source": "\n> Yehuda Katz recently gave a talk entitled [\"The Future of the Client-Side\nWeb\"](https://www.youtube.com/watch?v=EcyxXPILO8E) in which he detailed the\ncurrent challenges that web standards bodies face when trying to design APIs\nfor web developers to use. In this talk, Yehuda also highlighted Google's\nrecently announced [Polymer Project](https://www.polymer-project.org/) as a good\nexample of the right way to push the web platform forward.\n\nPolymer provides a \"low enough\" level API that gives web developers the power\nto redefine the way they write markup using the power of newer features coming\nto JavaScript in [ES6](https://tc39wiki.calculist.org/es6/). The specifics of\nthe implementation aren't relevant to what I want to say here, but Yehuda does\na great job covering the details at a high level in the video; I suggest you\nwatch it if they interest you.\n\nWhat I found interesting was the _message_ that was at the heart of the talk,\nhere's my paraphrased version:\n\n> Web Platform standards bodies need to focus less on getting implementations\n> of new APIs right the first time (hello\n> [AppCache](https://www.w3.org/Bugs/Public/show_bug.cgi?id=14702)) and instead\n> provide web developers with a set of lower level APIs that are exposed to\n> JavaScript. When this approach has been followed, developers are capable of\n> iterating far faster than standards bodies which results in consensus on API\n> design being reached faster and with less upfront design.\n\nThis is a fundamental shift in thinking that should be embraced and I believe\nthis approach has already been validated by a number of well-known JavaScript\nlibraries.\n\n# The Backbone Lesson\n\nSince its release, [Backbone](https://documentcloud.github.io/backbone/) has\nexploded in popularity and many [other](https://github.com/chaplinjs/chaplin)\n[frameworks](https://github.com/marionettejs/backbone.marionette) have since\nbeen built on top of the low-level components it provides. [Jeremy\nAshkenas](https://www.twitter.com/jashkenas) and the team at [Document\nCloud](https://www.documentcloud.org) did an amazing job of releasing a set of\ncomponents that can be adapted to fit almost any scenario when building a web\napplication&mdash;from simple uses of Backbone.View inside an existing legacy\napplication all the way up to writing a self-contained application that runs in\nthe browser.\n\nWhen I first started working in Backbone almost two years ago, I remember\nfeeling overwhelmed at how I was supposed to use all the pieces provided. I\nbelieve this speaks to the essence of how Backbone was created, and looking\nback now it is clear to me that Backbone follows the design model that Yehuda\npraises in his talk; it gave us a low-level set of components and didn't really\nenforce any particular design decisions on how to use them&mdash;aside from an\nimportant guiding principle: get your data out of the DOM.\n\n# The Ember Conundrum\n\nA recent blog post comparing [Ember](https://emberjs.com/) and\nAngular&mdash;originally entitled [\"AngularJS vs Ember, It's not even\nclose\"](https://eviltrout.com/2013/06/15/ember-vs-angular-its-not-even-close.html)&mdash;highlights\nsome perceived shortcomings of Angular, chief among them being there are too\nmany pitfalls in the simplistic features Angular provides and the Angular team\nshould strive to provide higher-level conventions/components that developers\ncan follow. While Yehuda didn't write the comparison post, the point of view\nexpressed by the author really struck me as being in stark contrast to the\ndecentralized/low-level API design approach that Yehuda extols the virtues of\nin his talk: success is realized when developers are given access to low-level\ncomponents without many opinions on how they should be used. Designing a\npowerful, approachable, easy-to-learn-difficult-to-master framework _is_ hard,\nbut Ember is _very_ opinionated.\n\nIt seems to me like the Ember team and contributors would be better served by\nfollowing these design goals; spending more time observing how web developers\nuse their low-level APIs when crafting solutions and less time trying to get a\nhigh-level rich-web application framework right the first time. Perhaps this is\nwhy the path to Ember's 1.0 release has been so full of frequent, [backwards\ncompatibility breaking](https://meta.stackoverflow.com/a/163861) API changes.\n\n# The Angular Approach\n\nInitially I was skeptical about the power of\n[Angular](https://www.angularjs.org), having spent a good 18 months of my life\ninvested in writing applications with Backbone I wasn't eager to make a jump to\nanother framework. Thankfully my skepticism was quickly swept aside as I\ndiscovered the beauty in the simplicity of the Angular API. With Angular, I\ndon't have to extend framework built-in objects or methods; I can just use\nPOJSO's (Plain Old JavaScript Objects) and functions. I also don't have to\nspend a lot of time thinking about how to structure my application thanks to\n[`angular.module`](https://docs.angularjs.org/guide/module) and built-in\n[dependency injection](https://docs.angularjs.org/guide/di). Angular _really_\nhits the sweet spot between low-level components and _tightly scoped_\nhigh-level abstractions. It provides high-level features that each have a\nsingular focus as well as low-level components that I can craft into\ndomain-specific solutions within my applications.\n\nThe ability to craft custom markup through\n[`angular.directive`](https://docs.angularjs.org/guide/directive) is an\ninteresting high-level piece in that it has the power to create custom\ncomponents that are as coarse or granular as you need them to be. Angular is\n_just_ opinionated enough that it allows developers to work with the low-level\ncomponents provided to craft higher level abstractions. In fact, I think that\nis the core benefit of Angular. Having the power to abstract:\n\n```html\n<div id=\"chart\" data-type=\"bar\">\n  <div class=\"legend\"></div>\n  ... lots of other stuff\n</div>\n```\n\ninto\n\n```html\n<bar-chart></bar-chart>\n```\n\nis an incredibly powerful idea.\n\n# Web Components and the future of Markup\n\nOne of the most exciting changes to the Web Platform in the last five years is\nthe upcoming [Web\nComponents](https://www.w3.org/TR/2013/WD-components-intro-20130606/) spec.\n[Eric\nBidelman](https://www.google.ca/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CC0QFjAA&url=https%3A%2F%2Ftwitter.com%2Febidel&ei=_EDLUbuIK8iHywGUuYHoDg&usg=AFQjCNHgffvpgL9vHcpCK96uvkRqTmUkzg&bvm=bv.48340889,d.aWc)\ngave a [great overview](https://www.youtube.com/watch?v=fqULJBBEVQE) of it\nduring Google IO this year and [Alex Komoroske](https://twitter.com/jkomoros)\nand [Matthew McNulty](https://twitter.com/mattsmcnulty) had an [amazing\ndemo](https://www.youtube.com/watch?v=0g0oOOT86NY) that showcased some of the\ncapabilities. I'm excited about Web Components because it will allow web\ndevelopers to experiment at a lower-level by reshaping the way that we write\nmarkup. It will also offer true encapsulation on the web, a feature that has\nbeen sorely lacking.\n\nIt seems like the lessons the Angular team have learned are helping to shape\nthe direction of Web Components. In fact, [Miško\nHevery](https://twitter.com/mhevery) from the Angular team has [this to\nsay](https://groups.google.com/forum/#!msg/polymer-dev/4RSYaKmbtEk/uYnY3900wpIJ)\non Angular + Web Components:\n\n> Web Components (Polymer, Ember, or any other framework/library) will work\n seamlessly within Angular apps and directives.\n\n> Components written in Angular will export to Web Components (to be used by\n Polymer, Ember, or any other framework/library).\n\nThe awesome thing about Angular and Polymer is that you can use them to achieve\nthese kinds of markup abstractions in your applications right now, along with\nall the other great features they provide. I'm eager to see how the lower-level\nfeatures in ES6 and low-level libraries like Polymer are going to be used by\ndevelopers to create even more amazing frameworks in the future.\n\n# Moving the Web Forward with Low-Level APIs\n\nI think Yehuda has it right; standards bodies need to focus less on getting\nhigh-level APIs right up front and more on providing developers with enough\nlow-level APIs with which to experiment. The same principle applies to the\ndesign of JavaScript application frameworks. My hope is that the standards\nbodies _and_ JavaScript framework authors embrace this decentralized approach\nto design going forward. Ideally this will move the web development community\nbeyond rhetoric and zero-sum thinking, and into an age of innovation.\n"
  },
  "attributes": {
    "title": "What Polymer and Angular tell us about the future success of the Web Platform and JavaScript Frameworks",
    "date": "2013-08-08"
  },
  "markdown": "\n> Yehuda Katz recently gave a talk entitled [\"The Future of the Client-Side\nWeb\"](https://www.youtube.com/watch?v=EcyxXPILO8E) in which he detailed the\ncurrent challenges that web standards bodies face when trying to design APIs\nfor web developers to use. In this talk, Yehuda also highlighted Google's\nrecently announced [Polymer Project](https://www.polymer-project.org/) as a good\nexample of the right way to push the web platform forward.\n\nPolymer provides a \"low enough\" level API that gives web developers the power\nto redefine the way they write markup using the power of newer features coming\nto JavaScript in [ES6](https://tc39wiki.calculist.org/es6/). The specifics of\nthe implementation aren't relevant to what I want to say here, but Yehuda does\na great job covering the details at a high level in the video; I suggest you\nwatch it if they interest you.\n\nWhat I found interesting was the _message_ that was at the heart of the talk,\nhere's my paraphrased version:\n\n> Web Platform standards bodies need to focus less on getting implementations\n> of new APIs right the first time (hello\n> [AppCache](https://www.w3.org/Bugs/Public/show_bug.cgi?id=14702)) and instead\n> provide web developers with a set of lower level APIs that are exposed to\n> JavaScript. When this approach has been followed, developers are capable of\n> iterating far faster than standards bodies which results in consensus on API\n> design being reached faster and with less upfront design.\n\nThis is a fundamental shift in thinking that should be embraced and I believe\nthis approach has already been validated by a number of well-known JavaScript\nlibraries.\n\n# The Backbone Lesson\n\nSince its release, [Backbone](https://documentcloud.github.io/backbone/) has\nexploded in popularity and many [other](https://github.com/chaplinjs/chaplin)\n[frameworks](https://github.com/marionettejs/backbone.marionette) have since\nbeen built on top of the low-level components it provides. [Jeremy\nAshkenas](https://www.twitter.com/jashkenas) and the team at [Document\nCloud](https://www.documentcloud.org) did an amazing job of releasing a set of\ncomponents that can be adapted to fit almost any scenario when building a web\napplication&mdash;from simple uses of Backbone.View inside an existing legacy\napplication all the way up to writing a self-contained application that runs in\nthe browser.\n\nWhen I first started working in Backbone almost two years ago, I remember\nfeeling overwhelmed at how I was supposed to use all the pieces provided. I\nbelieve this speaks to the essence of how Backbone was created, and looking\nback now it is clear to me that Backbone follows the design model that Yehuda\npraises in his talk; it gave us a low-level set of components and didn't really\nenforce any particular design decisions on how to use them&mdash;aside from an\nimportant guiding principle: get your data out of the DOM.\n\n# The Ember Conundrum\n\nA recent blog post comparing [Ember](https://emberjs.com/) and\nAngular&mdash;originally entitled [\"AngularJS vs Ember, It's not even\nclose\"](https://eviltrout.com/2013/06/15/ember-vs-angular-its-not-even-close.html)&mdash;highlights\nsome perceived shortcomings of Angular, chief among them being there are too\nmany pitfalls in the simplistic features Angular provides and the Angular team\nshould strive to provide higher-level conventions/components that developers\ncan follow. While Yehuda didn't write the comparison post, the point of view\nexpressed by the author really struck me as being in stark contrast to the\ndecentralized/low-level API design approach that Yehuda extols the virtues of\nin his talk: success is realized when developers are given access to low-level\ncomponents without many opinions on how they should be used. Designing a\npowerful, approachable, easy-to-learn-difficult-to-master framework _is_ hard,\nbut Ember is _very_ opinionated.\n\nIt seems to me like the Ember team and contributors would be better served by\nfollowing these design goals; spending more time observing how web developers\nuse their low-level APIs when crafting solutions and less time trying to get a\nhigh-level rich-web application framework right the first time. Perhaps this is\nwhy the path to Ember's 1.0 release has been so full of frequent, [backwards\ncompatibility breaking](https://meta.stackoverflow.com/a/163861) API changes.\n\n# The Angular Approach\n\nInitially I was skeptical about the power of\n[Angular](https://www.angularjs.org), having spent a good 18 months of my life\ninvested in writing applications with Backbone I wasn't eager to make a jump to\nanother framework. Thankfully my skepticism was quickly swept aside as I\ndiscovered the beauty in the simplicity of the Angular API. With Angular, I\ndon't have to extend framework built-in objects or methods; I can just use\nPOJSO's (Plain Old JavaScript Objects) and functions. I also don't have to\nspend a lot of time thinking about how to structure my application thanks to\n[`angular.module`](https://docs.angularjs.org/guide/module) and built-in\n[dependency injection](https://docs.angularjs.org/guide/di). Angular _really_\nhits the sweet spot between low-level components and _tightly scoped_\nhigh-level abstractions. It provides high-level features that each have a\nsingular focus as well as low-level components that I can craft into\ndomain-specific solutions within my applications.\n\nThe ability to craft custom markup through\n[`angular.directive`](https://docs.angularjs.org/guide/directive) is an\ninteresting high-level piece in that it has the power to create custom\ncomponents that are as coarse or granular as you need them to be. Angular is\n_just_ opinionated enough that it allows developers to work with the low-level\ncomponents provided to craft higher level abstractions. In fact, I think that\nis the core benefit of Angular. Having the power to abstract:\n\n```html\n<div id=\"chart\" data-type=\"bar\">\n  <div class=\"legend\"></div>\n  ... lots of other stuff\n</div>\n```\n\ninto\n\n```html\n<bar-chart></bar-chart>\n```\n\nis an incredibly powerful idea.\n\n# Web Components and the future of Markup\n\nOne of the most exciting changes to the Web Platform in the last five years is\nthe upcoming [Web\nComponents](https://www.w3.org/TR/2013/WD-components-intro-20130606/) spec.\n[Eric\nBidelman](https://www.google.ca/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CC0QFjAA&url=https%3A%2F%2Ftwitter.com%2Febidel&ei=_EDLUbuIK8iHywGUuYHoDg&usg=AFQjCNHgffvpgL9vHcpCK96uvkRqTmUkzg&bvm=bv.48340889,d.aWc)\ngave a [great overview](https://www.youtube.com/watch?v=fqULJBBEVQE) of it\nduring Google IO this year and [Alex Komoroske](https://twitter.com/jkomoros)\nand [Matthew McNulty](https://twitter.com/mattsmcnulty) had an [amazing\ndemo](https://www.youtube.com/watch?v=0g0oOOT86NY) that showcased some of the\ncapabilities. I'm excited about Web Components because it will allow web\ndevelopers to experiment at a lower-level by reshaping the way that we write\nmarkup. It will also offer true encapsulation on the web, a feature that has\nbeen sorely lacking.\n\nIt seems like the lessons the Angular team have learned are helping to shape\nthe direction of Web Components. In fact, [Miško\nHevery](https://twitter.com/mhevery) from the Angular team has [this to\nsay](https://groups.google.com/forum/#!msg/polymer-dev/4RSYaKmbtEk/uYnY3900wpIJ)\non Angular + Web Components:\n\n> Web Components (Polymer, Ember, or any other framework/library) will work\n seamlessly within Angular apps and directives.\n\n> Components written in Angular will export to Web Components (to be used by\n Polymer, Ember, or any other framework/library).\n\nThe awesome thing about Angular and Polymer is that you can use them to achieve\nthese kinds of markup abstractions in your applications right now, along with\nall the other great features they provide. I'm eager to see how the lower-level\nfeatures in ES6 and low-level libraries like Polymer are going to be used by\ndevelopers to create even more amazing frameworks in the future.\n\n# Moving the Web Forward with Low-Level APIs\n\nI think Yehuda has it right; standards bodies need to focus less on getting\nhigh-level APIs right up front and more on providing developers with enough\nlow-level APIs with which to experiment. The same principle applies to the\ndesign of JavaScript application frameworks. My hope is that the standards\nbodies _and_ JavaScript framework authors embrace this decentralized approach\nto design going forward. Ideally this will move the web development community\nbeyond rhetoric and zero-sum thinking, and into an age of innovation.\n"
}></pre></div><div><a href="/posts/2013-06-18-frontend-workflows-with-grunt-and-angularjs.html">Frontend Workflows with Grunt &amp; Angular JS</a><pre><{
  "path": "app/posts/2013-06-18-frontend-workflows-with-grunt-and-angularjs.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Frontend Workflows with Grunt & Angular JS",
      "date": "2013-06-18"
    },
    "source": "\n> A screencast that shows front-end developers how they can craft workflows with Grunt JS, along with some specific workflow improvements when working with Angular JS.\n\n<iframe src=\"https://www.youtube.com/embed/fSAgFxjFSqY?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Github Source: https://github.com/davemo/frontend-workflows-with-grunt-and-angularjs\n- Resource Bundle: https://blog.davemo.com/posts/2007-01-01-bundle-links.html#frontend-workflows-grunt-and-angular\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
  },
  "attributes": {
    "title": "Frontend Workflows with Grunt & Angular JS",
    "date": "2013-06-18"
  },
  "markdown": "\n> A screencast that shows front-end developers how they can craft workflows with Grunt JS, along with some specific workflow improvements when working with Angular JS.\n\n<iframe src=\"https://www.youtube.com/embed/fSAgFxjFSqY?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Github Source: https://github.com/davemo/frontend-workflows-with-grunt-and-angularjs\n- Resource Bundle: https://blog.davemo.com/posts/2007-01-01-bundle-links.html#frontend-workflows-grunt-and-angular\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
}></{
  "path": "app/posts/2013-06-18-frontend-workflows-with-grunt-and-angularjs.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Frontend Workflows with Grunt & Angular JS",
      "date": "2013-06-18"
    },
    "source": "\n> A screencast that shows front-end developers how they can craft workflows with Grunt JS, along with some specific workflow improvements when working with Angular JS.\n\n<iframe src=\"https://www.youtube.com/embed/fSAgFxjFSqY?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Github Source: https://github.com/davemo/frontend-workflows-with-grunt-and-angularjs\n- Resource Bundle: https://blog.davemo.com/posts/2007-01-01-bundle-links.html#frontend-workflows-grunt-and-angular\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
  },
  "attributes": {
    "title": "Frontend Workflows with Grunt & Angular JS",
    "date": "2013-06-18"
  },
  "markdown": "\n> A screencast that shows front-end developers how they can craft workflows with Grunt JS, along with some specific workflow improvements when working with Angular JS.\n\n<iframe src=\"https://www.youtube.com/embed/fSAgFxjFSqY?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Github Source: https://github.com/davemo/frontend-workflows-with-grunt-and-angularjs\n- Resource Bundle: https://blog.davemo.com/posts/2007-01-01-bundle-links.html#frontend-workflows-grunt-and-angular\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
}></pre></div><div><a href="/posts/2013-05-27-security-with-angular-js.html">Security with Angular JS</a><pre><{
  "path": "app/posts/2013-05-27-security-with-angular-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Security with Angular JS",
      "date": "2013-05-27"
    },
    "source": "\n> A brief look at some common-sense ways that you can secure a web application written with Angular JS and Laravel 4.\n\n<iframe src=\"https://www.youtube.com/embed/18ifoT-Id54?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nBy watching this screencast you can expect to learn about:\n\n- 3 common-sense ways to secure your web application\n- angular.constant\n- ng-init\n- ng-sanitize\n- Laravel CSRF support, route filters, and built in protection\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
  },
  "attributes": {
    "title": "Security with Angular JS",
    "date": "2013-05-27"
  },
  "markdown": "\n> A brief look at some common-sense ways that you can secure a web application written with Angular JS and Laravel 4.\n\n<iframe src=\"https://www.youtube.com/embed/18ifoT-Id54?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nBy watching this screencast you can expect to learn about:\n\n- 3 common-sense ways to secure your web application\n- angular.constant\n- ng-init\n- ng-sanitize\n- Laravel CSRF support, route filters, and built in protection\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
}></{
  "path": "app/posts/2013-05-27-security-with-angular-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Security with Angular JS",
      "date": "2013-05-27"
    },
    "source": "\n> A brief look at some common-sense ways that you can secure a web application written with Angular JS and Laravel 4.\n\n<iframe src=\"https://www.youtube.com/embed/18ifoT-Id54?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nBy watching this screencast you can expect to learn about:\n\n- 3 common-sense ways to secure your web application\n- angular.constant\n- ng-init\n- ng-sanitize\n- Laravel CSRF support, route filters, and built in protection\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
  },
  "attributes": {
    "title": "Security with Angular JS",
    "date": "2013-05-27"
  },
  "markdown": "\n> A brief look at some common-sense ways that you can secure a web application written with Angular JS and Laravel 4.\n\n<iframe src=\"https://www.youtube.com/embed/18ifoT-Id54?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nBy watching this screencast you can expect to learn about:\n\n- 3 common-sense ways to secure your web application\n- angular.constant\n- ng-init\n- ng-sanitize\n- Laravel CSRF support, route filters, and built in protection\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
}></pre></div><div><a href="/posts/2013-05-21-end-to-end-with-angularjs.html">End to End with Angular JS</a><pre><{
  "path": "app/posts/2013-05-21-end-to-end-with-angularjs.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "End to End with Angular JS",
      "date": "2013-05-21"
    },
    "source": "\n> A more intermediate/advanced look at building an AngularJS application backed by a MySQL database using the Laravel 4 PHP Web Application Framework.\n\n<iframe src=\"https://www.youtube.com/embed/hqAyiqUs93c?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nThis is an extension of my screencast [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE) that focuses more on intermediate/advanced topics and walks through creating a working web application on top of the Laravel 4 Web Application Framework.\n\nThings you can expect to learn:\n\n* $http\n* $rootScope\n* taking the [AuthenticationService](https://github.com/davemo/intro-to-angularjs/blob/master/app/js/app.js#L19) we built earlier end-to-end\n* creating a FlashService for displaying alerts to users\n* access control for client-side routes with $rootScope and $routeProvider\n* $httpProvider.responseInterceptors and logging out users automatically if serverside sessions expire\n* $routeProvider.resolve property and making view rendering data dependent\n* laravel 4 migrations, controllers, models, and authentication\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
  },
  "attributes": {
    "title": "End to End with Angular JS",
    "date": "2013-05-21"
  },
  "markdown": "\n> A more intermediate/advanced look at building an AngularJS application backed by a MySQL database using the Laravel 4 PHP Web Application Framework.\n\n<iframe src=\"https://www.youtube.com/embed/hqAyiqUs93c?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nThis is an extension of my screencast [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE) that focuses more on intermediate/advanced topics and walks through creating a working web application on top of the Laravel 4 Web Application Framework.\n\nThings you can expect to learn:\n\n* $http\n* $rootScope\n* taking the [AuthenticationService](https://github.com/davemo/intro-to-angularjs/blob/master/app/js/app.js#L19) we built earlier end-to-end\n* creating a FlashService for displaying alerts to users\n* access control for client-side routes with $rootScope and $routeProvider\n* $httpProvider.responseInterceptors and logging out users automatically if serverside sessions expire\n* $routeProvider.resolve property and making view rendering data dependent\n* laravel 4 migrations, controllers, models, and authentication\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
}></{
  "path": "app/posts/2013-05-21-end-to-end-with-angularjs.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "End to End with Angular JS",
      "date": "2013-05-21"
    },
    "source": "\n> A more intermediate/advanced look at building an AngularJS application backed by a MySQL database using the Laravel 4 PHP Web Application Framework.\n\n<iframe src=\"https://www.youtube.com/embed/hqAyiqUs93c?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nThis is an extension of my screencast [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE) that focuses more on intermediate/advanced topics and walks through creating a working web application on top of the Laravel 4 Web Application Framework.\n\nThings you can expect to learn:\n\n* $http\n* $rootScope\n* taking the [AuthenticationService](https://github.com/davemo/intro-to-angularjs/blob/master/app/js/app.js#L19) we built earlier end-to-end\n* creating a FlashService for displaying alerts to users\n* access control for client-side routes with $rootScope and $routeProvider\n* $httpProvider.responseInterceptors and logging out users automatically if serverside sessions expire\n* $routeProvider.resolve property and making view rendering data dependent\n* laravel 4 migrations, controllers, models, and authentication\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
  },
  "attributes": {
    "title": "End to End with Angular JS",
    "date": "2013-05-21"
  },
  "markdown": "\n> A more intermediate/advanced look at building an AngularJS application backed by a MySQL database using the Laravel 4 PHP Web Application Framework.\n\n<iframe src=\"https://www.youtube.com/embed/hqAyiqUs93c?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\nThis is an extension of my screencast [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE) that focuses more on intermediate/advanced topics and walks through creating a working web application on top of the Laravel 4 Web Application Framework.\n\nThings you can expect to learn:\n\n* $http\n* $rootScope\n* taking the [AuthenticationService](https://github.com/davemo/intro-to-angularjs/blob/master/app/js/app.js#L19) we built earlier end-to-end\n* creating a FlashService for displaying alerts to users\n* access control for client-side routes with $rootScope and $routeProvider\n* $httpProvider.responseInterceptors and logging out users automatically if serverside sessions expire\n* $routeProvider.resolve property and making view rendering data dependent\n* laravel 4 migrations, controllers, models, and authentication\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\n"
}></pre></div><div><a href="/posts/2013-05-03-introduction-to-angular-js.html">Introduction to Angular JS</a><pre><{
  "path": "app/posts/2013-05-03-introduction-to-angular-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Introduction to Angular JS",
      "date": "2013-05-03"
    },
    "source": "\n> Walk through building a sample application with AngularJS to learn some of the basics along with some commentary that contrasts it with jQuery / Backbone.JS\n\n<iframe src=\"https://www.youtube.com/embed/8ILQOFAgaXE?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\nSome additional high-quality resources:\n\n- Excellent Tutorials by John Lindquist: http://www.egghead.io\n- Basic Source: https://github.com/davemo/intro-to-angularjs\n- Advanced Source: https://github.com/davemo/lineman-angular-template\n- An Intro to Lineman JS: http://www.youtube.com/watch?v=BmZ4XRErYAI"
  },
  "attributes": {
    "title": "Introduction to Angular JS",
    "date": "2013-05-03"
  },
  "markdown": "\n> Walk through building a sample application with AngularJS to learn some of the basics along with some commentary that contrasts it with jQuery / Backbone.JS\n\n<iframe src=\"https://www.youtube.com/embed/8ILQOFAgaXE?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\nSome additional high-quality resources:\n\n- Excellent Tutorials by John Lindquist: http://www.egghead.io\n- Basic Source: https://github.com/davemo/intro-to-angularjs\n- Advanced Source: https://github.com/davemo/lineman-angular-template\n- An Intro to Lineman JS: http://www.youtube.com/watch?v=BmZ4XRErYAI"
}></{
  "path": "app/posts/2013-05-03-introduction-to-angular-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Introduction to Angular JS",
      "date": "2013-05-03"
    },
    "source": "\n> Walk through building a sample application with AngularJS to learn some of the basics along with some commentary that contrasts it with jQuery / Backbone.JS\n\n<iframe src=\"https://www.youtube.com/embed/8ILQOFAgaXE?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\nSome additional high-quality resources:\n\n- Excellent Tutorials by John Lindquist: http://www.egghead.io\n- Basic Source: https://github.com/davemo/intro-to-angularjs\n- Advanced Source: https://github.com/davemo/lineman-angular-template\n- An Intro to Lineman JS: http://www.youtube.com/watch?v=BmZ4XRErYAI"
  },
  "attributes": {
    "title": "Introduction to Angular JS",
    "date": "2013-05-03"
  },
  "markdown": "\n> Walk through building a sample application with AngularJS to learn some of the basics along with some commentary that contrasts it with jQuery / Backbone.JS\n\n<iframe src=\"https://www.youtube.com/embed/8ILQOFAgaXE?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\nThis is part of a screencast series on Angular JS\n\n1. [Intro to Angular JS](http://www.youtube.com/watch?v=8ILQOFAgaXE)\n1. [End to End with Angular JS](http://www.youtube.com/watch?v=hqAyiqUs93c)\n1. [Security with Angular JS](http://www.youtube.com/watch?v=18ifoT-Id54)\n1. [Frontend Workflows with Grunt and Angular JS](http://www.youtube.com/watch?v=fSAgFxjFSqY)\n1. [Testing Strategies for Angular JS](https://www.youtube.com/watch?v=UYVcY9EJcRs)\n1. [Advanced Directives with Angular JS (Part 1)](https://www.youtube.com/watch?v=Ty8XcASK9js)\n1. [Advanced Directives with Angular JS (Part 2)](https://www.youtube.com/watch?v=4zG8SfucUzg)\n\nSome additional high-quality resources:\n\n- Excellent Tutorials by John Lindquist: http://www.egghead.io\n- Basic Source: https://github.com/davemo/intro-to-angularjs\n- Advanced Source: https://github.com/davemo/lineman-angular-template\n- An Intro to Lineman JS: http://www.youtube.com/watch?v=BmZ4XRErYAI"
}></pre></div><div><a href="/posts/2012-11-02-inversion-of-control-the-ui-thread-and-backbone-js-views.html">Inversion of Control, the UI thread, and Backbone JS</a><pre><{
  "path": "app/posts/2012-11-02-inversion-of-control-the-ui-thread-and-backbone-js-views.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Inversion of Control, the UI thread, and Backbone JS",
      "date": "2012-11-02"
    },
    "source": "\n> In this screencast I examine how understanding the browsers UI Thread and the \"Inversion of Control\" principle can be used to make life easier when working with Backbone.JS views.\n\n<iframe src=\"https://www.youtube.com/embed/mU1JcPikdMs?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Code: https://github.com/davemo/zombie-events/tree/inversion-of-control\n"
  },
  "attributes": {
    "title": "Inversion of Control, the UI thread, and Backbone JS",
    "date": "2012-11-02"
  },
  "markdown": "\n> In this screencast I examine how understanding the browsers UI Thread and the \"Inversion of Control\" principle can be used to make life easier when working with Backbone.JS views.\n\n<iframe src=\"https://www.youtube.com/embed/mU1JcPikdMs?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Code: https://github.com/davemo/zombie-events/tree/inversion-of-control\n"
}></{
  "path": "app/posts/2012-11-02-inversion-of-control-the-ui-thread-and-backbone-js-views.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Inversion of Control, the UI thread, and Backbone JS",
      "date": "2012-11-02"
    },
    "source": "\n> In this screencast I examine how understanding the browsers UI Thread and the \"Inversion of Control\" principle can be used to make life easier when working with Backbone.JS views.\n\n<iframe src=\"https://www.youtube.com/embed/mU1JcPikdMs?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Code: https://github.com/davemo/zombie-events/tree/inversion-of-control\n"
  },
  "attributes": {
    "title": "Inversion of Control, the UI thread, and Backbone JS",
    "date": "2012-11-02"
  },
  "markdown": "\n> In this screencast I examine how understanding the browsers UI Thread and the \"Inversion of Control\" principle can be used to make life easier when working with Backbone.JS views.\n\n<iframe src=\"https://www.youtube.com/embed/mU1JcPikdMs?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Code: https://github.com/davemo/zombie-events/tree/inversion-of-control\n"
}></pre></div><div><a href="/posts/2012-09-28-understanding-view-zombie-events-in-backbone-js.html">Understanding View Zombie Events in Backbone JS</a><pre><{
  "path": "app/posts/2012-09-28-understanding-view-zombie-events-in-backbone-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Understanding View Zombie Events in Backbone JS",
      "date": "2012-09-28"
    },
    "source": "\n> A quick examination of view level zombie events in Backbone.JS, how they manifest, and one solution to help eliminate them.\n\n<iframe src=\"https://www.youtube.com/embed/hb8_IReoms8?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Code: https://github.com/davemo/zombie-events\n"
  },
  "attributes": {
    "title": "Understanding View Zombie Events in Backbone JS",
    "date": "2012-09-28"
  },
  "markdown": "\n> A quick examination of view level zombie events in Backbone.JS, how they manifest, and one solution to help eliminate them.\n\n<iframe src=\"https://www.youtube.com/embed/hb8_IReoms8?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Code: https://github.com/davemo/zombie-events\n"
}></{
  "path": "app/posts/2012-09-28-understanding-view-zombie-events-in-backbone-js.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Understanding View Zombie Events in Backbone JS",
      "date": "2012-09-28"
    },
    "source": "\n> A quick examination of view level zombie events in Backbone.JS, how they manifest, and one solution to help eliminate them.\n\n<iframe src=\"https://www.youtube.com/embed/hb8_IReoms8?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Code: https://github.com/davemo/zombie-events\n"
  },
  "attributes": {
    "title": "Understanding View Zombie Events in Backbone JS",
    "date": "2012-09-28"
  },
  "markdown": "\n> A quick examination of view level zombie events in Backbone.JS, how they manifest, and one solution to help eliminate them.\n\n<iframe src=\"https://www.youtube.com/embed/hb8_IReoms8?wmode=transparent\" allowfullscreen frameborder=\"0\" height=\"417\" width=\"500\"></iframe>\n\n# Resources\n\n- Code: https://github.com/davemo/zombie-events\n"
}></pre></div><div><a href="/posts/2012-08-22-the-benefits-of-interactive-prototyping.html">The Benefits of Interactive Prototyping</a><pre><{
  "path": "app/posts/2012-08-22-the-benefits-of-interactive-prototyping.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The Benefits of Interactive Prototyping",
      "date": "2012-08-22"
    },
    "source": "\n> I had a small epiphany today while working on a new prototype for a client:\n\"different stages of prototyping yield different levels of information\". I know\nI know, not much of a brainwave there, right? I was never one for writing\nheadlines and there's a lot of knowledge packed into that statement, so stick\nwith me as I attempt to unpack it for you :)\n\n## The Gist\n\nThose familiar with it will know there are some basic ways to prototype that\nprogress upwards in terms of fidelity. At the lowest end of the fidelity\nspectrum people often start by drawing lots of boxes and arrows on paper. Next\ncomes some of the static mockup tools that are popular today, like\n[Balsamiq](https://www.balsamiq.com/), [Hot Gloo](https://www.hotgloo.com/),\n[Fireworks](https://www.adobe.com/products/fireworks.html) (and many more).\n\nFurther up the fidelity chain comes prototyping in the Browser which has some\ninteresting advantages over static prototypes; what struck me today was how much\nmore I could learn from prototyping in the browser when I moved from static\nmarkup into interactivity. Each level of fidelity provides different things we\ncan learn; at a high level this is how I think it breaks down:\n\n-   Paper Prototyping\n    -   What I think the information architecture hierarchy should be.\n\n-   Static Prototyping\n    -   How I think the information architecture hierarchy will flow from one\n        area to another.\n\n-   Browser Prototyping (Static)\n    -   How the information hierarchy actually flows from one area to another at\n        different screen resolutions.\n    -   How changes in typography, size, and placement affect the usability of\n        my information architecture.\n\n-   Browser Prototyping (Interactive)\n    -   How robust the information architecture and design are when considering\n        user interaction.\n    -   What things I should do first to improve my information architecture and\n        design.\n\nAs I read through the list above I notice a few interesting things. Firstly, the\nvalue of the information I receive increases as I move to a higher fidelity\nprototype. In Paper and Static prototyping the information I get isn't really\nall that useful; for the most part it is hypothetical. I can show it to others\nto get more feedback but it is still subjective; based on perception and varied\ninterpretation. It isn't until I move into prototyping with the Browser that I\ncan actually play with the information, architecture, and layout and start to\nget concrete information that will help me approach what I need to change in my\nnext iteration.\n\n## In Practice\n\nThe interface and interaction I have been prototyping the last two days is for a\nuser creating a fitness challenge comprised of multiple activities for multiple\nparticipants. As I was working to take my browser prototype from static to\ninteractive I discovered that even though I had a good idea of how the system I\nwas implementing worked I found I didn't have a great way to express the system\nthinking in a user interface that made sense to humans.\n\nSo often engineers have a great grasp on what the system requirements are for\nthe interface they are building that they end up building the interface as if it\nreads like machine language. In the last two days I feel it was very valuable to\nrepeatedly try to express the system constraints in \"plain old english\" as if I\nwere a user trying to interact with them, but I didn't come to that realization\nuntil I made the leap from static to interactive.\n\n* * * * *\n\n![Static Prototype\n1](https://f.cl.ly/items/3D1t0k1K073g2o3h3L3a/static.prototype.1.png)\n\nIn my first pass at the prototype with static content and no interaction this is\nwhat I came up with. The interaction theory was that users would fill in basic\ndetails about the fitness challenge and be able to see a preview summary of what\nthe challenge would look like before submitting to the server(you can see the\nsummary at the bottom of the screen). During this iteration I came to the\nrealization that that positioning the summary at the bottom of the screen does\nnothing to help users understand what it is they are doing; we ended up deciding\non a new layout that positions the summary to be always in the users view in the\nfollowing iteration.\n\n* * * * *\n\n![Static Prototype\n2](https://f.cl.ly/items/1W1T340A0W0V3c2T1Y2f/static.prototype.2.png)\n\nIn this iteration the idea for a \"live updating\" summary was the driver for the\nlayout change. We thought that if users could see the results of their\ninteraction taking shape live it would help to reinforce how the interface was\naffecting the output (challenge creation).\n\n* * * * *\n\n![iOS Static Prototype\n1](https://f.cl.ly/items/0E41451o0B1f1V1J2w2W/iOS.prototype.1.png)\n\n![iOS Static Prototype\n2](https://f.cl.ly/items/1F3r351R0G2Q1D3Q3p0E/iOS.prototype.2.png)\n\n![iOS Static Prototype\n3](https://f.cl.ly/items/2a0C3T3b1q1m293m0g1y/iOS.prototype.3.png)\n\nBecause one of our design constraints was to attempt to make this page work for\nboth desktop and mobile we implemented the [twitter bootstrap responsive\nstylesheet](https://twitter.github.com/bootstrap/scaffolding.html#responsive) so\nwe could play with the layout and see how it felt. This is one of the biggest\nbenefits of designing in a browser first and previewing the design in the iOS\nsimulator really helped to further shape the layout. Up to this point we were\nstill iterating with static markup and felt like we were making good progress\nwith the information we had received from in browser testing. The next step was\nto start wiring up user interactions to see what else was revealed.\n\n* * * * *\n\n![Dynamic Prototype\n1](https://f.cl.ly/items/0V4742133R030g453t1D/dynamic.prototype.1.png)\n\nI've been using [Backbone.JS](https://documentcloud.github.com/backbone/) for the\nlast 18 months and it's a wonderful tool for building prototypes with. We\ndecided to add some simple collection backed views and flesh out the user\ninteraction of adding Activities and having them update live in the preview.\nWhat this yielded first was a realization that our design didn't account for all\nthat many rules due to our fixed position summary preview. (note: the new [affix\nplugin](https://twitter.github.com/bootstrap/javascript.html#affix) in [bootstrap\n2.1](https://twitter.github.com/bootstrap/) is \\_great\\_ for this, but you should\nbe aware of how tall your content could potentially be!)\n\n* * * * *\n\n![Dynamic Prototype\n2](https://f.cl.ly/items/2T2h3a1y232u2a1a3619/dynamic.prototype.2.png)\n\nOops. You could say I should have encountered that in the static stage of in\nbrowser testing by adding more static data to test the layout, but I didn't and\nI find that this is often the case with static prototypes. Adding interactivity\nto a prototype helps to uncover places your design breaks down. It was at this\npoint I had a discussion with a teammate to demo what had been built so far and\nwe both came to the realization that the tabular display under the activities UI\nwas not user friendly. The interface for adding Activities seems to read like\nenglish (we arrived at that after a number of iterations) but the display of the\ndata isn't helpful to users at all and really mirrors how the underlying system\nstores the data.\n\n* * * * *\n\n## Moving Forward\n\nOur next step will be to prototype a layout where the summary preview \\_is\\_ the\ninterface to eliminate the \"system language\" from the interface altogether. In\nconclusion, I don't think we would have been able to iterate and refine our\napproach as effectively if we had not started in the browser and added\ninteractivity to the prototype soon after prototyping with static markup. The\nthings we can learn from interactive prototypes can really help crank out\ninterfaces that are much more usable.\n\nIf you aren't already prototyping interactivity in the browser I would encourage\nyou to start as soon as possible, the earlier you start the earlier you'll find\nout how to fix your interface! :)\n\n"
  },
  "attributes": {
    "title": "The Benefits of Interactive Prototyping",
    "date": "2012-08-22"
  },
  "markdown": "\n> I had a small epiphany today while working on a new prototype for a client:\n\"different stages of prototyping yield different levels of information\". I know\nI know, not much of a brainwave there, right? I was never one for writing\nheadlines and there's a lot of knowledge packed into that statement, so stick\nwith me as I attempt to unpack it for you :)\n\n## The Gist\n\nThose familiar with it will know there are some basic ways to prototype that\nprogress upwards in terms of fidelity. At the lowest end of the fidelity\nspectrum people often start by drawing lots of boxes and arrows on paper. Next\ncomes some of the static mockup tools that are popular today, like\n[Balsamiq](https://www.balsamiq.com/), [Hot Gloo](https://www.hotgloo.com/),\n[Fireworks](https://www.adobe.com/products/fireworks.html) (and many more).\n\nFurther up the fidelity chain comes prototyping in the Browser which has some\ninteresting advantages over static prototypes; what struck me today was how much\nmore I could learn from prototyping in the browser when I moved from static\nmarkup into interactivity. Each level of fidelity provides different things we\ncan learn; at a high level this is how I think it breaks down:\n\n-   Paper Prototyping\n    -   What I think the information architecture hierarchy should be.\n\n-   Static Prototyping\n    -   How I think the information architecture hierarchy will flow from one\n        area to another.\n\n-   Browser Prototyping (Static)\n    -   How the information hierarchy actually flows from one area to another at\n        different screen resolutions.\n    -   How changes in typography, size, and placement affect the usability of\n        my information architecture.\n\n-   Browser Prototyping (Interactive)\n    -   How robust the information architecture and design are when considering\n        user interaction.\n    -   What things I should do first to improve my information architecture and\n        design.\n\nAs I read through the list above I notice a few interesting things. Firstly, the\nvalue of the information I receive increases as I move to a higher fidelity\nprototype. In Paper and Static prototyping the information I get isn't really\nall that useful; for the most part it is hypothetical. I can show it to others\nto get more feedback but it is still subjective; based on perception and varied\ninterpretation. It isn't until I move into prototyping with the Browser that I\ncan actually play with the information, architecture, and layout and start to\nget concrete information that will help me approach what I need to change in my\nnext iteration.\n\n## In Practice\n\nThe interface and interaction I have been prototyping the last two days is for a\nuser creating a fitness challenge comprised of multiple activities for multiple\nparticipants. As I was working to take my browser prototype from static to\ninteractive I discovered that even though I had a good idea of how the system I\nwas implementing worked I found I didn't have a great way to express the system\nthinking in a user interface that made sense to humans.\n\nSo often engineers have a great grasp on what the system requirements are for\nthe interface they are building that they end up building the interface as if it\nreads like machine language. In the last two days I feel it was very valuable to\nrepeatedly try to express the system constraints in \"plain old english\" as if I\nwere a user trying to interact with them, but I didn't come to that realization\nuntil I made the leap from static to interactive.\n\n* * * * *\n\n![Static Prototype\n1](https://f.cl.ly/items/3D1t0k1K073g2o3h3L3a/static.prototype.1.png)\n\nIn my first pass at the prototype with static content and no interaction this is\nwhat I came up with. The interaction theory was that users would fill in basic\ndetails about the fitness challenge and be able to see a preview summary of what\nthe challenge would look like before submitting to the server(you can see the\nsummary at the bottom of the screen). During this iteration I came to the\nrealization that that positioning the summary at the bottom of the screen does\nnothing to help users understand what it is they are doing; we ended up deciding\non a new layout that positions the summary to be always in the users view in the\nfollowing iteration.\n\n* * * * *\n\n![Static Prototype\n2](https://f.cl.ly/items/1W1T340A0W0V3c2T1Y2f/static.prototype.2.png)\n\nIn this iteration the idea for a \"live updating\" summary was the driver for the\nlayout change. We thought that if users could see the results of their\ninteraction taking shape live it would help to reinforce how the interface was\naffecting the output (challenge creation).\n\n* * * * *\n\n![iOS Static Prototype\n1](https://f.cl.ly/items/0E41451o0B1f1V1J2w2W/iOS.prototype.1.png)\n\n![iOS Static Prototype\n2](https://f.cl.ly/items/1F3r351R0G2Q1D3Q3p0E/iOS.prototype.2.png)\n\n![iOS Static Prototype\n3](https://f.cl.ly/items/2a0C3T3b1q1m293m0g1y/iOS.prototype.3.png)\n\nBecause one of our design constraints was to attempt to make this page work for\nboth desktop and mobile we implemented the [twitter bootstrap responsive\nstylesheet](https://twitter.github.com/bootstrap/scaffolding.html#responsive) so\nwe could play with the layout and see how it felt. This is one of the biggest\nbenefits of designing in a browser first and previewing the design in the iOS\nsimulator really helped to further shape the layout. Up to this point we were\nstill iterating with static markup and felt like we were making good progress\nwith the information we had received from in browser testing. The next step was\nto start wiring up user interactions to see what else was revealed.\n\n* * * * *\n\n![Dynamic Prototype\n1](https://f.cl.ly/items/0V4742133R030g453t1D/dynamic.prototype.1.png)\n\nI've been using [Backbone.JS](https://documentcloud.github.com/backbone/) for the\nlast 18 months and it's a wonderful tool for building prototypes with. We\ndecided to add some simple collection backed views and flesh out the user\ninteraction of adding Activities and having them update live in the preview.\nWhat this yielded first was a realization that our design didn't account for all\nthat many rules due to our fixed position summary preview. (note: the new [affix\nplugin](https://twitter.github.com/bootstrap/javascript.html#affix) in [bootstrap\n2.1](https://twitter.github.com/bootstrap/) is \\_great\\_ for this, but you should\nbe aware of how tall your content could potentially be!)\n\n* * * * *\n\n![Dynamic Prototype\n2](https://f.cl.ly/items/2T2h3a1y232u2a1a3619/dynamic.prototype.2.png)\n\nOops. You could say I should have encountered that in the static stage of in\nbrowser testing by adding more static data to test the layout, but I didn't and\nI find that this is often the case with static prototypes. Adding interactivity\nto a prototype helps to uncover places your design breaks down. It was at this\npoint I had a discussion with a teammate to demo what had been built so far and\nwe both came to the realization that the tabular display under the activities UI\nwas not user friendly. The interface for adding Activities seems to read like\nenglish (we arrived at that after a number of iterations) but the display of the\ndata isn't helpful to users at all and really mirrors how the underlying system\nstores the data.\n\n* * * * *\n\n## Moving Forward\n\nOur next step will be to prototype a layout where the summary preview \\_is\\_ the\ninterface to eliminate the \"system language\" from the interface altogether. In\nconclusion, I don't think we would have been able to iterate and refine our\napproach as effectively if we had not started in the browser and added\ninteractivity to the prototype soon after prototyping with static markup. The\nthings we can learn from interactive prototypes can really help crank out\ninterfaces that are much more usable.\n\nIf you aren't already prototyping interactivity in the browser I would encourage\nyou to start as soon as possible, the earlier you start the earlier you'll find\nout how to fix your interface! :)\n\n"
}></{
  "path": "app/posts/2012-08-22-the-benefits-of-interactive-prototyping.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The Benefits of Interactive Prototyping",
      "date": "2012-08-22"
    },
    "source": "\n> I had a small epiphany today while working on a new prototype for a client:\n\"different stages of prototyping yield different levels of information\". I know\nI know, not much of a brainwave there, right? I was never one for writing\nheadlines and there's a lot of knowledge packed into that statement, so stick\nwith me as I attempt to unpack it for you :)\n\n## The Gist\n\nThose familiar with it will know there are some basic ways to prototype that\nprogress upwards in terms of fidelity. At the lowest end of the fidelity\nspectrum people often start by drawing lots of boxes and arrows on paper. Next\ncomes some of the static mockup tools that are popular today, like\n[Balsamiq](https://www.balsamiq.com/), [Hot Gloo](https://www.hotgloo.com/),\n[Fireworks](https://www.adobe.com/products/fireworks.html) (and many more).\n\nFurther up the fidelity chain comes prototyping in the Browser which has some\ninteresting advantages over static prototypes; what struck me today was how much\nmore I could learn from prototyping in the browser when I moved from static\nmarkup into interactivity. Each level of fidelity provides different things we\ncan learn; at a high level this is how I think it breaks down:\n\n-   Paper Prototyping\n    -   What I think the information architecture hierarchy should be.\n\n-   Static Prototyping\n    -   How I think the information architecture hierarchy will flow from one\n        area to another.\n\n-   Browser Prototyping (Static)\n    -   How the information hierarchy actually flows from one area to another at\n        different screen resolutions.\n    -   How changes in typography, size, and placement affect the usability of\n        my information architecture.\n\n-   Browser Prototyping (Interactive)\n    -   How robust the information architecture and design are when considering\n        user interaction.\n    -   What things I should do first to improve my information architecture and\n        design.\n\nAs I read through the list above I notice a few interesting things. Firstly, the\nvalue of the information I receive increases as I move to a higher fidelity\nprototype. In Paper and Static prototyping the information I get isn't really\nall that useful; for the most part it is hypothetical. I can show it to others\nto get more feedback but it is still subjective; based on perception and varied\ninterpretation. It isn't until I move into prototyping with the Browser that I\ncan actually play with the information, architecture, and layout and start to\nget concrete information that will help me approach what I need to change in my\nnext iteration.\n\n## In Practice\n\nThe interface and interaction I have been prototyping the last two days is for a\nuser creating a fitness challenge comprised of multiple activities for multiple\nparticipants. As I was working to take my browser prototype from static to\ninteractive I discovered that even though I had a good idea of how the system I\nwas implementing worked I found I didn't have a great way to express the system\nthinking in a user interface that made sense to humans.\n\nSo often engineers have a great grasp on what the system requirements are for\nthe interface they are building that they end up building the interface as if it\nreads like machine language. In the last two days I feel it was very valuable to\nrepeatedly try to express the system constraints in \"plain old english\" as if I\nwere a user trying to interact with them, but I didn't come to that realization\nuntil I made the leap from static to interactive.\n\n* * * * *\n\n![Static Prototype\n1](https://f.cl.ly/items/3D1t0k1K073g2o3h3L3a/static.prototype.1.png)\n\nIn my first pass at the prototype with static content and no interaction this is\nwhat I came up with. The interaction theory was that users would fill in basic\ndetails about the fitness challenge and be able to see a preview summary of what\nthe challenge would look like before submitting to the server(you can see the\nsummary at the bottom of the screen). During this iteration I came to the\nrealization that that positioning the summary at the bottom of the screen does\nnothing to help users understand what it is they are doing; we ended up deciding\non a new layout that positions the summary to be always in the users view in the\nfollowing iteration.\n\n* * * * *\n\n![Static Prototype\n2](https://f.cl.ly/items/1W1T340A0W0V3c2T1Y2f/static.prototype.2.png)\n\nIn this iteration the idea for a \"live updating\" summary was the driver for the\nlayout change. We thought that if users could see the results of their\ninteraction taking shape live it would help to reinforce how the interface was\naffecting the output (challenge creation).\n\n* * * * *\n\n![iOS Static Prototype\n1](https://f.cl.ly/items/0E41451o0B1f1V1J2w2W/iOS.prototype.1.png)\n\n![iOS Static Prototype\n2](https://f.cl.ly/items/1F3r351R0G2Q1D3Q3p0E/iOS.prototype.2.png)\n\n![iOS Static Prototype\n3](https://f.cl.ly/items/2a0C3T3b1q1m293m0g1y/iOS.prototype.3.png)\n\nBecause one of our design constraints was to attempt to make this page work for\nboth desktop and mobile we implemented the [twitter bootstrap responsive\nstylesheet](https://twitter.github.com/bootstrap/scaffolding.html#responsive) so\nwe could play with the layout and see how it felt. This is one of the biggest\nbenefits of designing in a browser first and previewing the design in the iOS\nsimulator really helped to further shape the layout. Up to this point we were\nstill iterating with static markup and felt like we were making good progress\nwith the information we had received from in browser testing. The next step was\nto start wiring up user interactions to see what else was revealed.\n\n* * * * *\n\n![Dynamic Prototype\n1](https://f.cl.ly/items/0V4742133R030g453t1D/dynamic.prototype.1.png)\n\nI've been using [Backbone.JS](https://documentcloud.github.com/backbone/) for the\nlast 18 months and it's a wonderful tool for building prototypes with. We\ndecided to add some simple collection backed views and flesh out the user\ninteraction of adding Activities and having them update live in the preview.\nWhat this yielded first was a realization that our design didn't account for all\nthat many rules due to our fixed position summary preview. (note: the new [affix\nplugin](https://twitter.github.com/bootstrap/javascript.html#affix) in [bootstrap\n2.1](https://twitter.github.com/bootstrap/) is \\_great\\_ for this, but you should\nbe aware of how tall your content could potentially be!)\n\n* * * * *\n\n![Dynamic Prototype\n2](https://f.cl.ly/items/2T2h3a1y232u2a1a3619/dynamic.prototype.2.png)\n\nOops. You could say I should have encountered that in the static stage of in\nbrowser testing by adding more static data to test the layout, but I didn't and\nI find that this is often the case with static prototypes. Adding interactivity\nto a prototype helps to uncover places your design breaks down. It was at this\npoint I had a discussion with a teammate to demo what had been built so far and\nwe both came to the realization that the tabular display under the activities UI\nwas not user friendly. The interface for adding Activities seems to read like\nenglish (we arrived at that after a number of iterations) but the display of the\ndata isn't helpful to users at all and really mirrors how the underlying system\nstores the data.\n\n* * * * *\n\n## Moving Forward\n\nOur next step will be to prototype a layout where the summary preview \\_is\\_ the\ninterface to eliminate the \"system language\" from the interface altogether. In\nconclusion, I don't think we would have been able to iterate and refine our\napproach as effectively if we had not started in the browser and added\ninteractivity to the prototype soon after prototyping with static markup. The\nthings we can learn from interactive prototypes can really help crank out\ninterfaces that are much more usable.\n\nIf you aren't already prototyping interactivity in the browser I would encourage\nyou to start as soon as possible, the earlier you start the earlier you'll find\nout how to fix your interface! :)\n\n"
  },
  "attributes": {
    "title": "The Benefits of Interactive Prototyping",
    "date": "2012-08-22"
  },
  "markdown": "\n> I had a small epiphany today while working on a new prototype for a client:\n\"different stages of prototyping yield different levels of information\". I know\nI know, not much of a brainwave there, right? I was never one for writing\nheadlines and there's a lot of knowledge packed into that statement, so stick\nwith me as I attempt to unpack it for you :)\n\n## The Gist\n\nThose familiar with it will know there are some basic ways to prototype that\nprogress upwards in terms of fidelity. At the lowest end of the fidelity\nspectrum people often start by drawing lots of boxes and arrows on paper. Next\ncomes some of the static mockup tools that are popular today, like\n[Balsamiq](https://www.balsamiq.com/), [Hot Gloo](https://www.hotgloo.com/),\n[Fireworks](https://www.adobe.com/products/fireworks.html) (and many more).\n\nFurther up the fidelity chain comes prototyping in the Browser which has some\ninteresting advantages over static prototypes; what struck me today was how much\nmore I could learn from prototyping in the browser when I moved from static\nmarkup into interactivity. Each level of fidelity provides different things we\ncan learn; at a high level this is how I think it breaks down:\n\n-   Paper Prototyping\n    -   What I think the information architecture hierarchy should be.\n\n-   Static Prototyping\n    -   How I think the information architecture hierarchy will flow from one\n        area to another.\n\n-   Browser Prototyping (Static)\n    -   How the information hierarchy actually flows from one area to another at\n        different screen resolutions.\n    -   How changes in typography, size, and placement affect the usability of\n        my information architecture.\n\n-   Browser Prototyping (Interactive)\n    -   How robust the information architecture and design are when considering\n        user interaction.\n    -   What things I should do first to improve my information architecture and\n        design.\n\nAs I read through the list above I notice a few interesting things. Firstly, the\nvalue of the information I receive increases as I move to a higher fidelity\nprototype. In Paper and Static prototyping the information I get isn't really\nall that useful; for the most part it is hypothetical. I can show it to others\nto get more feedback but it is still subjective; based on perception and varied\ninterpretation. It isn't until I move into prototyping with the Browser that I\ncan actually play with the information, architecture, and layout and start to\nget concrete information that will help me approach what I need to change in my\nnext iteration.\n\n## In Practice\n\nThe interface and interaction I have been prototyping the last two days is for a\nuser creating a fitness challenge comprised of multiple activities for multiple\nparticipants. As I was working to take my browser prototype from static to\ninteractive I discovered that even though I had a good idea of how the system I\nwas implementing worked I found I didn't have a great way to express the system\nthinking in a user interface that made sense to humans.\n\nSo often engineers have a great grasp on what the system requirements are for\nthe interface they are building that they end up building the interface as if it\nreads like machine language. In the last two days I feel it was very valuable to\nrepeatedly try to express the system constraints in \"plain old english\" as if I\nwere a user trying to interact with them, but I didn't come to that realization\nuntil I made the leap from static to interactive.\n\n* * * * *\n\n![Static Prototype\n1](https://f.cl.ly/items/3D1t0k1K073g2o3h3L3a/static.prototype.1.png)\n\nIn my first pass at the prototype with static content and no interaction this is\nwhat I came up with. The interaction theory was that users would fill in basic\ndetails about the fitness challenge and be able to see a preview summary of what\nthe challenge would look like before submitting to the server(you can see the\nsummary at the bottom of the screen). During this iteration I came to the\nrealization that that positioning the summary at the bottom of the screen does\nnothing to help users understand what it is they are doing; we ended up deciding\non a new layout that positions the summary to be always in the users view in the\nfollowing iteration.\n\n* * * * *\n\n![Static Prototype\n2](https://f.cl.ly/items/1W1T340A0W0V3c2T1Y2f/static.prototype.2.png)\n\nIn this iteration the idea for a \"live updating\" summary was the driver for the\nlayout change. We thought that if users could see the results of their\ninteraction taking shape live it would help to reinforce how the interface was\naffecting the output (challenge creation).\n\n* * * * *\n\n![iOS Static Prototype\n1](https://f.cl.ly/items/0E41451o0B1f1V1J2w2W/iOS.prototype.1.png)\n\n![iOS Static Prototype\n2](https://f.cl.ly/items/1F3r351R0G2Q1D3Q3p0E/iOS.prototype.2.png)\n\n![iOS Static Prototype\n3](https://f.cl.ly/items/2a0C3T3b1q1m293m0g1y/iOS.prototype.3.png)\n\nBecause one of our design constraints was to attempt to make this page work for\nboth desktop and mobile we implemented the [twitter bootstrap responsive\nstylesheet](https://twitter.github.com/bootstrap/scaffolding.html#responsive) so\nwe could play with the layout and see how it felt. This is one of the biggest\nbenefits of designing in a browser first and previewing the design in the iOS\nsimulator really helped to further shape the layout. Up to this point we were\nstill iterating with static markup and felt like we were making good progress\nwith the information we had received from in browser testing. The next step was\nto start wiring up user interactions to see what else was revealed.\n\n* * * * *\n\n![Dynamic Prototype\n1](https://f.cl.ly/items/0V4742133R030g453t1D/dynamic.prototype.1.png)\n\nI've been using [Backbone.JS](https://documentcloud.github.com/backbone/) for the\nlast 18 months and it's a wonderful tool for building prototypes with. We\ndecided to add some simple collection backed views and flesh out the user\ninteraction of adding Activities and having them update live in the preview.\nWhat this yielded first was a realization that our design didn't account for all\nthat many rules due to our fixed position summary preview. (note: the new [affix\nplugin](https://twitter.github.com/bootstrap/javascript.html#affix) in [bootstrap\n2.1](https://twitter.github.com/bootstrap/) is \\_great\\_ for this, but you should\nbe aware of how tall your content could potentially be!)\n\n* * * * *\n\n![Dynamic Prototype\n2](https://f.cl.ly/items/2T2h3a1y232u2a1a3619/dynamic.prototype.2.png)\n\nOops. You could say I should have encountered that in the static stage of in\nbrowser testing by adding more static data to test the layout, but I didn't and\nI find that this is often the case with static prototypes. Adding interactivity\nto a prototype helps to uncover places your design breaks down. It was at this\npoint I had a discussion with a teammate to demo what had been built so far and\nwe both came to the realization that the tabular display under the activities UI\nwas not user friendly. The interface for adding Activities seems to read like\nenglish (we arrived at that after a number of iterations) but the display of the\ndata isn't helpful to users at all and really mirrors how the underlying system\nstores the data.\n\n* * * * *\n\n## Moving Forward\n\nOur next step will be to prototype a layout where the summary preview \\_is\\_ the\ninterface to eliminate the \"system language\" from the interface altogether. In\nconclusion, I don't think we would have been able to iterate and refine our\napproach as effectively if we had not started in the browser and added\ninteractivity to the prototype soon after prototyping with static markup. The\nthings we can learn from interactive prototypes can really help crank out\ninterfaces that are much more usable.\n\nIf you aren't already prototyping interactivity in the browser I would encourage\nyou to start as soon as possible, the earlier you start the earlier you'll find\nout how to fix your interface! :)\n\n"
}></pre></div><div><a href="/posts/2011-11-21-the-scna-2011-narrative-suitability-capability-anarchy-and-propaganda.html">The SCNA 2011 Narrative: Suitability, Capability, Anarachy &amp; Propaganda</a><pre><{
  "path": "app/posts/2011-11-21-the-scna-2011-narrative-suitability-capability-anarchy-and-propaganda.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The SCNA 2011 Narrative: Suitability, Capability, Anarachy & Propaganda",
      "date": "2011-11-21"
    },
    "source": "\nI attended [Software Crafstmanship North\nAmerica](https://scna.softwarecraftsmanship.org/) in Chicago this weekend and\ncame away feeling much differently than I thought I would. I [tweeted a\nsummary](https://twitter.com/dmosher/status/138476620896931840) of my thoughts\nlast night:\n\n> @dmosher: I find it interesting that the talks I agreed with most at \\#scna\n> were predominantly against established \"agile\" principles … :|\n\nTwitter is a horrible medium for expressing ideas that are packed with meaning;\nthis post is intended to unpack my tweet and experience at SCNA 2011 by focusing\non the 3 talks I found the most valuable and how they formed a cohesive and\npowerful narrative in my mind.\n\n## Suitability vs Capability\n\n[Gary Bernhardt](https://twitter.com/#!/garybernhardt) gave a wonderful talk\nentitled \"Expansion & Contraction\". I think he should have titled it\n\"Suitability vs Capability\" but it was a brilliant talk and the one I considered\nthe best of the conference. Here's my best attempt at paraphrasing it:\n\n> Programming Language and Technology go through a constant ebb and flow of\n> expanding and contracting over time. During expansion, these solutions are\n> \"Capability\" solutions; that is, they are capable of solving problems but they\n> are not yet suitable. Eventually there is a contraction that happens and\n> \"Suitability\" solutions emerge.\n>\n> Java first emerged as a Capability Solution during an expansion in the post\n> C/C++ era. Time passed and a contraction occurred in which Java matured into a\n> Suitability Solution for developing software.\n\nA few times during his talk Gary mentioned that JavaScript and NodeJS are\ncurrently in the realm of Capability Solutions. At first this rubbed me the\nwrong way but I think that's because I wasn't really listening to what he was\nsaying *objectively*. NodeJS is absolutely in the realm of Capability and not\nSuitability at the moment, but that doesn't mean you can't create something\nuseful with it.\n\nThinking more about the heart of Gary's talk I find myself glad that it was on\nDay 1 because I found that it framed my thinking for the rest of the conference.\n\n## Programmer Anarchy\n\nAgile best practices are often framed as things we \"must do\" in order to be\nsuccessful but I think it would behoove us to frame them in terms of suitability\nand capability.\n\n[Fred George](https://twitter.com/#!/fgeorge52) gave a talk in the breakout room\non Day 2 entitled \"[Programmer\nAnarchy](https://forwardtechnology.co.uk/videos/32447325)\". His ideas might seem\nradical to some but I think they are an appropriate response based on an\nevaluation of suitability/capability for his *specific situation*. It's\nimportant to understand that the following decisions derive from a company that\nis continually investing in new ways to make money by building very small\napplications. Here's the gist:\n\n> Agile prescribes many best practices like Kanban, Scrum, XP, Pairing,\n> Continuous Integration, Unit Testing... the list goes on.\n>\n> In the waterfall era the power to determine *how* systems get built lies\n> squarely with the *customer*. Up-front design docs and requirements\n> specifications dictate how developers should build a system to achieve\n> success. Through waterfall, systems are often built completely wrong. As a\n> result customer trust is lower, developer happiness decreases, and success is\n> not realized.\n>\n> In the agile era the power to determine *how* systems get built is *shared*\n> between the *customer and developers* but there is a gap in trust because of\n> the past failures of waterfall. Agile is an attempt to bridge the trust gap by\n> building things faster and with less bugs. Through agile, systems are also\n> built wrong but they fail faster which mitigates risk and decreases the cost\n> of change.\n>\n> In the era of Programmer Anarchy the power to determine *how* systems are\n> built lie directly with *developers.*\n>\n> -   non-developer roles like architects, project manager, scrum-master, team\n>     lead, delivery lead, hr people and tester are completely eliminated from\n>     teams\n> -   developers are empowered to build software using whatever technology they\n>     choose and with whatever tools they choose\n> -   applications and systems are extremely small (100-300 lines of code) so\n>     unit-tests, acceptance tests, and continuous integration are eliminated\n>     entirely\n> -   teams are encouraged to write and re-write applications using whatever\n>     they want, including capability solutions (Clojure, NodeJS, Cassandra,\n>     Hadoop, etc..)\n\nFred talked a lot about his company and how they have a lot of trust in their\ndevelopers to be able to turn ideas into money. The first thing they do on any\nproject is write the business metrics code to be able to verify whether\nsomething they produce can be tied back to business value. This is an absolutely\n*critical point* that needs to be understood. Most of the time, my\ndissatisfaction in the work I do is related to not knowing whether something I\nbuild will *actually* have value. If I had metric and monitoring code in place\nthat was able to tell me what I created is making money and can be considered\nsuccessful my job satisfaction would increase greatly.\n\nUnit tests weren't suitable for Fred's teams because they were writing such\nsmall applications, so they eliminated them. Traditional \"Agile\" roles weren't\nsuitable because he empowered developers to make decisions on what to use, how\nto use it and which developers would be best suited to building it, so they\neliminated them. I think you can see the pattern.\n\nI found it interesting that Fred's teams got rid of things many in the Agile\nmovement consider to be not only suitable but *essential* to building good\nsoftware. It was also fascinating that he actively pushed his teams to use\ncapability solutions like Clojure, NodeJS, Cassandra and Hadoop, which proved\nwildly successful.\n\nWhether you agree with the decisions or not is irrelevant; Fred's team made a\njudgement call about the suitability of all the typical \"Agile\" best practices\nand cut away all the things that weren't suitable. Good teams find ways to\neliminate waste by evaluating whether the things they do are capable *and*\nsuitable and eliminating things that aren't.\n\n## Propaganda, Indoctrination, Fanbois, and Education\n\nI believe there to be a significant difference between a \"Big 'A' Agile\" and\n\"Little 'a' agile\". The religion of \"Agile\" is often touted as the one single\nway to build software. The number of roles and processes prescribed by \"Agile\"\nis excessive, however, this is due to a failure to evaluate things in terms of\nwhether they are suitability solutions or capability solutions for a given\nproject/team.\n\nIt was probably surprising to people in the software craftsmanship movement that\n[Zed Shaw](https://twitter.com/zedshaw) was invited to speak, but his talk on\n\"Propaganda, Indoctrination, Fanbois, and Education\" was the most thought\nprovoking talk at SCNA 2011. Here's my translation:\n\n> Anyone who tells you that they have found the \"one true way\" to build software\n> is a con-artist trying to sell you something.\n>\n> If you aren't writing code, you aren't a programmer. Programmers build\n> software, everything else is just marketing spin.\n>\n> Indoctrination happens when you're convinced to think something is the only\n> way. Education gives you options and lets you make choices. Don't be\n> indoctrinated, be educated.\n>\n> Agile and all the related buzzwordy ideas can be boiled down to these 3 simple\n> ideas:\n>\n> -   Make a list of stuff to do.\n> -   Do that stuff.\n> -   Automate the heck out of everything.\n>\n> (note: these things don't have to be done in any particular order)\n\nWhile he's abrasive and rubs a lot of people the wrong way, Zed Shaw has done a\nlot of good for the software craftsmanship movement. He's trying to put the\nfocus back on learning programming instead of \"Super XP Double Pairing Kanban\nScrum Sauce\" and all the rest of the \"Agile\" marketing spin. His [\"Learn Code\nthe Hard Way\"](https://learncodethehardway.org/) series is wildly successful and\nis actually teaching people how to program. Somebody at the conference asked\nhim:\n\n> \"So what do you think about Unit Testing and Continuous Integration and all\n> that stuff then?\"\n\nHis response was pretty down to earth:\n\n> I've worked for big consulting companies doing every one of those things in\n> the past. I've written tests, done TDD, used pivotal tracker blah-de-bloo or\n> whatever you're using. Those things aren't bad but anyone who is trying to\n> tell you those things are the \"one true way\" to build software is a con-artist\n> trying to sell you something. If you believe that stuff you've got a\n> mind-virus. You don't want a mind-virus.\n\nI used to change my thinking *drastically* all the time. I'd go to conferences\nand experience a lot of hype and get infected with a mind-virus that led me to\nadopt ideas that I would later on discard. This isn't a healthy thing to do.\nNothing I experienced at SCNA 2011 was radical enough to make me change my\nthinking drastically, but what I did experience will help me to be much more\nobjective about the things I let influence me going forward.\n\n## Where do we go from here?\n\nIt's important to be objective. It's important to question the value of things\nwe do, especially when we do them because somebody has told us they will solve\nall our problems.\n\nTo me, the most important narrative of SCNA 2011, and the thoughts behind my\n[tweet](https://twitter.com/dmosher/status/138476620896931840) are these:\n\n-   Don't buy into all the propaganda, don't get indoctrinated. Get educated.\n-   Learn to *objectively* evaluate the tools, processes, and ideas we use in\n    terms of *suitability and capability*.\n-   Let go of suitability solutions if they don't give you any value.\n-   Embrace capability solutions because you might be surprised by their value.\n"
  },
  "attributes": {
    "title": "The SCNA 2011 Narrative: Suitability, Capability, Anarachy & Propaganda",
    "date": "2011-11-21"
  },
  "markdown": "\nI attended [Software Crafstmanship North\nAmerica](https://scna.softwarecraftsmanship.org/) in Chicago this weekend and\ncame away feeling much differently than I thought I would. I [tweeted a\nsummary](https://twitter.com/dmosher/status/138476620896931840) of my thoughts\nlast night:\n\n> @dmosher: I find it interesting that the talks I agreed with most at \\#scna\n> were predominantly against established \"agile\" principles … :|\n\nTwitter is a horrible medium for expressing ideas that are packed with meaning;\nthis post is intended to unpack my tweet and experience at SCNA 2011 by focusing\non the 3 talks I found the most valuable and how they formed a cohesive and\npowerful narrative in my mind.\n\n## Suitability vs Capability\n\n[Gary Bernhardt](https://twitter.com/#!/garybernhardt) gave a wonderful talk\nentitled \"Expansion & Contraction\". I think he should have titled it\n\"Suitability vs Capability\" but it was a brilliant talk and the one I considered\nthe best of the conference. Here's my best attempt at paraphrasing it:\n\n> Programming Language and Technology go through a constant ebb and flow of\n> expanding and contracting over time. During expansion, these solutions are\n> \"Capability\" solutions; that is, they are capable of solving problems but they\n> are not yet suitable. Eventually there is a contraction that happens and\n> \"Suitability\" solutions emerge.\n>\n> Java first emerged as a Capability Solution during an expansion in the post\n> C/C++ era. Time passed and a contraction occurred in which Java matured into a\n> Suitability Solution for developing software.\n\nA few times during his talk Gary mentioned that JavaScript and NodeJS are\ncurrently in the realm of Capability Solutions. At first this rubbed me the\nwrong way but I think that's because I wasn't really listening to what he was\nsaying *objectively*. NodeJS is absolutely in the realm of Capability and not\nSuitability at the moment, but that doesn't mean you can't create something\nuseful with it.\n\nThinking more about the heart of Gary's talk I find myself glad that it was on\nDay 1 because I found that it framed my thinking for the rest of the conference.\n\n## Programmer Anarchy\n\nAgile best practices are often framed as things we \"must do\" in order to be\nsuccessful but I think it would behoove us to frame them in terms of suitability\nand capability.\n\n[Fred George](https://twitter.com/#!/fgeorge52) gave a talk in the breakout room\non Day 2 entitled \"[Programmer\nAnarchy](https://forwardtechnology.co.uk/videos/32447325)\". His ideas might seem\nradical to some but I think they are an appropriate response based on an\nevaluation of suitability/capability for his *specific situation*. It's\nimportant to understand that the following decisions derive from a company that\nis continually investing in new ways to make money by building very small\napplications. Here's the gist:\n\n> Agile prescribes many best practices like Kanban, Scrum, XP, Pairing,\n> Continuous Integration, Unit Testing... the list goes on.\n>\n> In the waterfall era the power to determine *how* systems get built lies\n> squarely with the *customer*. Up-front design docs and requirements\n> specifications dictate how developers should build a system to achieve\n> success. Through waterfall, systems are often built completely wrong. As a\n> result customer trust is lower, developer happiness decreases, and success is\n> not realized.\n>\n> In the agile era the power to determine *how* systems get built is *shared*\n> between the *customer and developers* but there is a gap in trust because of\n> the past failures of waterfall. Agile is an attempt to bridge the trust gap by\n> building things faster and with less bugs. Through agile, systems are also\n> built wrong but they fail faster which mitigates risk and decreases the cost\n> of change.\n>\n> In the era of Programmer Anarchy the power to determine *how* systems are\n> built lie directly with *developers.*\n>\n> -   non-developer roles like architects, project manager, scrum-master, team\n>     lead, delivery lead, hr people and tester are completely eliminated from\n>     teams\n> -   developers are empowered to build software using whatever technology they\n>     choose and with whatever tools they choose\n> -   applications and systems are extremely small (100-300 lines of code) so\n>     unit-tests, acceptance tests, and continuous integration are eliminated\n>     entirely\n> -   teams are encouraged to write and re-write applications using whatever\n>     they want, including capability solutions (Clojure, NodeJS, Cassandra,\n>     Hadoop, etc..)\n\nFred talked a lot about his company and how they have a lot of trust in their\ndevelopers to be able to turn ideas into money. The first thing they do on any\nproject is write the business metrics code to be able to verify whether\nsomething they produce can be tied back to business value. This is an absolutely\n*critical point* that needs to be understood. Most of the time, my\ndissatisfaction in the work I do is related to not knowing whether something I\nbuild will *actually* have value. If I had metric and monitoring code in place\nthat was able to tell me what I created is making money and can be considered\nsuccessful my job satisfaction would increase greatly.\n\nUnit tests weren't suitable for Fred's teams because they were writing such\nsmall applications, so they eliminated them. Traditional \"Agile\" roles weren't\nsuitable because he empowered developers to make decisions on what to use, how\nto use it and which developers would be best suited to building it, so they\neliminated them. I think you can see the pattern.\n\nI found it interesting that Fred's teams got rid of things many in the Agile\nmovement consider to be not only suitable but *essential* to building good\nsoftware. It was also fascinating that he actively pushed his teams to use\ncapability solutions like Clojure, NodeJS, Cassandra and Hadoop, which proved\nwildly successful.\n\nWhether you agree with the decisions or not is irrelevant; Fred's team made a\njudgement call about the suitability of all the typical \"Agile\" best practices\nand cut away all the things that weren't suitable. Good teams find ways to\neliminate waste by evaluating whether the things they do are capable *and*\nsuitable and eliminating things that aren't.\n\n## Propaganda, Indoctrination, Fanbois, and Education\n\nI believe there to be a significant difference between a \"Big 'A' Agile\" and\n\"Little 'a' agile\". The religion of \"Agile\" is often touted as the one single\nway to build software. The number of roles and processes prescribed by \"Agile\"\nis excessive, however, this is due to a failure to evaluate things in terms of\nwhether they are suitability solutions or capability solutions for a given\nproject/team.\n\nIt was probably surprising to people in the software craftsmanship movement that\n[Zed Shaw](https://twitter.com/zedshaw) was invited to speak, but his talk on\n\"Propaganda, Indoctrination, Fanbois, and Education\" was the most thought\nprovoking talk at SCNA 2011. Here's my translation:\n\n> Anyone who tells you that they have found the \"one true way\" to build software\n> is a con-artist trying to sell you something.\n>\n> If you aren't writing code, you aren't a programmer. Programmers build\n> software, everything else is just marketing spin.\n>\n> Indoctrination happens when you're convinced to think something is the only\n> way. Education gives you options and lets you make choices. Don't be\n> indoctrinated, be educated.\n>\n> Agile and all the related buzzwordy ideas can be boiled down to these 3 simple\n> ideas:\n>\n> -   Make a list of stuff to do.\n> -   Do that stuff.\n> -   Automate the heck out of everything.\n>\n> (note: these things don't have to be done in any particular order)\n\nWhile he's abrasive and rubs a lot of people the wrong way, Zed Shaw has done a\nlot of good for the software craftsmanship movement. He's trying to put the\nfocus back on learning programming instead of \"Super XP Double Pairing Kanban\nScrum Sauce\" and all the rest of the \"Agile\" marketing spin. His [\"Learn Code\nthe Hard Way\"](https://learncodethehardway.org/) series is wildly successful and\nis actually teaching people how to program. Somebody at the conference asked\nhim:\n\n> \"So what do you think about Unit Testing and Continuous Integration and all\n> that stuff then?\"\n\nHis response was pretty down to earth:\n\n> I've worked for big consulting companies doing every one of those things in\n> the past. I've written tests, done TDD, used pivotal tracker blah-de-bloo or\n> whatever you're using. Those things aren't bad but anyone who is trying to\n> tell you those things are the \"one true way\" to build software is a con-artist\n> trying to sell you something. If you believe that stuff you've got a\n> mind-virus. You don't want a mind-virus.\n\nI used to change my thinking *drastically* all the time. I'd go to conferences\nand experience a lot of hype and get infected with a mind-virus that led me to\nadopt ideas that I would later on discard. This isn't a healthy thing to do.\nNothing I experienced at SCNA 2011 was radical enough to make me change my\nthinking drastically, but what I did experience will help me to be much more\nobjective about the things I let influence me going forward.\n\n## Where do we go from here?\n\nIt's important to be objective. It's important to question the value of things\nwe do, especially when we do them because somebody has told us they will solve\nall our problems.\n\nTo me, the most important narrative of SCNA 2011, and the thoughts behind my\n[tweet](https://twitter.com/dmosher/status/138476620896931840) are these:\n\n-   Don't buy into all the propaganda, don't get indoctrinated. Get educated.\n-   Learn to *objectively* evaluate the tools, processes, and ideas we use in\n    terms of *suitability and capability*.\n-   Let go of suitability solutions if they don't give you any value.\n-   Embrace capability solutions because you might be surprised by their value.\n"
}></{
  "path": "app/posts/2011-11-21-the-scna-2011-narrative-suitability-capability-anarchy-and-propaganda.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The SCNA 2011 Narrative: Suitability, Capability, Anarachy & Propaganda",
      "date": "2011-11-21"
    },
    "source": "\nI attended [Software Crafstmanship North\nAmerica](https://scna.softwarecraftsmanship.org/) in Chicago this weekend and\ncame away feeling much differently than I thought I would. I [tweeted a\nsummary](https://twitter.com/dmosher/status/138476620896931840) of my thoughts\nlast night:\n\n> @dmosher: I find it interesting that the talks I agreed with most at \\#scna\n> were predominantly against established \"agile\" principles … :|\n\nTwitter is a horrible medium for expressing ideas that are packed with meaning;\nthis post is intended to unpack my tweet and experience at SCNA 2011 by focusing\non the 3 talks I found the most valuable and how they formed a cohesive and\npowerful narrative in my mind.\n\n## Suitability vs Capability\n\n[Gary Bernhardt](https://twitter.com/#!/garybernhardt) gave a wonderful talk\nentitled \"Expansion & Contraction\". I think he should have titled it\n\"Suitability vs Capability\" but it was a brilliant talk and the one I considered\nthe best of the conference. Here's my best attempt at paraphrasing it:\n\n> Programming Language and Technology go through a constant ebb and flow of\n> expanding and contracting over time. During expansion, these solutions are\n> \"Capability\" solutions; that is, they are capable of solving problems but they\n> are not yet suitable. Eventually there is a contraction that happens and\n> \"Suitability\" solutions emerge.\n>\n> Java first emerged as a Capability Solution during an expansion in the post\n> C/C++ era. Time passed and a contraction occurred in which Java matured into a\n> Suitability Solution for developing software.\n\nA few times during his talk Gary mentioned that JavaScript and NodeJS are\ncurrently in the realm of Capability Solutions. At first this rubbed me the\nwrong way but I think that's because I wasn't really listening to what he was\nsaying *objectively*. NodeJS is absolutely in the realm of Capability and not\nSuitability at the moment, but that doesn't mean you can't create something\nuseful with it.\n\nThinking more about the heart of Gary's talk I find myself glad that it was on\nDay 1 because I found that it framed my thinking for the rest of the conference.\n\n## Programmer Anarchy\n\nAgile best practices are often framed as things we \"must do\" in order to be\nsuccessful but I think it would behoove us to frame them in terms of suitability\nand capability.\n\n[Fred George](https://twitter.com/#!/fgeorge52) gave a talk in the breakout room\non Day 2 entitled \"[Programmer\nAnarchy](https://forwardtechnology.co.uk/videos/32447325)\". His ideas might seem\nradical to some but I think they are an appropriate response based on an\nevaluation of suitability/capability for his *specific situation*. It's\nimportant to understand that the following decisions derive from a company that\nis continually investing in new ways to make money by building very small\napplications. Here's the gist:\n\n> Agile prescribes many best practices like Kanban, Scrum, XP, Pairing,\n> Continuous Integration, Unit Testing... the list goes on.\n>\n> In the waterfall era the power to determine *how* systems get built lies\n> squarely with the *customer*. Up-front design docs and requirements\n> specifications dictate how developers should build a system to achieve\n> success. Through waterfall, systems are often built completely wrong. As a\n> result customer trust is lower, developer happiness decreases, and success is\n> not realized.\n>\n> In the agile era the power to determine *how* systems get built is *shared*\n> between the *customer and developers* but there is a gap in trust because of\n> the past failures of waterfall. Agile is an attempt to bridge the trust gap by\n> building things faster and with less bugs. Through agile, systems are also\n> built wrong but they fail faster which mitigates risk and decreases the cost\n> of change.\n>\n> In the era of Programmer Anarchy the power to determine *how* systems are\n> built lie directly with *developers.*\n>\n> -   non-developer roles like architects, project manager, scrum-master, team\n>     lead, delivery lead, hr people and tester are completely eliminated from\n>     teams\n> -   developers are empowered to build software using whatever technology they\n>     choose and with whatever tools they choose\n> -   applications and systems are extremely small (100-300 lines of code) so\n>     unit-tests, acceptance tests, and continuous integration are eliminated\n>     entirely\n> -   teams are encouraged to write and re-write applications using whatever\n>     they want, including capability solutions (Clojure, NodeJS, Cassandra,\n>     Hadoop, etc..)\n\nFred talked a lot about his company and how they have a lot of trust in their\ndevelopers to be able to turn ideas into money. The first thing they do on any\nproject is write the business metrics code to be able to verify whether\nsomething they produce can be tied back to business value. This is an absolutely\n*critical point* that needs to be understood. Most of the time, my\ndissatisfaction in the work I do is related to not knowing whether something I\nbuild will *actually* have value. If I had metric and monitoring code in place\nthat was able to tell me what I created is making money and can be considered\nsuccessful my job satisfaction would increase greatly.\n\nUnit tests weren't suitable for Fred's teams because they were writing such\nsmall applications, so they eliminated them. Traditional \"Agile\" roles weren't\nsuitable because he empowered developers to make decisions on what to use, how\nto use it and which developers would be best suited to building it, so they\neliminated them. I think you can see the pattern.\n\nI found it interesting that Fred's teams got rid of things many in the Agile\nmovement consider to be not only suitable but *essential* to building good\nsoftware. It was also fascinating that he actively pushed his teams to use\ncapability solutions like Clojure, NodeJS, Cassandra and Hadoop, which proved\nwildly successful.\n\nWhether you agree with the decisions or not is irrelevant; Fred's team made a\njudgement call about the suitability of all the typical \"Agile\" best practices\nand cut away all the things that weren't suitable. Good teams find ways to\neliminate waste by evaluating whether the things they do are capable *and*\nsuitable and eliminating things that aren't.\n\n## Propaganda, Indoctrination, Fanbois, and Education\n\nI believe there to be a significant difference between a \"Big 'A' Agile\" and\n\"Little 'a' agile\". The religion of \"Agile\" is often touted as the one single\nway to build software. The number of roles and processes prescribed by \"Agile\"\nis excessive, however, this is due to a failure to evaluate things in terms of\nwhether they are suitability solutions or capability solutions for a given\nproject/team.\n\nIt was probably surprising to people in the software craftsmanship movement that\n[Zed Shaw](https://twitter.com/zedshaw) was invited to speak, but his talk on\n\"Propaganda, Indoctrination, Fanbois, and Education\" was the most thought\nprovoking talk at SCNA 2011. Here's my translation:\n\n> Anyone who tells you that they have found the \"one true way\" to build software\n> is a con-artist trying to sell you something.\n>\n> If you aren't writing code, you aren't a programmer. Programmers build\n> software, everything else is just marketing spin.\n>\n> Indoctrination happens when you're convinced to think something is the only\n> way. Education gives you options and lets you make choices. Don't be\n> indoctrinated, be educated.\n>\n> Agile and all the related buzzwordy ideas can be boiled down to these 3 simple\n> ideas:\n>\n> -   Make a list of stuff to do.\n> -   Do that stuff.\n> -   Automate the heck out of everything.\n>\n> (note: these things don't have to be done in any particular order)\n\nWhile he's abrasive and rubs a lot of people the wrong way, Zed Shaw has done a\nlot of good for the software craftsmanship movement. He's trying to put the\nfocus back on learning programming instead of \"Super XP Double Pairing Kanban\nScrum Sauce\" and all the rest of the \"Agile\" marketing spin. His [\"Learn Code\nthe Hard Way\"](https://learncodethehardway.org/) series is wildly successful and\nis actually teaching people how to program. Somebody at the conference asked\nhim:\n\n> \"So what do you think about Unit Testing and Continuous Integration and all\n> that stuff then?\"\n\nHis response was pretty down to earth:\n\n> I've worked for big consulting companies doing every one of those things in\n> the past. I've written tests, done TDD, used pivotal tracker blah-de-bloo or\n> whatever you're using. Those things aren't bad but anyone who is trying to\n> tell you those things are the \"one true way\" to build software is a con-artist\n> trying to sell you something. If you believe that stuff you've got a\n> mind-virus. You don't want a mind-virus.\n\nI used to change my thinking *drastically* all the time. I'd go to conferences\nand experience a lot of hype and get infected with a mind-virus that led me to\nadopt ideas that I would later on discard. This isn't a healthy thing to do.\nNothing I experienced at SCNA 2011 was radical enough to make me change my\nthinking drastically, but what I did experience will help me to be much more\nobjective about the things I let influence me going forward.\n\n## Where do we go from here?\n\nIt's important to be objective. It's important to question the value of things\nwe do, especially when we do them because somebody has told us they will solve\nall our problems.\n\nTo me, the most important narrative of SCNA 2011, and the thoughts behind my\n[tweet](https://twitter.com/dmosher/status/138476620896931840) are these:\n\n-   Don't buy into all the propaganda, don't get indoctrinated. Get educated.\n-   Learn to *objectively* evaluate the tools, processes, and ideas we use in\n    terms of *suitability and capability*.\n-   Let go of suitability solutions if they don't give you any value.\n-   Embrace capability solutions because you might be surprised by their value.\n"
  },
  "attributes": {
    "title": "The SCNA 2011 Narrative: Suitability, Capability, Anarachy & Propaganda",
    "date": "2011-11-21"
  },
  "markdown": "\nI attended [Software Crafstmanship North\nAmerica](https://scna.softwarecraftsmanship.org/) in Chicago this weekend and\ncame away feeling much differently than I thought I would. I [tweeted a\nsummary](https://twitter.com/dmosher/status/138476620896931840) of my thoughts\nlast night:\n\n> @dmosher: I find it interesting that the talks I agreed with most at \\#scna\n> were predominantly against established \"agile\" principles … :|\n\nTwitter is a horrible medium for expressing ideas that are packed with meaning;\nthis post is intended to unpack my tweet and experience at SCNA 2011 by focusing\non the 3 talks I found the most valuable and how they formed a cohesive and\npowerful narrative in my mind.\n\n## Suitability vs Capability\n\n[Gary Bernhardt](https://twitter.com/#!/garybernhardt) gave a wonderful talk\nentitled \"Expansion & Contraction\". I think he should have titled it\n\"Suitability vs Capability\" but it was a brilliant talk and the one I considered\nthe best of the conference. Here's my best attempt at paraphrasing it:\n\n> Programming Language and Technology go through a constant ebb and flow of\n> expanding and contracting over time. During expansion, these solutions are\n> \"Capability\" solutions; that is, they are capable of solving problems but they\n> are not yet suitable. Eventually there is a contraction that happens and\n> \"Suitability\" solutions emerge.\n>\n> Java first emerged as a Capability Solution during an expansion in the post\n> C/C++ era. Time passed and a contraction occurred in which Java matured into a\n> Suitability Solution for developing software.\n\nA few times during his talk Gary mentioned that JavaScript and NodeJS are\ncurrently in the realm of Capability Solutions. At first this rubbed me the\nwrong way but I think that's because I wasn't really listening to what he was\nsaying *objectively*. NodeJS is absolutely in the realm of Capability and not\nSuitability at the moment, but that doesn't mean you can't create something\nuseful with it.\n\nThinking more about the heart of Gary's talk I find myself glad that it was on\nDay 1 because I found that it framed my thinking for the rest of the conference.\n\n## Programmer Anarchy\n\nAgile best practices are often framed as things we \"must do\" in order to be\nsuccessful but I think it would behoove us to frame them in terms of suitability\nand capability.\n\n[Fred George](https://twitter.com/#!/fgeorge52) gave a talk in the breakout room\non Day 2 entitled \"[Programmer\nAnarchy](https://forwardtechnology.co.uk/videos/32447325)\". His ideas might seem\nradical to some but I think they are an appropriate response based on an\nevaluation of suitability/capability for his *specific situation*. It's\nimportant to understand that the following decisions derive from a company that\nis continually investing in new ways to make money by building very small\napplications. Here's the gist:\n\n> Agile prescribes many best practices like Kanban, Scrum, XP, Pairing,\n> Continuous Integration, Unit Testing... the list goes on.\n>\n> In the waterfall era the power to determine *how* systems get built lies\n> squarely with the *customer*. Up-front design docs and requirements\n> specifications dictate how developers should build a system to achieve\n> success. Through waterfall, systems are often built completely wrong. As a\n> result customer trust is lower, developer happiness decreases, and success is\n> not realized.\n>\n> In the agile era the power to determine *how* systems get built is *shared*\n> between the *customer and developers* but there is a gap in trust because of\n> the past failures of waterfall. Agile is an attempt to bridge the trust gap by\n> building things faster and with less bugs. Through agile, systems are also\n> built wrong but they fail faster which mitigates risk and decreases the cost\n> of change.\n>\n> In the era of Programmer Anarchy the power to determine *how* systems are\n> built lie directly with *developers.*\n>\n> -   non-developer roles like architects, project manager, scrum-master, team\n>     lead, delivery lead, hr people and tester are completely eliminated from\n>     teams\n> -   developers are empowered to build software using whatever technology they\n>     choose and with whatever tools they choose\n> -   applications and systems are extremely small (100-300 lines of code) so\n>     unit-tests, acceptance tests, and continuous integration are eliminated\n>     entirely\n> -   teams are encouraged to write and re-write applications using whatever\n>     they want, including capability solutions (Clojure, NodeJS, Cassandra,\n>     Hadoop, etc..)\n\nFred talked a lot about his company and how they have a lot of trust in their\ndevelopers to be able to turn ideas into money. The first thing they do on any\nproject is write the business metrics code to be able to verify whether\nsomething they produce can be tied back to business value. This is an absolutely\n*critical point* that needs to be understood. Most of the time, my\ndissatisfaction in the work I do is related to not knowing whether something I\nbuild will *actually* have value. If I had metric and monitoring code in place\nthat was able to tell me what I created is making money and can be considered\nsuccessful my job satisfaction would increase greatly.\n\nUnit tests weren't suitable for Fred's teams because they were writing such\nsmall applications, so they eliminated them. Traditional \"Agile\" roles weren't\nsuitable because he empowered developers to make decisions on what to use, how\nto use it and which developers would be best suited to building it, so they\neliminated them. I think you can see the pattern.\n\nI found it interesting that Fred's teams got rid of things many in the Agile\nmovement consider to be not only suitable but *essential* to building good\nsoftware. It was also fascinating that he actively pushed his teams to use\ncapability solutions like Clojure, NodeJS, Cassandra and Hadoop, which proved\nwildly successful.\n\nWhether you agree with the decisions or not is irrelevant; Fred's team made a\njudgement call about the suitability of all the typical \"Agile\" best practices\nand cut away all the things that weren't suitable. Good teams find ways to\neliminate waste by evaluating whether the things they do are capable *and*\nsuitable and eliminating things that aren't.\n\n## Propaganda, Indoctrination, Fanbois, and Education\n\nI believe there to be a significant difference between a \"Big 'A' Agile\" and\n\"Little 'a' agile\". The religion of \"Agile\" is often touted as the one single\nway to build software. The number of roles and processes prescribed by \"Agile\"\nis excessive, however, this is due to a failure to evaluate things in terms of\nwhether they are suitability solutions or capability solutions for a given\nproject/team.\n\nIt was probably surprising to people in the software craftsmanship movement that\n[Zed Shaw](https://twitter.com/zedshaw) was invited to speak, but his talk on\n\"Propaganda, Indoctrination, Fanbois, and Education\" was the most thought\nprovoking talk at SCNA 2011. Here's my translation:\n\n> Anyone who tells you that they have found the \"one true way\" to build software\n> is a con-artist trying to sell you something.\n>\n> If you aren't writing code, you aren't a programmer. Programmers build\n> software, everything else is just marketing spin.\n>\n> Indoctrination happens when you're convinced to think something is the only\n> way. Education gives you options and lets you make choices. Don't be\n> indoctrinated, be educated.\n>\n> Agile and all the related buzzwordy ideas can be boiled down to these 3 simple\n> ideas:\n>\n> -   Make a list of stuff to do.\n> -   Do that stuff.\n> -   Automate the heck out of everything.\n>\n> (note: these things don't have to be done in any particular order)\n\nWhile he's abrasive and rubs a lot of people the wrong way, Zed Shaw has done a\nlot of good for the software craftsmanship movement. He's trying to put the\nfocus back on learning programming instead of \"Super XP Double Pairing Kanban\nScrum Sauce\" and all the rest of the \"Agile\" marketing spin. His [\"Learn Code\nthe Hard Way\"](https://learncodethehardway.org/) series is wildly successful and\nis actually teaching people how to program. Somebody at the conference asked\nhim:\n\n> \"So what do you think about Unit Testing and Continuous Integration and all\n> that stuff then?\"\n\nHis response was pretty down to earth:\n\n> I've worked for big consulting companies doing every one of those things in\n> the past. I've written tests, done TDD, used pivotal tracker blah-de-bloo or\n> whatever you're using. Those things aren't bad but anyone who is trying to\n> tell you those things are the \"one true way\" to build software is a con-artist\n> trying to sell you something. If you believe that stuff you've got a\n> mind-virus. You don't want a mind-virus.\n\nI used to change my thinking *drastically* all the time. I'd go to conferences\nand experience a lot of hype and get infected with a mind-virus that led me to\nadopt ideas that I would later on discard. This isn't a healthy thing to do.\nNothing I experienced at SCNA 2011 was radical enough to make me change my\nthinking drastically, but what I did experience will help me to be much more\nobjective about the things I let influence me going forward.\n\n## Where do we go from here?\n\nIt's important to be objective. It's important to question the value of things\nwe do, especially when we do them because somebody has told us they will solve\nall our problems.\n\nTo me, the most important narrative of SCNA 2011, and the thoughts behind my\n[tweet](https://twitter.com/dmosher/status/138476620896931840) are these:\n\n-   Don't buy into all the propaganda, don't get indoctrinated. Get educated.\n-   Learn to *objectively* evaluate the tools, processes, and ideas we use in\n    terms of *suitability and capability*.\n-   Let go of suitability solutions if they don't give you any value.\n-   Embrace capability solutions because you might be surprised by their value.\n"
}></pre></div><div><a href="/posts/2011-05-27-immersed-in-agile.html">Immersed in agile</a><pre><{
  "path": "app/posts/2011-05-27-immersed-in-agile.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Immersed in agile",
      "date": "2011-05-27"
    },
    "source": "\n> I started working as an independent contractor for [Pillar\nTechnology](https://www.pillartechnology.com/) over 6 months ago (Nov 1, 2010).\nAt the time, I had no idea what was in store for me; looking back now I think\nI've hit a new point from which to grow in my career so it seems time to engage\nin a retrospective on the last year.\n\n## Some History\n\nPrior to working with Pillar I spent just over 2 years working on a number of\nprojects at [VendAsta Technologies](https://www.vendasta.com/). I grew a lot in\nthose 2 years but mostly in a technical capacity. Things like continuous\nintegration, build configuration, and (briefly) unit testing were introduced to\nme. It was enlightening to get a taste of the technical goodness offered by\nthose things but ultimately I felt like there was no one there who could guide\nme in the underlying principles that necessitate them. At the same time I was\nintroduced to many of the core concepts of this thing people in the software\ndevelopment community call \"agile\". Coming out of VendAsta in 2010 I thought I\nknew what agile was. I thought it was Scrum, XP, TDD, continuous integration and\na whole host of other technical terms.\n\nLooking back at where I've come in the last 7 months I don't think I can say I\nknow what agile is even now, because it is an ephemeral thing that seems to be\nconstantly evolving. What I can say is that I know a lot more about the core of\nwhat's important in software development: delivering business value and earning\nthe trust of those you work with.\n\n## Trust and Value over Working Software\n\nMy first 6 months with Pillar were served working on a client project for\n[Gordon Food Services](https://www.gfs.com/en) out of Grand Rapids, MI. I worked\nremotely for those 6 months out of an office in my basement that\n[Tanys](https://www.twitter.com/littlemrsmosher) and I built the week before I\nstarted. A brief note on working remotely: it opened my eyes up to a key thing\nthat's required to be successful in life; self-discipline. I had my doubts about\nhow effective I could be remotely but I decided it was worth the challenge and\ncommitted to myself that I would do what it took. Getting up at 7 am to make\nstandup in the morning (hello, 2 hour time zone difference), pushing myself to\nkeep lines of communication open, and pouring my heart and soul into building\ntrust with the client; these are the things I did over those 6 months. And it\npaid off. I grew in my technical knowledge but also in my ability to cultivate\ngood business relationships.\n\nThe people at both the client and Pillar have been great, providing much in the\nway of the mentoring and leadership around the principles of good software\ndevelopment that I had craved for such a long time. In 6 months working for GFS\nthe team I was part of a team that produced software faster, with less defects,\nand with more value than any other project I've been on. The experience was\nenergizing and opened my eyes to the power of building trust and constantly\ndelivering value all while adhering to solid software craftsmanship principles.\n\n## Beyond TDD\n\nPrior to joining Pillar I thought I had a pretty good grasp on the technical\nconcepts surrounding \"agile\". 7 months later my eyes have been opened to how\nmuch more than technicality agile really is. At its heart, agile is a way of\nthinking that promotes accountability, integrity, quality, and value oriented\nthinking. I used to think writing tests was something you did after writing\nproduction code to verify the behaviour you had crafted. Now I understand\nthat \"The fundamental conundrum of software development: I can code fast when I\nhave a good design but I can't design until I've coded slowly.\" ([Kent\nBeck](https://twitoaster.com/kentbeck/the-fundamental-conundrum-of-software-development-i-can-code-fast-when-i-have-a-good-design-but-i-cant-design-until-ive-coded-slowly/)).\n\nA good design is achieved by thinking out architecture by writing tests first.\nI've also learned that tests can act as documentation by example, so it's\nimportant to continually curate test code so that it doesn't grow stagnant. Most\nimportantly of all I've seen the power of having a codebase with 95%+ test\ncoverage and how that acts as a safety net to making change. This last point\ncan't be overstated; the freedom experienced through red/green/refactor makes\nchange cheap and development incredibly enjoyable. At the core of my change here\nfrom 7 months ago is a paradigm shift in the way I think about developing: I\ndon't feel responsible writing production code until I have a failing test.\n\n## The Best Way To Learn\n\nSomething I've always felt positive about is my ability to teach. I feel I have\nthe heart of a teacher, which means that I can empathize with people to\nunderstand the pain they feel. (I've felt the pain too, which always helps). In\nthe last 7 months I've been devoting myself to studying more effective ways to\npromote craftsmanship in front-end development. One of those ways is to teach\nmore. This has not been easy; front-end development has historically been\ntreated as a second class citizen. (I could write a whole other blog post about\nthat alone, but that's a topic for another time). Breaking down barriers between\nfront-end and back-end developers requires a certain amount of grace and poise\nthat I didn't have 7 months ago. Being able to effectively communicate solid\nengineering principles to back-end oriented developers requires empathy,\ncompassion, and the ability to communicate using language they understand.\n\nI've often had to put aside my idealism and promote compromise. I've also had to\nbecome humble and admit that sometimes the front-end is not the place where\neverything should live. (But I still think there's a whole lot of logic on the\nserver that shouldn't be there. Again, another topic for another post). The\nbenefit to engaging developers across architectural boundaries and striving to\nteach is that I've been able to learn a lot. I've learned how to effectively\ntest drive [JavaScript](https://pivotal.github.com/jasmine/) (/hattip\n[@searls](https://twitter.com/searls)), how to build scalable, object-oriented\nCSS/HTML, how to achieve an appropriate [separation of\nconcerns](https://documentcloud.github.com/backbone/) on the front-end, and how\nto translate n-tier architecture principles from the server-side to my\nclient-side code. Being at a company like Pillar has provided a rich environment\nin which to grow; it's something I'm very grateful for.\n\n## The Path to Agility\n\nMany of my co-workers attended the\n[\\#pathtoagility](https://twitter.com/#!/search/%23pathtoagility) conference in\nOhio this week. I wasn't able to attend but I think it's fitting to end a post\nabout my own personal \"path to agility\" with some forward looking thoughts that\ncan help you (and me) to continue on that path. Software development is evolving\nand changing; set yourself up for success by being willing to evolve and change\nright along with it. Agility is more than process or technical solutions; it\ninvolves integrity, accountability and a fundamental paradigm shift in your way\nof thinking. Continue to look for ways you can shift your thinking. Be\nopen-minded. Teaching is a powerful exercise in self examination and growth; try\nto spend time teaching those around you, it's worth the investment.\n"
  },
  "attributes": {
    "title": "Immersed in agile",
    "date": "2011-05-27"
  },
  "markdown": "\n> I started working as an independent contractor for [Pillar\nTechnology](https://www.pillartechnology.com/) over 6 months ago (Nov 1, 2010).\nAt the time, I had no idea what was in store for me; looking back now I think\nI've hit a new point from which to grow in my career so it seems time to engage\nin a retrospective on the last year.\n\n## Some History\n\nPrior to working with Pillar I spent just over 2 years working on a number of\nprojects at [VendAsta Technologies](https://www.vendasta.com/). I grew a lot in\nthose 2 years but mostly in a technical capacity. Things like continuous\nintegration, build configuration, and (briefly) unit testing were introduced to\nme. It was enlightening to get a taste of the technical goodness offered by\nthose things but ultimately I felt like there was no one there who could guide\nme in the underlying principles that necessitate them. At the same time I was\nintroduced to many of the core concepts of this thing people in the software\ndevelopment community call \"agile\". Coming out of VendAsta in 2010 I thought I\nknew what agile was. I thought it was Scrum, XP, TDD, continuous integration and\na whole host of other technical terms.\n\nLooking back at where I've come in the last 7 months I don't think I can say I\nknow what agile is even now, because it is an ephemeral thing that seems to be\nconstantly evolving. What I can say is that I know a lot more about the core of\nwhat's important in software development: delivering business value and earning\nthe trust of those you work with.\n\n## Trust and Value over Working Software\n\nMy first 6 months with Pillar were served working on a client project for\n[Gordon Food Services](https://www.gfs.com/en) out of Grand Rapids, MI. I worked\nremotely for those 6 months out of an office in my basement that\n[Tanys](https://www.twitter.com/littlemrsmosher) and I built the week before I\nstarted. A brief note on working remotely: it opened my eyes up to a key thing\nthat's required to be successful in life; self-discipline. I had my doubts about\nhow effective I could be remotely but I decided it was worth the challenge and\ncommitted to myself that I would do what it took. Getting up at 7 am to make\nstandup in the morning (hello, 2 hour time zone difference), pushing myself to\nkeep lines of communication open, and pouring my heart and soul into building\ntrust with the client; these are the things I did over those 6 months. And it\npaid off. I grew in my technical knowledge but also in my ability to cultivate\ngood business relationships.\n\nThe people at both the client and Pillar have been great, providing much in the\nway of the mentoring and leadership around the principles of good software\ndevelopment that I had craved for such a long time. In 6 months working for GFS\nthe team I was part of a team that produced software faster, with less defects,\nand with more value than any other project I've been on. The experience was\nenergizing and opened my eyes to the power of building trust and constantly\ndelivering value all while adhering to solid software craftsmanship principles.\n\n## Beyond TDD\n\nPrior to joining Pillar I thought I had a pretty good grasp on the technical\nconcepts surrounding \"agile\". 7 months later my eyes have been opened to how\nmuch more than technicality agile really is. At its heart, agile is a way of\nthinking that promotes accountability, integrity, quality, and value oriented\nthinking. I used to think writing tests was something you did after writing\nproduction code to verify the behaviour you had crafted. Now I understand\nthat \"The fundamental conundrum of software development: I can code fast when I\nhave a good design but I can't design until I've coded slowly.\" ([Kent\nBeck](https://twitoaster.com/kentbeck/the-fundamental-conundrum-of-software-development-i-can-code-fast-when-i-have-a-good-design-but-i-cant-design-until-ive-coded-slowly/)).\n\nA good design is achieved by thinking out architecture by writing tests first.\nI've also learned that tests can act as documentation by example, so it's\nimportant to continually curate test code so that it doesn't grow stagnant. Most\nimportantly of all I've seen the power of having a codebase with 95%+ test\ncoverage and how that acts as a safety net to making change. This last point\ncan't be overstated; the freedom experienced through red/green/refactor makes\nchange cheap and development incredibly enjoyable. At the core of my change here\nfrom 7 months ago is a paradigm shift in the way I think about developing: I\ndon't feel responsible writing production code until I have a failing test.\n\n## The Best Way To Learn\n\nSomething I've always felt positive about is my ability to teach. I feel I have\nthe heart of a teacher, which means that I can empathize with people to\nunderstand the pain they feel. (I've felt the pain too, which always helps). In\nthe last 7 months I've been devoting myself to studying more effective ways to\npromote craftsmanship in front-end development. One of those ways is to teach\nmore. This has not been easy; front-end development has historically been\ntreated as a second class citizen. (I could write a whole other blog post about\nthat alone, but that's a topic for another time). Breaking down barriers between\nfront-end and back-end developers requires a certain amount of grace and poise\nthat I didn't have 7 months ago. Being able to effectively communicate solid\nengineering principles to back-end oriented developers requires empathy,\ncompassion, and the ability to communicate using language they understand.\n\nI've often had to put aside my idealism and promote compromise. I've also had to\nbecome humble and admit that sometimes the front-end is not the place where\neverything should live. (But I still think there's a whole lot of logic on the\nserver that shouldn't be there. Again, another topic for another post). The\nbenefit to engaging developers across architectural boundaries and striving to\nteach is that I've been able to learn a lot. I've learned how to effectively\ntest drive [JavaScript](https://pivotal.github.com/jasmine/) (/hattip\n[@searls](https://twitter.com/searls)), how to build scalable, object-oriented\nCSS/HTML, how to achieve an appropriate [separation of\nconcerns](https://documentcloud.github.com/backbone/) on the front-end, and how\nto translate n-tier architecture principles from the server-side to my\nclient-side code. Being at a company like Pillar has provided a rich environment\nin which to grow; it's something I'm very grateful for.\n\n## The Path to Agility\n\nMany of my co-workers attended the\n[\\#pathtoagility](https://twitter.com/#!/search/%23pathtoagility) conference in\nOhio this week. I wasn't able to attend but I think it's fitting to end a post\nabout my own personal \"path to agility\" with some forward looking thoughts that\ncan help you (and me) to continue on that path. Software development is evolving\nand changing; set yourself up for success by being willing to evolve and change\nright along with it. Agility is more than process or technical solutions; it\ninvolves integrity, accountability and a fundamental paradigm shift in your way\nof thinking. Continue to look for ways you can shift your thinking. Be\nopen-minded. Teaching is a powerful exercise in self examination and growth; try\nto spend time teaching those around you, it's worth the investment.\n"
}></{
  "path": "app/posts/2011-05-27-immersed-in-agile.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Immersed in agile",
      "date": "2011-05-27"
    },
    "source": "\n> I started working as an independent contractor for [Pillar\nTechnology](https://www.pillartechnology.com/) over 6 months ago (Nov 1, 2010).\nAt the time, I had no idea what was in store for me; looking back now I think\nI've hit a new point from which to grow in my career so it seems time to engage\nin a retrospective on the last year.\n\n## Some History\n\nPrior to working with Pillar I spent just over 2 years working on a number of\nprojects at [VendAsta Technologies](https://www.vendasta.com/). I grew a lot in\nthose 2 years but mostly in a technical capacity. Things like continuous\nintegration, build configuration, and (briefly) unit testing were introduced to\nme. It was enlightening to get a taste of the technical goodness offered by\nthose things but ultimately I felt like there was no one there who could guide\nme in the underlying principles that necessitate them. At the same time I was\nintroduced to many of the core concepts of this thing people in the software\ndevelopment community call \"agile\". Coming out of VendAsta in 2010 I thought I\nknew what agile was. I thought it was Scrum, XP, TDD, continuous integration and\na whole host of other technical terms.\n\nLooking back at where I've come in the last 7 months I don't think I can say I\nknow what agile is even now, because it is an ephemeral thing that seems to be\nconstantly evolving. What I can say is that I know a lot more about the core of\nwhat's important in software development: delivering business value and earning\nthe trust of those you work with.\n\n## Trust and Value over Working Software\n\nMy first 6 months with Pillar were served working on a client project for\n[Gordon Food Services](https://www.gfs.com/en) out of Grand Rapids, MI. I worked\nremotely for those 6 months out of an office in my basement that\n[Tanys](https://www.twitter.com/littlemrsmosher) and I built the week before I\nstarted. A brief note on working remotely: it opened my eyes up to a key thing\nthat's required to be successful in life; self-discipline. I had my doubts about\nhow effective I could be remotely but I decided it was worth the challenge and\ncommitted to myself that I would do what it took. Getting up at 7 am to make\nstandup in the morning (hello, 2 hour time zone difference), pushing myself to\nkeep lines of communication open, and pouring my heart and soul into building\ntrust with the client; these are the things I did over those 6 months. And it\npaid off. I grew in my technical knowledge but also in my ability to cultivate\ngood business relationships.\n\nThe people at both the client and Pillar have been great, providing much in the\nway of the mentoring and leadership around the principles of good software\ndevelopment that I had craved for such a long time. In 6 months working for GFS\nthe team I was part of a team that produced software faster, with less defects,\nand with more value than any other project I've been on. The experience was\nenergizing and opened my eyes to the power of building trust and constantly\ndelivering value all while adhering to solid software craftsmanship principles.\n\n## Beyond TDD\n\nPrior to joining Pillar I thought I had a pretty good grasp on the technical\nconcepts surrounding \"agile\". 7 months later my eyes have been opened to how\nmuch more than technicality agile really is. At its heart, agile is a way of\nthinking that promotes accountability, integrity, quality, and value oriented\nthinking. I used to think writing tests was something you did after writing\nproduction code to verify the behaviour you had crafted. Now I understand\nthat \"The fundamental conundrum of software development: I can code fast when I\nhave a good design but I can't design until I've coded slowly.\" ([Kent\nBeck](https://twitoaster.com/kentbeck/the-fundamental-conundrum-of-software-development-i-can-code-fast-when-i-have-a-good-design-but-i-cant-design-until-ive-coded-slowly/)).\n\nA good design is achieved by thinking out architecture by writing tests first.\nI've also learned that tests can act as documentation by example, so it's\nimportant to continually curate test code so that it doesn't grow stagnant. Most\nimportantly of all I've seen the power of having a codebase with 95%+ test\ncoverage and how that acts as a safety net to making change. This last point\ncan't be overstated; the freedom experienced through red/green/refactor makes\nchange cheap and development incredibly enjoyable. At the core of my change here\nfrom 7 months ago is a paradigm shift in the way I think about developing: I\ndon't feel responsible writing production code until I have a failing test.\n\n## The Best Way To Learn\n\nSomething I've always felt positive about is my ability to teach. I feel I have\nthe heart of a teacher, which means that I can empathize with people to\nunderstand the pain they feel. (I've felt the pain too, which always helps). In\nthe last 7 months I've been devoting myself to studying more effective ways to\npromote craftsmanship in front-end development. One of those ways is to teach\nmore. This has not been easy; front-end development has historically been\ntreated as a second class citizen. (I could write a whole other blog post about\nthat alone, but that's a topic for another time). Breaking down barriers between\nfront-end and back-end developers requires a certain amount of grace and poise\nthat I didn't have 7 months ago. Being able to effectively communicate solid\nengineering principles to back-end oriented developers requires empathy,\ncompassion, and the ability to communicate using language they understand.\n\nI've often had to put aside my idealism and promote compromise. I've also had to\nbecome humble and admit that sometimes the front-end is not the place where\neverything should live. (But I still think there's a whole lot of logic on the\nserver that shouldn't be there. Again, another topic for another post). The\nbenefit to engaging developers across architectural boundaries and striving to\nteach is that I've been able to learn a lot. I've learned how to effectively\ntest drive [JavaScript](https://pivotal.github.com/jasmine/) (/hattip\n[@searls](https://twitter.com/searls)), how to build scalable, object-oriented\nCSS/HTML, how to achieve an appropriate [separation of\nconcerns](https://documentcloud.github.com/backbone/) on the front-end, and how\nto translate n-tier architecture principles from the server-side to my\nclient-side code. Being at a company like Pillar has provided a rich environment\nin which to grow; it's something I'm very grateful for.\n\n## The Path to Agility\n\nMany of my co-workers attended the\n[\\#pathtoagility](https://twitter.com/#!/search/%23pathtoagility) conference in\nOhio this week. I wasn't able to attend but I think it's fitting to end a post\nabout my own personal \"path to agility\" with some forward looking thoughts that\ncan help you (and me) to continue on that path. Software development is evolving\nand changing; set yourself up for success by being willing to evolve and change\nright along with it. Agility is more than process or technical solutions; it\ninvolves integrity, accountability and a fundamental paradigm shift in your way\nof thinking. Continue to look for ways you can shift your thinking. Be\nopen-minded. Teaching is a powerful exercise in self examination and growth; try\nto spend time teaching those around you, it's worth the investment.\n"
  },
  "attributes": {
    "title": "Immersed in agile",
    "date": "2011-05-27"
  },
  "markdown": "\n> I started working as an independent contractor for [Pillar\nTechnology](https://www.pillartechnology.com/) over 6 months ago (Nov 1, 2010).\nAt the time, I had no idea what was in store for me; looking back now I think\nI've hit a new point from which to grow in my career so it seems time to engage\nin a retrospective on the last year.\n\n## Some History\n\nPrior to working with Pillar I spent just over 2 years working on a number of\nprojects at [VendAsta Technologies](https://www.vendasta.com/). I grew a lot in\nthose 2 years but mostly in a technical capacity. Things like continuous\nintegration, build configuration, and (briefly) unit testing were introduced to\nme. It was enlightening to get a taste of the technical goodness offered by\nthose things but ultimately I felt like there was no one there who could guide\nme in the underlying principles that necessitate them. At the same time I was\nintroduced to many of the core concepts of this thing people in the software\ndevelopment community call \"agile\". Coming out of VendAsta in 2010 I thought I\nknew what agile was. I thought it was Scrum, XP, TDD, continuous integration and\na whole host of other technical terms.\n\nLooking back at where I've come in the last 7 months I don't think I can say I\nknow what agile is even now, because it is an ephemeral thing that seems to be\nconstantly evolving. What I can say is that I know a lot more about the core of\nwhat's important in software development: delivering business value and earning\nthe trust of those you work with.\n\n## Trust and Value over Working Software\n\nMy first 6 months with Pillar were served working on a client project for\n[Gordon Food Services](https://www.gfs.com/en) out of Grand Rapids, MI. I worked\nremotely for those 6 months out of an office in my basement that\n[Tanys](https://www.twitter.com/littlemrsmosher) and I built the week before I\nstarted. A brief note on working remotely: it opened my eyes up to a key thing\nthat's required to be successful in life; self-discipline. I had my doubts about\nhow effective I could be remotely but I decided it was worth the challenge and\ncommitted to myself that I would do what it took. Getting up at 7 am to make\nstandup in the morning (hello, 2 hour time zone difference), pushing myself to\nkeep lines of communication open, and pouring my heart and soul into building\ntrust with the client; these are the things I did over those 6 months. And it\npaid off. I grew in my technical knowledge but also in my ability to cultivate\ngood business relationships.\n\nThe people at both the client and Pillar have been great, providing much in the\nway of the mentoring and leadership around the principles of good software\ndevelopment that I had craved for such a long time. In 6 months working for GFS\nthe team I was part of a team that produced software faster, with less defects,\nand with more value than any other project I've been on. The experience was\nenergizing and opened my eyes to the power of building trust and constantly\ndelivering value all while adhering to solid software craftsmanship principles.\n\n## Beyond TDD\n\nPrior to joining Pillar I thought I had a pretty good grasp on the technical\nconcepts surrounding \"agile\". 7 months later my eyes have been opened to how\nmuch more than technicality agile really is. At its heart, agile is a way of\nthinking that promotes accountability, integrity, quality, and value oriented\nthinking. I used to think writing tests was something you did after writing\nproduction code to verify the behaviour you had crafted. Now I understand\nthat \"The fundamental conundrum of software development: I can code fast when I\nhave a good design but I can't design until I've coded slowly.\" ([Kent\nBeck](https://twitoaster.com/kentbeck/the-fundamental-conundrum-of-software-development-i-can-code-fast-when-i-have-a-good-design-but-i-cant-design-until-ive-coded-slowly/)).\n\nA good design is achieved by thinking out architecture by writing tests first.\nI've also learned that tests can act as documentation by example, so it's\nimportant to continually curate test code so that it doesn't grow stagnant. Most\nimportantly of all I've seen the power of having a codebase with 95%+ test\ncoverage and how that acts as a safety net to making change. This last point\ncan't be overstated; the freedom experienced through red/green/refactor makes\nchange cheap and development incredibly enjoyable. At the core of my change here\nfrom 7 months ago is a paradigm shift in the way I think about developing: I\ndon't feel responsible writing production code until I have a failing test.\n\n## The Best Way To Learn\n\nSomething I've always felt positive about is my ability to teach. I feel I have\nthe heart of a teacher, which means that I can empathize with people to\nunderstand the pain they feel. (I've felt the pain too, which always helps). In\nthe last 7 months I've been devoting myself to studying more effective ways to\npromote craftsmanship in front-end development. One of those ways is to teach\nmore. This has not been easy; front-end development has historically been\ntreated as a second class citizen. (I could write a whole other blog post about\nthat alone, but that's a topic for another time). Breaking down barriers between\nfront-end and back-end developers requires a certain amount of grace and poise\nthat I didn't have 7 months ago. Being able to effectively communicate solid\nengineering principles to back-end oriented developers requires empathy,\ncompassion, and the ability to communicate using language they understand.\n\nI've often had to put aside my idealism and promote compromise. I've also had to\nbecome humble and admit that sometimes the front-end is not the place where\neverything should live. (But I still think there's a whole lot of logic on the\nserver that shouldn't be there. Again, another topic for another post). The\nbenefit to engaging developers across architectural boundaries and striving to\nteach is that I've been able to learn a lot. I've learned how to effectively\ntest drive [JavaScript](https://pivotal.github.com/jasmine/) (/hattip\n[@searls](https://twitter.com/searls)), how to build scalable, object-oriented\nCSS/HTML, how to achieve an appropriate [separation of\nconcerns](https://documentcloud.github.com/backbone/) on the front-end, and how\nto translate n-tier architecture principles from the server-side to my\nclient-side code. Being at a company like Pillar has provided a rich environment\nin which to grow; it's something I'm very grateful for.\n\n## The Path to Agility\n\nMany of my co-workers attended the\n[\\#pathtoagility](https://twitter.com/#!/search/%23pathtoagility) conference in\nOhio this week. I wasn't able to attend but I think it's fitting to end a post\nabout my own personal \"path to agility\" with some forward looking thoughts that\ncan help you (and me) to continue on that path. Software development is evolving\nand changing; set yourself up for success by being willing to evolve and change\nright along with it. Agility is more than process or technical solutions; it\ninvolves integrity, accountability and a fundamental paradigm shift in your way\nof thinking. Continue to look for ways you can shift your thinking. Be\nopen-minded. Teaching is a powerful exercise in self examination and growth; try\nto spend time teaching those around you, it's worth the investment.\n"
}></pre></div><div><a href="/posts/2010-11-05-front-end-web-debugging-techniques-isolation.html">Frontend Web Debugging Techniques : Isolation</a><pre><{
  "path": "app/posts/2010-11-05-front-end-web-debugging-techniques-isolation.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Frontend Web Debugging Techniques : Isolation",
      "date": "2010-11-05"
    },
    "source": "\n> I must be getting older. My idea of \"fun\" on a Friday night is to go downstairs and write a blog post with some of the ideas that have been percolating in my brain for the last few months. I am disappoint. Oh well, my impending senility is your benefit! That is of course if you're into front end web development at all.\n\nSo, I've been talking with a few friends lately about this idea of \"good habits\" with regards to front end web development and I started stewing on a bunch of ideas on how I could write about something like that in an effective way. Sorry to say that this blog post will not be about good habits relating to code but rather as they relate to debugging front end code. I think the latter is valuable and you'll still get a decent idea of some good habits to work with going forward. Enough rambling, onward!\n\n## Isolation, Your First Stop\n\nYou've just fired up your browser and checked out an existing application from your repository of choice. You get the app running and go to take a look at the state of the front end because you have a bug to fix. A nice shiny red bug sitting there in front of you. Eager to dig in you open [Firebug](https://www.getfirebug.com) / [Webkit Inspector](https://webkit.org/blog/1091/more-web-inspector-updates/) and find yourself looking at no less than 50 separate CSS files and 40 javascript files. YIKES!\n\nThe bug card you have says some buttons aren't appearing properly in IE7 and the latest Chrome. So you dive in with your front end tweaker and start disabling styles dynamically hoping you can affect some change in the cascade that will fix the bug live in the browser right there in front of you. Bam! Looks good in Firefox/Chrome and then you open IE and things go to hell. Sound familiar?\n\nIt's at this point that you should really stop what you're doing and try to isolate the problem. I've spent more than enough time hacking in this way to know that it's a lost cause and infinitely frustrating to boot. The best way to fix a rendering issue in a case like this is to isolate your problem so you can control the number of variables you are testing.\n\nHere's how I like to break down my isolation debugging process:\n\n## 1. Create a Test Case\n\nOpen a new html file in Textmate or your favorite code editor and create a brand new HTML page. I like to keep a skeleton page so I can do this quickly. This page should have no stylesheets or scripts loaded.\n\n<script src=\"https://gist.github.com/davemo/665184.js\"></script>\n\n## 2. Replicate the Environment\n\nBring the HTML in question into your sample page as it appears in your production code. Also bring only the CSS that applies to those elements and put them in a style block in the head of your sample page.\n\n<script src=\"https://gist.github.com/davemo/665183.js\"></script>\n\n## 3. Verify\n\nYou probably have some assumptions about what you think the problem is, this is the step where you verify that. Open your sample page in the browsers you want to test in and see what kind of results you get. The goal here is to eliminate the thousands of lines of other CSS and JavaScript that might be altering the way your markup is displayed.\n\n![](/img/17120048-Screen_shot_2010-11-05_at_10.13.57_PM.png)\n![](/img/17120050-Screen_shot_2010-11-05_at_10.14.39_PM.png)\n\n## 4. Refactor\n\nOnce you've verified things are behaving the way you want you should probably refactor that HTML and CSS to contain less presentation in your markup. Often markup from legacy applications has been touched by many different people with varying interpretations about how to write HTML; that's ok but given you spent the time to isolate this problem you may as well do some cleanup.\n\n## 5. Verify ... Again\n\nYou've made changes, run your test page through the browsers you are testing for again. Repeat step 4 and 5 until you've got a good baseline to work with. It's also good to remember the answer to [https://dowebsitesneedtolookexactlythesameineverybrowser.com](https://dowebsitesneedtolookexactlythesameineverybrowser.com) at this point.\n\n## 6. Integrate\n\nYou were able to eliminate a bunch of redundant CSS selectors and redundant markup. Great! Now it's time to inject your newly refactored code back into the mess of 50 CSS and 40 javascript files. This can be challenging based on how many dependencies you touched in your refactoring but at least you have a baseline of what to expect now.\n\nIntegration is going to result in some more rendering anomalies but now you have a core set of solid CSS/HTML that you know will work. What you do now is go through Firebug/Webkit Inspector and start disabling styles in the cascade that also affect your elements until you get the result you are looking for.\n\n## Conclusions\n\nYou will probably still have to fiddle but at least you will have eliminated a significant amount of frustration by isolating the problem and proving out your assumptions about how the markup and css will behave in other browsers. Of course you could avoid a significant amount of this cross browser troubleshooting by using something like [Compass](https://compass-style.org/docs/) and [SASS](https://brandonmathis.com/blog/2010/09/21/fast-color-theming-with-compass-and-sass/),\nbut that's a topic for another blog post ;)\n\nI hope this was helpful to you and I wish you luck on improving your frontend debugging process and reducing the amount of frustration experienced.\n"
  },
  "attributes": {
    "title": "Frontend Web Debugging Techniques : Isolation",
    "date": "2010-11-05"
  },
  "markdown": "\n> I must be getting older. My idea of \"fun\" on a Friday night is to go downstairs and write a blog post with some of the ideas that have been percolating in my brain for the last few months. I am disappoint. Oh well, my impending senility is your benefit! That is of course if you're into front end web development at all.\n\nSo, I've been talking with a few friends lately about this idea of \"good habits\" with regards to front end web development and I started stewing on a bunch of ideas on how I could write about something like that in an effective way. Sorry to say that this blog post will not be about good habits relating to code but rather as they relate to debugging front end code. I think the latter is valuable and you'll still get a decent idea of some good habits to work with going forward. Enough rambling, onward!\n\n## Isolation, Your First Stop\n\nYou've just fired up your browser and checked out an existing application from your repository of choice. You get the app running and go to take a look at the state of the front end because you have a bug to fix. A nice shiny red bug sitting there in front of you. Eager to dig in you open [Firebug](https://www.getfirebug.com) / [Webkit Inspector](https://webkit.org/blog/1091/more-web-inspector-updates/) and find yourself looking at no less than 50 separate CSS files and 40 javascript files. YIKES!\n\nThe bug card you have says some buttons aren't appearing properly in IE7 and the latest Chrome. So you dive in with your front end tweaker and start disabling styles dynamically hoping you can affect some change in the cascade that will fix the bug live in the browser right there in front of you. Bam! Looks good in Firefox/Chrome and then you open IE and things go to hell. Sound familiar?\n\nIt's at this point that you should really stop what you're doing and try to isolate the problem. I've spent more than enough time hacking in this way to know that it's a lost cause and infinitely frustrating to boot. The best way to fix a rendering issue in a case like this is to isolate your problem so you can control the number of variables you are testing.\n\nHere's how I like to break down my isolation debugging process:\n\n## 1. Create a Test Case\n\nOpen a new html file in Textmate or your favorite code editor and create a brand new HTML page. I like to keep a skeleton page so I can do this quickly. This page should have no stylesheets or scripts loaded.\n\n<script src=\"https://gist.github.com/davemo/665184.js\"></script>\n\n## 2. Replicate the Environment\n\nBring the HTML in question into your sample page as it appears in your production code. Also bring only the CSS that applies to those elements and put them in a style block in the head of your sample page.\n\n<script src=\"https://gist.github.com/davemo/665183.js\"></script>\n\n## 3. Verify\n\nYou probably have some assumptions about what you think the problem is, this is the step where you verify that. Open your sample page in the browsers you want to test in and see what kind of results you get. The goal here is to eliminate the thousands of lines of other CSS and JavaScript that might be altering the way your markup is displayed.\n\n![](/img/17120048-Screen_shot_2010-11-05_at_10.13.57_PM.png)\n![](/img/17120050-Screen_shot_2010-11-05_at_10.14.39_PM.png)\n\n## 4. Refactor\n\nOnce you've verified things are behaving the way you want you should probably refactor that HTML and CSS to contain less presentation in your markup. Often markup from legacy applications has been touched by many different people with varying interpretations about how to write HTML; that's ok but given you spent the time to isolate this problem you may as well do some cleanup.\n\n## 5. Verify ... Again\n\nYou've made changes, run your test page through the browsers you are testing for again. Repeat step 4 and 5 until you've got a good baseline to work with. It's also good to remember the answer to [https://dowebsitesneedtolookexactlythesameineverybrowser.com](https://dowebsitesneedtolookexactlythesameineverybrowser.com) at this point.\n\n## 6. Integrate\n\nYou were able to eliminate a bunch of redundant CSS selectors and redundant markup. Great! Now it's time to inject your newly refactored code back into the mess of 50 CSS and 40 javascript files. This can be challenging based on how many dependencies you touched in your refactoring but at least you have a baseline of what to expect now.\n\nIntegration is going to result in some more rendering anomalies but now you have a core set of solid CSS/HTML that you know will work. What you do now is go through Firebug/Webkit Inspector and start disabling styles in the cascade that also affect your elements until you get the result you are looking for.\n\n## Conclusions\n\nYou will probably still have to fiddle but at least you will have eliminated a significant amount of frustration by isolating the problem and proving out your assumptions about how the markup and css will behave in other browsers. Of course you could avoid a significant amount of this cross browser troubleshooting by using something like [Compass](https://compass-style.org/docs/) and [SASS](https://brandonmathis.com/blog/2010/09/21/fast-color-theming-with-compass-and-sass/),\nbut that's a topic for another blog post ;)\n\nI hope this was helpful to you and I wish you luck on improving your frontend debugging process and reducing the amount of frustration experienced.\n"
}></{
  "path": "app/posts/2010-11-05-front-end-web-debugging-techniques-isolation.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Frontend Web Debugging Techniques : Isolation",
      "date": "2010-11-05"
    },
    "source": "\n> I must be getting older. My idea of \"fun\" on a Friday night is to go downstairs and write a blog post with some of the ideas that have been percolating in my brain for the last few months. I am disappoint. Oh well, my impending senility is your benefit! That is of course if you're into front end web development at all.\n\nSo, I've been talking with a few friends lately about this idea of \"good habits\" with regards to front end web development and I started stewing on a bunch of ideas on how I could write about something like that in an effective way. Sorry to say that this blog post will not be about good habits relating to code but rather as they relate to debugging front end code. I think the latter is valuable and you'll still get a decent idea of some good habits to work with going forward. Enough rambling, onward!\n\n## Isolation, Your First Stop\n\nYou've just fired up your browser and checked out an existing application from your repository of choice. You get the app running and go to take a look at the state of the front end because you have a bug to fix. A nice shiny red bug sitting there in front of you. Eager to dig in you open [Firebug](https://www.getfirebug.com) / [Webkit Inspector](https://webkit.org/blog/1091/more-web-inspector-updates/) and find yourself looking at no less than 50 separate CSS files and 40 javascript files. YIKES!\n\nThe bug card you have says some buttons aren't appearing properly in IE7 and the latest Chrome. So you dive in with your front end tweaker and start disabling styles dynamically hoping you can affect some change in the cascade that will fix the bug live in the browser right there in front of you. Bam! Looks good in Firefox/Chrome and then you open IE and things go to hell. Sound familiar?\n\nIt's at this point that you should really stop what you're doing and try to isolate the problem. I've spent more than enough time hacking in this way to know that it's a lost cause and infinitely frustrating to boot. The best way to fix a rendering issue in a case like this is to isolate your problem so you can control the number of variables you are testing.\n\nHere's how I like to break down my isolation debugging process:\n\n## 1. Create a Test Case\n\nOpen a new html file in Textmate or your favorite code editor and create a brand new HTML page. I like to keep a skeleton page so I can do this quickly. This page should have no stylesheets or scripts loaded.\n\n<script src=\"https://gist.github.com/davemo/665184.js\"></script>\n\n## 2. Replicate the Environment\n\nBring the HTML in question into your sample page as it appears in your production code. Also bring only the CSS that applies to those elements and put them in a style block in the head of your sample page.\n\n<script src=\"https://gist.github.com/davemo/665183.js\"></script>\n\n## 3. Verify\n\nYou probably have some assumptions about what you think the problem is, this is the step where you verify that. Open your sample page in the browsers you want to test in and see what kind of results you get. The goal here is to eliminate the thousands of lines of other CSS and JavaScript that might be altering the way your markup is displayed.\n\n![](/img/17120048-Screen_shot_2010-11-05_at_10.13.57_PM.png)\n![](/img/17120050-Screen_shot_2010-11-05_at_10.14.39_PM.png)\n\n## 4. Refactor\n\nOnce you've verified things are behaving the way you want you should probably refactor that HTML and CSS to contain less presentation in your markup. Often markup from legacy applications has been touched by many different people with varying interpretations about how to write HTML; that's ok but given you spent the time to isolate this problem you may as well do some cleanup.\n\n## 5. Verify ... Again\n\nYou've made changes, run your test page through the browsers you are testing for again. Repeat step 4 and 5 until you've got a good baseline to work with. It's also good to remember the answer to [https://dowebsitesneedtolookexactlythesameineverybrowser.com](https://dowebsitesneedtolookexactlythesameineverybrowser.com) at this point.\n\n## 6. Integrate\n\nYou were able to eliminate a bunch of redundant CSS selectors and redundant markup. Great! Now it's time to inject your newly refactored code back into the mess of 50 CSS and 40 javascript files. This can be challenging based on how many dependencies you touched in your refactoring but at least you have a baseline of what to expect now.\n\nIntegration is going to result in some more rendering anomalies but now you have a core set of solid CSS/HTML that you know will work. What you do now is go through Firebug/Webkit Inspector and start disabling styles in the cascade that also affect your elements until you get the result you are looking for.\n\n## Conclusions\n\nYou will probably still have to fiddle but at least you will have eliminated a significant amount of frustration by isolating the problem and proving out your assumptions about how the markup and css will behave in other browsers. Of course you could avoid a significant amount of this cross browser troubleshooting by using something like [Compass](https://compass-style.org/docs/) and [SASS](https://brandonmathis.com/blog/2010/09/21/fast-color-theming-with-compass-and-sass/),\nbut that's a topic for another blog post ;)\n\nI hope this was helpful to you and I wish you luck on improving your frontend debugging process and reducing the amount of frustration experienced.\n"
  },
  "attributes": {
    "title": "Frontend Web Debugging Techniques : Isolation",
    "date": "2010-11-05"
  },
  "markdown": "\n> I must be getting older. My idea of \"fun\" on a Friday night is to go downstairs and write a blog post with some of the ideas that have been percolating in my brain for the last few months. I am disappoint. Oh well, my impending senility is your benefit! That is of course if you're into front end web development at all.\n\nSo, I've been talking with a few friends lately about this idea of \"good habits\" with regards to front end web development and I started stewing on a bunch of ideas on how I could write about something like that in an effective way. Sorry to say that this blog post will not be about good habits relating to code but rather as they relate to debugging front end code. I think the latter is valuable and you'll still get a decent idea of some good habits to work with going forward. Enough rambling, onward!\n\n## Isolation, Your First Stop\n\nYou've just fired up your browser and checked out an existing application from your repository of choice. You get the app running and go to take a look at the state of the front end because you have a bug to fix. A nice shiny red bug sitting there in front of you. Eager to dig in you open [Firebug](https://www.getfirebug.com) / [Webkit Inspector](https://webkit.org/blog/1091/more-web-inspector-updates/) and find yourself looking at no less than 50 separate CSS files and 40 javascript files. YIKES!\n\nThe bug card you have says some buttons aren't appearing properly in IE7 and the latest Chrome. So you dive in with your front end tweaker and start disabling styles dynamically hoping you can affect some change in the cascade that will fix the bug live in the browser right there in front of you. Bam! Looks good in Firefox/Chrome and then you open IE and things go to hell. Sound familiar?\n\nIt's at this point that you should really stop what you're doing and try to isolate the problem. I've spent more than enough time hacking in this way to know that it's a lost cause and infinitely frustrating to boot. The best way to fix a rendering issue in a case like this is to isolate your problem so you can control the number of variables you are testing.\n\nHere's how I like to break down my isolation debugging process:\n\n## 1. Create a Test Case\n\nOpen a new html file in Textmate or your favorite code editor and create a brand new HTML page. I like to keep a skeleton page so I can do this quickly. This page should have no stylesheets or scripts loaded.\n\n<script src=\"https://gist.github.com/davemo/665184.js\"></script>\n\n## 2. Replicate the Environment\n\nBring the HTML in question into your sample page as it appears in your production code. Also bring only the CSS that applies to those elements and put them in a style block in the head of your sample page.\n\n<script src=\"https://gist.github.com/davemo/665183.js\"></script>\n\n## 3. Verify\n\nYou probably have some assumptions about what you think the problem is, this is the step where you verify that. Open your sample page in the browsers you want to test in and see what kind of results you get. The goal here is to eliminate the thousands of lines of other CSS and JavaScript that might be altering the way your markup is displayed.\n\n![](/img/17120048-Screen_shot_2010-11-05_at_10.13.57_PM.png)\n![](/img/17120050-Screen_shot_2010-11-05_at_10.14.39_PM.png)\n\n## 4. Refactor\n\nOnce you've verified things are behaving the way you want you should probably refactor that HTML and CSS to contain less presentation in your markup. Often markup from legacy applications has been touched by many different people with varying interpretations about how to write HTML; that's ok but given you spent the time to isolate this problem you may as well do some cleanup.\n\n## 5. Verify ... Again\n\nYou've made changes, run your test page through the browsers you are testing for again. Repeat step 4 and 5 until you've got a good baseline to work with. It's also good to remember the answer to [https://dowebsitesneedtolookexactlythesameineverybrowser.com](https://dowebsitesneedtolookexactlythesameineverybrowser.com) at this point.\n\n## 6. Integrate\n\nYou were able to eliminate a bunch of redundant CSS selectors and redundant markup. Great! Now it's time to inject your newly refactored code back into the mess of 50 CSS and 40 javascript files. This can be challenging based on how many dependencies you touched in your refactoring but at least you have a baseline of what to expect now.\n\nIntegration is going to result in some more rendering anomalies but now you have a core set of solid CSS/HTML that you know will work. What you do now is go through Firebug/Webkit Inspector and start disabling styles in the cascade that also affect your elements until you get the result you are looking for.\n\n## Conclusions\n\nYou will probably still have to fiddle but at least you will have eliminated a significant amount of frustration by isolating the problem and proving out your assumptions about how the markup and css will behave in other browsers. Of course you could avoid a significant amount of this cross browser troubleshooting by using something like [Compass](https://compass-style.org/docs/) and [SASS](https://brandonmathis.com/blog/2010/09/21/fast-color-theming-with-compass-and-sass/),\nbut that's a topic for another blog post ;)\n\nI hope this was helpful to you and I wish you luck on improving your frontend debugging process and reducing the amount of frustration experienced.\n"
}></pre></div><div><a href="/posts/2010-09-01-focus-is-the-glue.html">Focus is the glue</a><pre><{
  "path": "app/posts/2010-09-01-focus-is-the-glue.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Focus is the glue",
      "date": "2010-09-01"
    },
    "source": "\n> I've been playing a lot of basketball at work these days on lunch and coffee\nbreaks. As a programmer who sits most of the day, it's nice to have a place to\ngo to spend some energy. I've been keeping track of my progress in shooting free\nthrows and my percentage has been steadily improving. I think I shot 80% last\nweek (using a general warmup and then 10 in a row as my benchmark).\n\nI had what I like to call a \"micro-epiphany\" the other day when I went out to shoot\nbaskets. I started thinking about what it takes to be successful at basketball\nand realized that there are two primary areas of skill required: **mechanics**\nand **focus**.\n\n\n![Image of a basketball going into a hoop with a sunset in the background](/img/14471799-basketball.jpg)\n\n(image courtesy [StuSeeger](https://www.flickr.com/photos/stuseeger/136715887/),\nFlickr).\n\nTo succeed in putting the ball through the hoop you have to be solid in your\nmechanics. Your guide hand needs to support, but not influence, the weight of\nthe ball on your shooting hand. The ball should be positioned in your shooting\nhand in front of your head and not above it. When you release the ball you need\nto have a proper follow-through that directs and puts the proper amount of spin\non it. The amount of weight you put into your shot is also influenced by the\nusage of your legs and the proportion of force you exert with your arms. When\nyou break it all down from a mechanics point of view there are lots of things\ngoing on in a shot. Add in other variables like juking defenders, shooting from\nthe triple-threat position, jump-shots and you can see how the number of points\nof failure in the mechanics of a shot can grow exponentially. In order to\ncombine all the elements of a successful shot you require an understanding of\nall these mechanics; more importantly you need to have focus.\n\nFocus is like the glue that holds all the pieces together. When I was learning\nto shoot in high school we would do many drills that broke down each of the\ncomponents of a shot into the basic parts. It's necessary to break things down\nwhen you are working with complex processes because people, by nature, develop\nbad habits. I haven't played ball competitively since the end of grade 12 and it\nwas surprising to me how bad my shot had become when I first picked it up again\nalmost 6 weeks ago. Luckily I had a solid foundation of skills and the knowledge\nof how to do \"corrective surgery\" on my shot techniques that I was able to\nimprove significantly and bring my shooting percentage up. (It remains to be\nseen if I can still perform under the pressures of defense and actually shoot\nwell when playing against other players). However, even if I was perfect in all\nof the mechanics I would fail to make my shots count if I didn't have a focus on\nwhat I was doing. It's hard to describe it accurately so I'll attempt to convey\na brain dump in words of what goes on inside my head during a shot when I'm\nattempting to focus.\n\n\"Ok, setting up for a shot, feet are planted, **I know what I'm going to do**.\"\n\n\"The **ball is going to go in** the hoop, I'm aiming for the back of the rim\nbecause historically that's where I hit a higher percentage of my shots\"\n\n\"Good leg extension, I need to followthrough with my hand and point to the rim.\n[Don't forget to reach for the\ncookies](https://www.wikihow.com/Be-a-Good-Basketball-Shooter)\".\n\n\"The **ball is going to go in**, I aimed for the back of the rim.\"\n\n\"Release felt good, **that shot is going in**.\"\n\nI don't know if that accurately conveys what happens in nearly a microsecond,\nbut it's roughly what goes on in my head during a successful shot. The things\nI've bolded are what I believe to be the most important parts of making that\nshot. Here's the breakdown as I can categorize it:\n\n1.  Have a plan.\n2.  Reiterate the plan.\n3.  Reinforce good habits I know.\n4.  Express confidence in the plan. Reiterate again.\n5.  Celebrate victory upon execution.\n\nHaving a plan is important. It helps focus my energy into a consistent framework\nthat I know has worked in the past. Reiterating things helps me to re-focus if\ndistractions start to creep into my mind. Talking to myself about the good\nhabits I've developed helps me to avoid falling into the bad ones. Expressing\nconfidence solidifies the action I'm about to take and removes any doubt in my\nmind that what I'm about to do will be successful. And claiming victory, which\nmay seem unimportant, is crucial to seeing that ball go through the hoop. The\nlast few moments before the ball leaves my hand are a critical point in the\ntimeline of the shot. Everything up to that point has been mechanics but once\nthe ball leaves my hand I can't let down in my mental focus. It's almost as if I\nwill the ball to go through the hoop and my mental concentration is just the\nfinal exclamation point, the stamp of approval, on the entire process.\n\n\"Swish. **The ball went into the net. I knew it would.** That was a great shot!\"\n\nOnce execution is complete and I can see the results of all my hard work I find\nit helps to reflect on what went well and give myself a pat on the back.\nPositive reinforcement of this kind works much better than beating myself up\nover the few mistakes I may have made in the process of taking the shot.\n\nI'm sure there are many parallels that can be drawn between what I've talked\nabout here and other facets of life, but I'll leave that up to you the reader to\ndo.\n\nAll I know is that it feels good to play ball again. It feels good to **focus**!\n\n"
  },
  "attributes": {
    "title": "Focus is the glue",
    "date": "2010-09-01"
  },
  "markdown": "\n> I've been playing a lot of basketball at work these days on lunch and coffee\nbreaks. As a programmer who sits most of the day, it's nice to have a place to\ngo to spend some energy. I've been keeping track of my progress in shooting free\nthrows and my percentage has been steadily improving. I think I shot 80% last\nweek (using a general warmup and then 10 in a row as my benchmark).\n\nI had what I like to call a \"micro-epiphany\" the other day when I went out to shoot\nbaskets. I started thinking about what it takes to be successful at basketball\nand realized that there are two primary areas of skill required: **mechanics**\nand **focus**.\n\n\n![Image of a basketball going into a hoop with a sunset in the background](/img/14471799-basketball.jpg)\n\n(image courtesy [StuSeeger](https://www.flickr.com/photos/stuseeger/136715887/),\nFlickr).\n\nTo succeed in putting the ball through the hoop you have to be solid in your\nmechanics. Your guide hand needs to support, but not influence, the weight of\nthe ball on your shooting hand. The ball should be positioned in your shooting\nhand in front of your head and not above it. When you release the ball you need\nto have a proper follow-through that directs and puts the proper amount of spin\non it. The amount of weight you put into your shot is also influenced by the\nusage of your legs and the proportion of force you exert with your arms. When\nyou break it all down from a mechanics point of view there are lots of things\ngoing on in a shot. Add in other variables like juking defenders, shooting from\nthe triple-threat position, jump-shots and you can see how the number of points\nof failure in the mechanics of a shot can grow exponentially. In order to\ncombine all the elements of a successful shot you require an understanding of\nall these mechanics; more importantly you need to have focus.\n\nFocus is like the glue that holds all the pieces together. When I was learning\nto shoot in high school we would do many drills that broke down each of the\ncomponents of a shot into the basic parts. It's necessary to break things down\nwhen you are working with complex processes because people, by nature, develop\nbad habits. I haven't played ball competitively since the end of grade 12 and it\nwas surprising to me how bad my shot had become when I first picked it up again\nalmost 6 weeks ago. Luckily I had a solid foundation of skills and the knowledge\nof how to do \"corrective surgery\" on my shot techniques that I was able to\nimprove significantly and bring my shooting percentage up. (It remains to be\nseen if I can still perform under the pressures of defense and actually shoot\nwell when playing against other players). However, even if I was perfect in all\nof the mechanics I would fail to make my shots count if I didn't have a focus on\nwhat I was doing. It's hard to describe it accurately so I'll attempt to convey\na brain dump in words of what goes on inside my head during a shot when I'm\nattempting to focus.\n\n\"Ok, setting up for a shot, feet are planted, **I know what I'm going to do**.\"\n\n\"The **ball is going to go in** the hoop, I'm aiming for the back of the rim\nbecause historically that's where I hit a higher percentage of my shots\"\n\n\"Good leg extension, I need to followthrough with my hand and point to the rim.\n[Don't forget to reach for the\ncookies](https://www.wikihow.com/Be-a-Good-Basketball-Shooter)\".\n\n\"The **ball is going to go in**, I aimed for the back of the rim.\"\n\n\"Release felt good, **that shot is going in**.\"\n\nI don't know if that accurately conveys what happens in nearly a microsecond,\nbut it's roughly what goes on in my head during a successful shot. The things\nI've bolded are what I believe to be the most important parts of making that\nshot. Here's the breakdown as I can categorize it:\n\n1.  Have a plan.\n2.  Reiterate the plan.\n3.  Reinforce good habits I know.\n4.  Express confidence in the plan. Reiterate again.\n5.  Celebrate victory upon execution.\n\nHaving a plan is important. It helps focus my energy into a consistent framework\nthat I know has worked in the past. Reiterating things helps me to re-focus if\ndistractions start to creep into my mind. Talking to myself about the good\nhabits I've developed helps me to avoid falling into the bad ones. Expressing\nconfidence solidifies the action I'm about to take and removes any doubt in my\nmind that what I'm about to do will be successful. And claiming victory, which\nmay seem unimportant, is crucial to seeing that ball go through the hoop. The\nlast few moments before the ball leaves my hand are a critical point in the\ntimeline of the shot. Everything up to that point has been mechanics but once\nthe ball leaves my hand I can't let down in my mental focus. It's almost as if I\nwill the ball to go through the hoop and my mental concentration is just the\nfinal exclamation point, the stamp of approval, on the entire process.\n\n\"Swish. **The ball went into the net. I knew it would.** That was a great shot!\"\n\nOnce execution is complete and I can see the results of all my hard work I find\nit helps to reflect on what went well and give myself a pat on the back.\nPositive reinforcement of this kind works much better than beating myself up\nover the few mistakes I may have made in the process of taking the shot.\n\nI'm sure there are many parallels that can be drawn between what I've talked\nabout here and other facets of life, but I'll leave that up to you the reader to\ndo.\n\nAll I know is that it feels good to play ball again. It feels good to **focus**!\n\n"
}></{
  "path": "app/posts/2010-09-01-focus-is-the-glue.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Focus is the glue",
      "date": "2010-09-01"
    },
    "source": "\n> I've been playing a lot of basketball at work these days on lunch and coffee\nbreaks. As a programmer who sits most of the day, it's nice to have a place to\ngo to spend some energy. I've been keeping track of my progress in shooting free\nthrows and my percentage has been steadily improving. I think I shot 80% last\nweek (using a general warmup and then 10 in a row as my benchmark).\n\nI had what I like to call a \"micro-epiphany\" the other day when I went out to shoot\nbaskets. I started thinking about what it takes to be successful at basketball\nand realized that there are two primary areas of skill required: **mechanics**\nand **focus**.\n\n\n![Image of a basketball going into a hoop with a sunset in the background](/img/14471799-basketball.jpg)\n\n(image courtesy [StuSeeger](https://www.flickr.com/photos/stuseeger/136715887/),\nFlickr).\n\nTo succeed in putting the ball through the hoop you have to be solid in your\nmechanics. Your guide hand needs to support, but not influence, the weight of\nthe ball on your shooting hand. The ball should be positioned in your shooting\nhand in front of your head and not above it. When you release the ball you need\nto have a proper follow-through that directs and puts the proper amount of spin\non it. The amount of weight you put into your shot is also influenced by the\nusage of your legs and the proportion of force you exert with your arms. When\nyou break it all down from a mechanics point of view there are lots of things\ngoing on in a shot. Add in other variables like juking defenders, shooting from\nthe triple-threat position, jump-shots and you can see how the number of points\nof failure in the mechanics of a shot can grow exponentially. In order to\ncombine all the elements of a successful shot you require an understanding of\nall these mechanics; more importantly you need to have focus.\n\nFocus is like the glue that holds all the pieces together. When I was learning\nto shoot in high school we would do many drills that broke down each of the\ncomponents of a shot into the basic parts. It's necessary to break things down\nwhen you are working with complex processes because people, by nature, develop\nbad habits. I haven't played ball competitively since the end of grade 12 and it\nwas surprising to me how bad my shot had become when I first picked it up again\nalmost 6 weeks ago. Luckily I had a solid foundation of skills and the knowledge\nof how to do \"corrective surgery\" on my shot techniques that I was able to\nimprove significantly and bring my shooting percentage up. (It remains to be\nseen if I can still perform under the pressures of defense and actually shoot\nwell when playing against other players). However, even if I was perfect in all\nof the mechanics I would fail to make my shots count if I didn't have a focus on\nwhat I was doing. It's hard to describe it accurately so I'll attempt to convey\na brain dump in words of what goes on inside my head during a shot when I'm\nattempting to focus.\n\n\"Ok, setting up for a shot, feet are planted, **I know what I'm going to do**.\"\n\n\"The **ball is going to go in** the hoop, I'm aiming for the back of the rim\nbecause historically that's where I hit a higher percentage of my shots\"\n\n\"Good leg extension, I need to followthrough with my hand and point to the rim.\n[Don't forget to reach for the\ncookies](https://www.wikihow.com/Be-a-Good-Basketball-Shooter)\".\n\n\"The **ball is going to go in**, I aimed for the back of the rim.\"\n\n\"Release felt good, **that shot is going in**.\"\n\nI don't know if that accurately conveys what happens in nearly a microsecond,\nbut it's roughly what goes on in my head during a successful shot. The things\nI've bolded are what I believe to be the most important parts of making that\nshot. Here's the breakdown as I can categorize it:\n\n1.  Have a plan.\n2.  Reiterate the plan.\n3.  Reinforce good habits I know.\n4.  Express confidence in the plan. Reiterate again.\n5.  Celebrate victory upon execution.\n\nHaving a plan is important. It helps focus my energy into a consistent framework\nthat I know has worked in the past. Reiterating things helps me to re-focus if\ndistractions start to creep into my mind. Talking to myself about the good\nhabits I've developed helps me to avoid falling into the bad ones. Expressing\nconfidence solidifies the action I'm about to take and removes any doubt in my\nmind that what I'm about to do will be successful. And claiming victory, which\nmay seem unimportant, is crucial to seeing that ball go through the hoop. The\nlast few moments before the ball leaves my hand are a critical point in the\ntimeline of the shot. Everything up to that point has been mechanics but once\nthe ball leaves my hand I can't let down in my mental focus. It's almost as if I\nwill the ball to go through the hoop and my mental concentration is just the\nfinal exclamation point, the stamp of approval, on the entire process.\n\n\"Swish. **The ball went into the net. I knew it would.** That was a great shot!\"\n\nOnce execution is complete and I can see the results of all my hard work I find\nit helps to reflect on what went well and give myself a pat on the back.\nPositive reinforcement of this kind works much better than beating myself up\nover the few mistakes I may have made in the process of taking the shot.\n\nI'm sure there are many parallels that can be drawn between what I've talked\nabout here and other facets of life, but I'll leave that up to you the reader to\ndo.\n\nAll I know is that it feels good to play ball again. It feels good to **focus**!\n\n"
  },
  "attributes": {
    "title": "Focus is the glue",
    "date": "2010-09-01"
  },
  "markdown": "\n> I've been playing a lot of basketball at work these days on lunch and coffee\nbreaks. As a programmer who sits most of the day, it's nice to have a place to\ngo to spend some energy. I've been keeping track of my progress in shooting free\nthrows and my percentage has been steadily improving. I think I shot 80% last\nweek (using a general warmup and then 10 in a row as my benchmark).\n\nI had what I like to call a \"micro-epiphany\" the other day when I went out to shoot\nbaskets. I started thinking about what it takes to be successful at basketball\nand realized that there are two primary areas of skill required: **mechanics**\nand **focus**.\n\n\n![Image of a basketball going into a hoop with a sunset in the background](/img/14471799-basketball.jpg)\n\n(image courtesy [StuSeeger](https://www.flickr.com/photos/stuseeger/136715887/),\nFlickr).\n\nTo succeed in putting the ball through the hoop you have to be solid in your\nmechanics. Your guide hand needs to support, but not influence, the weight of\nthe ball on your shooting hand. The ball should be positioned in your shooting\nhand in front of your head and not above it. When you release the ball you need\nto have a proper follow-through that directs and puts the proper amount of spin\non it. The amount of weight you put into your shot is also influenced by the\nusage of your legs and the proportion of force you exert with your arms. When\nyou break it all down from a mechanics point of view there are lots of things\ngoing on in a shot. Add in other variables like juking defenders, shooting from\nthe triple-threat position, jump-shots and you can see how the number of points\nof failure in the mechanics of a shot can grow exponentially. In order to\ncombine all the elements of a successful shot you require an understanding of\nall these mechanics; more importantly you need to have focus.\n\nFocus is like the glue that holds all the pieces together. When I was learning\nto shoot in high school we would do many drills that broke down each of the\ncomponents of a shot into the basic parts. It's necessary to break things down\nwhen you are working with complex processes because people, by nature, develop\nbad habits. I haven't played ball competitively since the end of grade 12 and it\nwas surprising to me how bad my shot had become when I first picked it up again\nalmost 6 weeks ago. Luckily I had a solid foundation of skills and the knowledge\nof how to do \"corrective surgery\" on my shot techniques that I was able to\nimprove significantly and bring my shooting percentage up. (It remains to be\nseen if I can still perform under the pressures of defense and actually shoot\nwell when playing against other players). However, even if I was perfect in all\nof the mechanics I would fail to make my shots count if I didn't have a focus on\nwhat I was doing. It's hard to describe it accurately so I'll attempt to convey\na brain dump in words of what goes on inside my head during a shot when I'm\nattempting to focus.\n\n\"Ok, setting up for a shot, feet are planted, **I know what I'm going to do**.\"\n\n\"The **ball is going to go in** the hoop, I'm aiming for the back of the rim\nbecause historically that's where I hit a higher percentage of my shots\"\n\n\"Good leg extension, I need to followthrough with my hand and point to the rim.\n[Don't forget to reach for the\ncookies](https://www.wikihow.com/Be-a-Good-Basketball-Shooter)\".\n\n\"The **ball is going to go in**, I aimed for the back of the rim.\"\n\n\"Release felt good, **that shot is going in**.\"\n\nI don't know if that accurately conveys what happens in nearly a microsecond,\nbut it's roughly what goes on in my head during a successful shot. The things\nI've bolded are what I believe to be the most important parts of making that\nshot. Here's the breakdown as I can categorize it:\n\n1.  Have a plan.\n2.  Reiterate the plan.\n3.  Reinforce good habits I know.\n4.  Express confidence in the plan. Reiterate again.\n5.  Celebrate victory upon execution.\n\nHaving a plan is important. It helps focus my energy into a consistent framework\nthat I know has worked in the past. Reiterating things helps me to re-focus if\ndistractions start to creep into my mind. Talking to myself about the good\nhabits I've developed helps me to avoid falling into the bad ones. Expressing\nconfidence solidifies the action I'm about to take and removes any doubt in my\nmind that what I'm about to do will be successful. And claiming victory, which\nmay seem unimportant, is crucial to seeing that ball go through the hoop. The\nlast few moments before the ball leaves my hand are a critical point in the\ntimeline of the shot. Everything up to that point has been mechanics but once\nthe ball leaves my hand I can't let down in my mental focus. It's almost as if I\nwill the ball to go through the hoop and my mental concentration is just the\nfinal exclamation point, the stamp of approval, on the entire process.\n\n\"Swish. **The ball went into the net. I knew it would.** That was a great shot!\"\n\nOnce execution is complete and I can see the results of all my hard work I find\nit helps to reflect on what went well and give myself a pat on the back.\nPositive reinforcement of this kind works much better than beating myself up\nover the few mistakes I may have made in the process of taking the shot.\n\nI'm sure there are many parallels that can be drawn between what I've talked\nabout here and other facets of life, but I'll leave that up to you the reader to\ndo.\n\nAll I know is that it feels good to play ball again. It feels good to **focus**!\n\n"
}></pre></div><div><a href="/posts/2010-07-01-yes-man.html">Yes Man</a><pre><{
  "path": "app/posts/2010-07-01-yes-man.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Yes Man",
      "date": "2010-07-01"
    },
    "source": "\n> I haven't written anything here in a while. Life's full of seasons just like the\nplanet; I guess it's been winter on the blog while it's been summer outside (if\nyou can call the torrential downpour \"summer\"). I have a friend who went through\nan interesting experience recently. I don't want to get into the details because\nthey aren't important, what's important is the lessons learned through my\nfriend. I'll try and relate what I've learned through some stories.\n\nWhen I was in elementary school there was a certain hierarchy in place: the\nbullies intimidated the people who were weaker minded or easily influenced into\nsupporting them in their cause. They would surround themselves with these\npeople, the \"yes men\", and form what appeared to be an invincible force of fear\nand intimidation. Bullies do this for many reasons but the most fundamental is\nthat they want to get their way. I was involved with many altercations with the\nbullies because I refused to align myself with what they wanted. I chose to\nstand up for what I believed in and didn't feel like having someone else dictate\nhow I could or couldn't act. I'll be honest, standing up for what I believed in\ncaused me a lot of pain and grief. I got into fights, was picked on and made fun\nof, and generally seen as one of the unpopular kids as a result. But I didn't\ncompromise what I believed in; I didn't stand for someone influencing what I\nbelieved or what I could do. I wasn't a yes man then.\n\nDuring the transition period between elementary and high school (grade 8 - grade\n9) I noticed some interesting things about the relationship between the bullies\nand the yes men; they broke down. Part of it may be because of the size\ndifference in our elementary schools (a few hundred) and the high school (almost\n2000) but I think it was also due to the summer when most kids are on vacation\nor go out of town. The bullies didn't have their yes men around to back them,\nnor did they have a steady stream of kids to pick on so I think they had to find\nother things to do to scratch the \"bully\" itch, whatever that is. High school\nwas also a change for me, it afforded me the opportunity to not be on the bottom\nof the pecking order, so to speak. The bullies weren't in my classes and the\ncircle of yes men they had built up in elementary was disbursed throughout\nvarious course selections, timetables and schedules. Without the bullies and\ntheir yes men around I developed self confidence, I wasn't afraid to voice\nopinions in class and contribute to the discussion around me. I developed my own\nsense of direction in life, the things I felt were important, what I valued and\nwhat I wanted to do with my future. I wasn't a yes man then either.\n\nFast forward 20 years or so later and I've got a house, a beautiful wife, two\namazing children, a dog who wears a tie ( ask me later :), a job and\nresponsibilities. Those all sound like pretty great things; you might even say\nafter reading this far that the relative level of success I've achieved has been\nbecause I wasn't a yes man. The thing is, I've been a part time yes man for a\nwhile. Sometimes I stand up for what I think is right and sometimes I just keep\nmy mouth shut. The bullies aren't around anymore like they were in school, they\ndon't beat me up or call me names or get their friends to throw rocks at me,\nhowever there are new bullies and they aren't always people. Ideas can be\nbullies, things you read on the internet, things you listen to on the radio,\nbooks you read... they all call you to make some sort of choice when they engage\nyou. Money can be a bully, we always want more of it yet often getting more\ntruly never satisfies us; being a yes man to the money bully ends up in nothing\nbut grouchiness in my experience. We can also be bullies. We try and surround\nourselves with yes men who will make us feel validated about our decisions and\njustify the things we do.\n\nThe thing I've realized is that whether you're the bully or the yes man either\nway it sucks. The people in life who are the most successful are those who don't\ncompromise what they believe to conform to a certain standard. They stand up for\nwhat's true and good and noble and what drives them to be the kind of people\nthey are. They stay true to their convictions.\n\nI'm done being a yes man.\n"
  },
  "attributes": {
    "title": "Yes Man",
    "date": "2010-07-01"
  },
  "markdown": "\n> I haven't written anything here in a while. Life's full of seasons just like the\nplanet; I guess it's been winter on the blog while it's been summer outside (if\nyou can call the torrential downpour \"summer\"). I have a friend who went through\nan interesting experience recently. I don't want to get into the details because\nthey aren't important, what's important is the lessons learned through my\nfriend. I'll try and relate what I've learned through some stories.\n\nWhen I was in elementary school there was a certain hierarchy in place: the\nbullies intimidated the people who were weaker minded or easily influenced into\nsupporting them in their cause. They would surround themselves with these\npeople, the \"yes men\", and form what appeared to be an invincible force of fear\nand intimidation. Bullies do this for many reasons but the most fundamental is\nthat they want to get their way. I was involved with many altercations with the\nbullies because I refused to align myself with what they wanted. I chose to\nstand up for what I believed in and didn't feel like having someone else dictate\nhow I could or couldn't act. I'll be honest, standing up for what I believed in\ncaused me a lot of pain and grief. I got into fights, was picked on and made fun\nof, and generally seen as one of the unpopular kids as a result. But I didn't\ncompromise what I believed in; I didn't stand for someone influencing what I\nbelieved or what I could do. I wasn't a yes man then.\n\nDuring the transition period between elementary and high school (grade 8 - grade\n9) I noticed some interesting things about the relationship between the bullies\nand the yes men; they broke down. Part of it may be because of the size\ndifference in our elementary schools (a few hundred) and the high school (almost\n2000) but I think it was also due to the summer when most kids are on vacation\nor go out of town. The bullies didn't have their yes men around to back them,\nnor did they have a steady stream of kids to pick on so I think they had to find\nother things to do to scratch the \"bully\" itch, whatever that is. High school\nwas also a change for me, it afforded me the opportunity to not be on the bottom\nof the pecking order, so to speak. The bullies weren't in my classes and the\ncircle of yes men they had built up in elementary was disbursed throughout\nvarious course selections, timetables and schedules. Without the bullies and\ntheir yes men around I developed self confidence, I wasn't afraid to voice\nopinions in class and contribute to the discussion around me. I developed my own\nsense of direction in life, the things I felt were important, what I valued and\nwhat I wanted to do with my future. I wasn't a yes man then either.\n\nFast forward 20 years or so later and I've got a house, a beautiful wife, two\namazing children, a dog who wears a tie ( ask me later :), a job and\nresponsibilities. Those all sound like pretty great things; you might even say\nafter reading this far that the relative level of success I've achieved has been\nbecause I wasn't a yes man. The thing is, I've been a part time yes man for a\nwhile. Sometimes I stand up for what I think is right and sometimes I just keep\nmy mouth shut. The bullies aren't around anymore like they were in school, they\ndon't beat me up or call me names or get their friends to throw rocks at me,\nhowever there are new bullies and they aren't always people. Ideas can be\nbullies, things you read on the internet, things you listen to on the radio,\nbooks you read... they all call you to make some sort of choice when they engage\nyou. Money can be a bully, we always want more of it yet often getting more\ntruly never satisfies us; being a yes man to the money bully ends up in nothing\nbut grouchiness in my experience. We can also be bullies. We try and surround\nourselves with yes men who will make us feel validated about our decisions and\njustify the things we do.\n\nThe thing I've realized is that whether you're the bully or the yes man either\nway it sucks. The people in life who are the most successful are those who don't\ncompromise what they believe to conform to a certain standard. They stand up for\nwhat's true and good and noble and what drives them to be the kind of people\nthey are. They stay true to their convictions.\n\nI'm done being a yes man.\n"
}></{
  "path": "app/posts/2010-07-01-yes-man.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Yes Man",
      "date": "2010-07-01"
    },
    "source": "\n> I haven't written anything here in a while. Life's full of seasons just like the\nplanet; I guess it's been winter on the blog while it's been summer outside (if\nyou can call the torrential downpour \"summer\"). I have a friend who went through\nan interesting experience recently. I don't want to get into the details because\nthey aren't important, what's important is the lessons learned through my\nfriend. I'll try and relate what I've learned through some stories.\n\nWhen I was in elementary school there was a certain hierarchy in place: the\nbullies intimidated the people who were weaker minded or easily influenced into\nsupporting them in their cause. They would surround themselves with these\npeople, the \"yes men\", and form what appeared to be an invincible force of fear\nand intimidation. Bullies do this for many reasons but the most fundamental is\nthat they want to get their way. I was involved with many altercations with the\nbullies because I refused to align myself with what they wanted. I chose to\nstand up for what I believed in and didn't feel like having someone else dictate\nhow I could or couldn't act. I'll be honest, standing up for what I believed in\ncaused me a lot of pain and grief. I got into fights, was picked on and made fun\nof, and generally seen as one of the unpopular kids as a result. But I didn't\ncompromise what I believed in; I didn't stand for someone influencing what I\nbelieved or what I could do. I wasn't a yes man then.\n\nDuring the transition period between elementary and high school (grade 8 - grade\n9) I noticed some interesting things about the relationship between the bullies\nand the yes men; they broke down. Part of it may be because of the size\ndifference in our elementary schools (a few hundred) and the high school (almost\n2000) but I think it was also due to the summer when most kids are on vacation\nor go out of town. The bullies didn't have their yes men around to back them,\nnor did they have a steady stream of kids to pick on so I think they had to find\nother things to do to scratch the \"bully\" itch, whatever that is. High school\nwas also a change for me, it afforded me the opportunity to not be on the bottom\nof the pecking order, so to speak. The bullies weren't in my classes and the\ncircle of yes men they had built up in elementary was disbursed throughout\nvarious course selections, timetables and schedules. Without the bullies and\ntheir yes men around I developed self confidence, I wasn't afraid to voice\nopinions in class and contribute to the discussion around me. I developed my own\nsense of direction in life, the things I felt were important, what I valued and\nwhat I wanted to do with my future. I wasn't a yes man then either.\n\nFast forward 20 years or so later and I've got a house, a beautiful wife, two\namazing children, a dog who wears a tie ( ask me later :), a job and\nresponsibilities. Those all sound like pretty great things; you might even say\nafter reading this far that the relative level of success I've achieved has been\nbecause I wasn't a yes man. The thing is, I've been a part time yes man for a\nwhile. Sometimes I stand up for what I think is right and sometimes I just keep\nmy mouth shut. The bullies aren't around anymore like they were in school, they\ndon't beat me up or call me names or get their friends to throw rocks at me,\nhowever there are new bullies and they aren't always people. Ideas can be\nbullies, things you read on the internet, things you listen to on the radio,\nbooks you read... they all call you to make some sort of choice when they engage\nyou. Money can be a bully, we always want more of it yet often getting more\ntruly never satisfies us; being a yes man to the money bully ends up in nothing\nbut grouchiness in my experience. We can also be bullies. We try and surround\nourselves with yes men who will make us feel validated about our decisions and\njustify the things we do.\n\nThe thing I've realized is that whether you're the bully or the yes man either\nway it sucks. The people in life who are the most successful are those who don't\ncompromise what they believe to conform to a certain standard. They stand up for\nwhat's true and good and noble and what drives them to be the kind of people\nthey are. They stay true to their convictions.\n\nI'm done being a yes man.\n"
  },
  "attributes": {
    "title": "Yes Man",
    "date": "2010-07-01"
  },
  "markdown": "\n> I haven't written anything here in a while. Life's full of seasons just like the\nplanet; I guess it's been winter on the blog while it's been summer outside (if\nyou can call the torrential downpour \"summer\"). I have a friend who went through\nan interesting experience recently. I don't want to get into the details because\nthey aren't important, what's important is the lessons learned through my\nfriend. I'll try and relate what I've learned through some stories.\n\nWhen I was in elementary school there was a certain hierarchy in place: the\nbullies intimidated the people who were weaker minded or easily influenced into\nsupporting them in their cause. They would surround themselves with these\npeople, the \"yes men\", and form what appeared to be an invincible force of fear\nand intimidation. Bullies do this for many reasons but the most fundamental is\nthat they want to get their way. I was involved with many altercations with the\nbullies because I refused to align myself with what they wanted. I chose to\nstand up for what I believed in and didn't feel like having someone else dictate\nhow I could or couldn't act. I'll be honest, standing up for what I believed in\ncaused me a lot of pain and grief. I got into fights, was picked on and made fun\nof, and generally seen as one of the unpopular kids as a result. But I didn't\ncompromise what I believed in; I didn't stand for someone influencing what I\nbelieved or what I could do. I wasn't a yes man then.\n\nDuring the transition period between elementary and high school (grade 8 - grade\n9) I noticed some interesting things about the relationship between the bullies\nand the yes men; they broke down. Part of it may be because of the size\ndifference in our elementary schools (a few hundred) and the high school (almost\n2000) but I think it was also due to the summer when most kids are on vacation\nor go out of town. The bullies didn't have their yes men around to back them,\nnor did they have a steady stream of kids to pick on so I think they had to find\nother things to do to scratch the \"bully\" itch, whatever that is. High school\nwas also a change for me, it afforded me the opportunity to not be on the bottom\nof the pecking order, so to speak. The bullies weren't in my classes and the\ncircle of yes men they had built up in elementary was disbursed throughout\nvarious course selections, timetables and schedules. Without the bullies and\ntheir yes men around I developed self confidence, I wasn't afraid to voice\nopinions in class and contribute to the discussion around me. I developed my own\nsense of direction in life, the things I felt were important, what I valued and\nwhat I wanted to do with my future. I wasn't a yes man then either.\n\nFast forward 20 years or so later and I've got a house, a beautiful wife, two\namazing children, a dog who wears a tie ( ask me later :), a job and\nresponsibilities. Those all sound like pretty great things; you might even say\nafter reading this far that the relative level of success I've achieved has been\nbecause I wasn't a yes man. The thing is, I've been a part time yes man for a\nwhile. Sometimes I stand up for what I think is right and sometimes I just keep\nmy mouth shut. The bullies aren't around anymore like they were in school, they\ndon't beat me up or call me names or get their friends to throw rocks at me,\nhowever there are new bullies and they aren't always people. Ideas can be\nbullies, things you read on the internet, things you listen to on the radio,\nbooks you read... they all call you to make some sort of choice when they engage\nyou. Money can be a bully, we always want more of it yet often getting more\ntruly never satisfies us; being a yes man to the money bully ends up in nothing\nbut grouchiness in my experience. We can also be bullies. We try and surround\nourselves with yes men who will make us feel validated about our decisions and\njustify the things we do.\n\nThe thing I've realized is that whether you're the bully or the yes man either\nway it sucks. The people in life who are the most successful are those who don't\ncompromise what they believe to conform to a certain standard. They stand up for\nwhat's true and good and noble and what drives them to be the kind of people\nthey are. They stay true to their convictions.\n\nI'm done being a yes man.\n"
}></pre></div><div><a href="/posts/2010-02-12-3rd-party-comment-system-roundup.html">Third-Party Comment System Roundup</a><pre><{
  "path": "app/posts/2010-02-12-3rd-party-comment-system-roundup.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Third-Party Comment System Roundup",
      "date": "2010-02-12"
    },
    "source": "\n> We've all seen it. The classic tutorial on [insert popular web framework here]\nthat has us building a blogging system in twenty minutes or less. It's actually\ngetting kind of old and I'm growing sick of seeing what I'm able to create with\nonly platform x,y and z. I'm more interested in how I can use a web framework\nthat doesn't hold my hand by providing a bunch of \"one size fits all\" defaults.\nI like flexibility and choice.\n\nI like it when the web framework I'm using allows\nme to mix and match third party systems easily. One third party web framework\ncomponent that is becoming more popular is commenting systems. Let's take a\nbrief look at three of the most popular systems to see what each offers us.\n\n## Intense Debate\n\n![](/img/6538176-media_httpfarm3static_zwrDw.png)\n\n[www.intensedebate.com](https://www.intensedebate.com)\n\n[@photomatt](https://twitter.com/photomatt)\n\nI first experienced using intense debate when reading a couple blog posts on\nJohn W. Longs [wise heart design](https://www.wiseheartdesign.com). Created by\n[automattic](https://twitter.com/automattic) of wordpress fame, Intense Debate\n(ID) is a hosted commenting system that utilizes some sexy javascript and social\nnetwork integration to allow you to add comments to pretty much any page on the\nInternet. My experience with the sign up process for intense debate was actually\npretty frustrating as the log in system didn't seem to recognize my OpenID and\nyou can't create an account for the purposes of installation with anything\nexcept OpenID or their hand rolled registration.\n\nI was expecting to be able to sign up using any of the social networks they\nallow you to sign into their commenting system with. Room for improvement for\nsure but at least it doesn't affect the actual commenting sign system sign in.\nOn the plus side, once you do get an account created setup is pretty painless\nand involves pasting some simple javascript into the page that you want to add\ncomments to.\n\n### Sample Code\n\n![](/img/6538431-media_httpfarm5static_keJjk.png)\n\n![](/img/6538432-media_httpfarm3static_EDxfH.png)\n\nHow about the user experience when commenting on a site? This is where I really\nappreciate the power of third party commenting systems, with the value added by\nextra features I didn't have to code. Things like email notifications when\nsomeone replies to a thread, sign in using any of the social networks I'm a part\nof (ID supports Facebook, Twitter, and Open ID at the time of writing),\nautomated threading, profile linking, upvote/downvote, comment history, and\nintegration with popular blogging platforms like wordpress, blogger (hint hint\nPosterous, it would be nice if you added this!).\n\nI was also pleasantly surprised that a\n[tweet](https://twitter.com/dmosher/status/8168838760) about a bug in the email\nnotification system yielded a really fast response from their technical support\nteam. Did I mention it's free?\n\n## JS-Kit Echo\n\n![](/img/6538178-media_httpfarm3static_rBiqF.png)\n\n[www.js-kit.com](https://www.js-kit.com)\n\n[@echoenabled](https://twitter.com/echoenabled)\n\nI haven't used JS-Kit (JSK) on any live blogs but my good buddy [Nathan\nHeagy](https://www.twitter.com/nheagy) let me know of it's existence a few months\nago and I was intrigued to see what it might offer. Some differences from other\nsystems is that JSK allows you to publish comments from a larger variety of\nplaces and broadcast those comments out to more than just the web page the\ncomment thread is embedded on (ie: google friend, yahoo friends and FriendFeed\nin addition to the regular social networks). JS-Kit also has image uploading,\nYouTube video embedding, a basic comment formatting interface and lots more.\nThese features are nice, but I don't think they add as much value and here's the\nkicker: JS-Kit isn't free. They have a 30 day free trial available but after\nthat [pricing](https://js-kit.com/pricing/) starts at \\$12/year but is based on\nthe amount of traffic your site gets.\n\nThe code seems easy enough to understand:\n\n### Sample Code\n\n![](/img/6538433-media_httpfarm5static_huuwm.png)\n\nJS-Kit is ok but Intense Debate being free and providing essentially the same\ncore features without all the \"bells and whistles\" appeals to me much more. YMMV\n;)\n\n## Disqus\n\n![](/img/6538177-media_httpfarm3static_vHgyp.png)\n\n[www.disqus.com](https://www.disqus.com)\n\n[@disqus](https://twitter.com/disqus)\n\nThe veteran in hosted commenting systems, Disqus has been around for a lot\nlonger than either Intense Debate or JS-Kit and it shows. Disqus offers the most\nin terms of supported platforms for connecting to and rebroadcasting to as well\nas the media features that JSK offers (video and image publishing). Setup is\nslightly more involved; if you want to add things like Facebook Connect and\nAkismet (for spam protection) you need to provide API keys. Again the code is\nvery easy to inject into any page, static or dynamic.\n\n### Sample Code\n\n![](/img/6538434-media_httpfarm5static_jiFnk.png)\n\nDisqus also gives you the power to control the look and feel of the commenting\ninterface right inside their control panel. This is a pretty nice feature for\npeople who aren't so technical that they want to hack away at the CSS manually.\nThe fact that right out of the gate Disqus is free and offers just as much power\nas JS-Kit and Intense Debate makes it a pretty attractive option.\n\n## Conclusion\n\nThese are just a few of the options out there if you want to implement a\ncommenting system and don't want to write it yourself. I hope you learned\nsomething reading this (I sure did writing it). I made sure to research all the\nfacts as best I could before writing but in case I missed anything please feel\nfree to let me know in the .... commenting system Posterous has built in :]\n"
  },
  "attributes": {
    "title": "Third-Party Comment System Roundup",
    "date": "2010-02-12"
  },
  "markdown": "\n> We've all seen it. The classic tutorial on [insert popular web framework here]\nthat has us building a blogging system in twenty minutes or less. It's actually\ngetting kind of old and I'm growing sick of seeing what I'm able to create with\nonly platform x,y and z. I'm more interested in how I can use a web framework\nthat doesn't hold my hand by providing a bunch of \"one size fits all\" defaults.\nI like flexibility and choice.\n\nI like it when the web framework I'm using allows\nme to mix and match third party systems easily. One third party web framework\ncomponent that is becoming more popular is commenting systems. Let's take a\nbrief look at three of the most popular systems to see what each offers us.\n\n## Intense Debate\n\n![](/img/6538176-media_httpfarm3static_zwrDw.png)\n\n[www.intensedebate.com](https://www.intensedebate.com)\n\n[@photomatt](https://twitter.com/photomatt)\n\nI first experienced using intense debate when reading a couple blog posts on\nJohn W. Longs [wise heart design](https://www.wiseheartdesign.com). Created by\n[automattic](https://twitter.com/automattic) of wordpress fame, Intense Debate\n(ID) is a hosted commenting system that utilizes some sexy javascript and social\nnetwork integration to allow you to add comments to pretty much any page on the\nInternet. My experience with the sign up process for intense debate was actually\npretty frustrating as the log in system didn't seem to recognize my OpenID and\nyou can't create an account for the purposes of installation with anything\nexcept OpenID or their hand rolled registration.\n\nI was expecting to be able to sign up using any of the social networks they\nallow you to sign into their commenting system with. Room for improvement for\nsure but at least it doesn't affect the actual commenting sign system sign in.\nOn the plus side, once you do get an account created setup is pretty painless\nand involves pasting some simple javascript into the page that you want to add\ncomments to.\n\n### Sample Code\n\n![](/img/6538431-media_httpfarm5static_keJjk.png)\n\n![](/img/6538432-media_httpfarm3static_EDxfH.png)\n\nHow about the user experience when commenting on a site? This is where I really\nappreciate the power of third party commenting systems, with the value added by\nextra features I didn't have to code. Things like email notifications when\nsomeone replies to a thread, sign in using any of the social networks I'm a part\nof (ID supports Facebook, Twitter, and Open ID at the time of writing),\nautomated threading, profile linking, upvote/downvote, comment history, and\nintegration with popular blogging platforms like wordpress, blogger (hint hint\nPosterous, it would be nice if you added this!).\n\nI was also pleasantly surprised that a\n[tweet](https://twitter.com/dmosher/status/8168838760) about a bug in the email\nnotification system yielded a really fast response from their technical support\nteam. Did I mention it's free?\n\n## JS-Kit Echo\n\n![](/img/6538178-media_httpfarm3static_rBiqF.png)\n\n[www.js-kit.com](https://www.js-kit.com)\n\n[@echoenabled](https://twitter.com/echoenabled)\n\nI haven't used JS-Kit (JSK) on any live blogs but my good buddy [Nathan\nHeagy](https://www.twitter.com/nheagy) let me know of it's existence a few months\nago and I was intrigued to see what it might offer. Some differences from other\nsystems is that JSK allows you to publish comments from a larger variety of\nplaces and broadcast those comments out to more than just the web page the\ncomment thread is embedded on (ie: google friend, yahoo friends and FriendFeed\nin addition to the regular social networks). JS-Kit also has image uploading,\nYouTube video embedding, a basic comment formatting interface and lots more.\nThese features are nice, but I don't think they add as much value and here's the\nkicker: JS-Kit isn't free. They have a 30 day free trial available but after\nthat [pricing](https://js-kit.com/pricing/) starts at \\$12/year but is based on\nthe amount of traffic your site gets.\n\nThe code seems easy enough to understand:\n\n### Sample Code\n\n![](/img/6538433-media_httpfarm5static_huuwm.png)\n\nJS-Kit is ok but Intense Debate being free and providing essentially the same\ncore features without all the \"bells and whistles\" appeals to me much more. YMMV\n;)\n\n## Disqus\n\n![](/img/6538177-media_httpfarm3static_vHgyp.png)\n\n[www.disqus.com](https://www.disqus.com)\n\n[@disqus](https://twitter.com/disqus)\n\nThe veteran in hosted commenting systems, Disqus has been around for a lot\nlonger than either Intense Debate or JS-Kit and it shows. Disqus offers the most\nin terms of supported platforms for connecting to and rebroadcasting to as well\nas the media features that JSK offers (video and image publishing). Setup is\nslightly more involved; if you want to add things like Facebook Connect and\nAkismet (for spam protection) you need to provide API keys. Again the code is\nvery easy to inject into any page, static or dynamic.\n\n### Sample Code\n\n![](/img/6538434-media_httpfarm5static_jiFnk.png)\n\nDisqus also gives you the power to control the look and feel of the commenting\ninterface right inside their control panel. This is a pretty nice feature for\npeople who aren't so technical that they want to hack away at the CSS manually.\nThe fact that right out of the gate Disqus is free and offers just as much power\nas JS-Kit and Intense Debate makes it a pretty attractive option.\n\n## Conclusion\n\nThese are just a few of the options out there if you want to implement a\ncommenting system and don't want to write it yourself. I hope you learned\nsomething reading this (I sure did writing it). I made sure to research all the\nfacts as best I could before writing but in case I missed anything please feel\nfree to let me know in the .... commenting system Posterous has built in :]\n"
}></{
  "path": "app/posts/2010-02-12-3rd-party-comment-system-roundup.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Third-Party Comment System Roundup",
      "date": "2010-02-12"
    },
    "source": "\n> We've all seen it. The classic tutorial on [insert popular web framework here]\nthat has us building a blogging system in twenty minutes or less. It's actually\ngetting kind of old and I'm growing sick of seeing what I'm able to create with\nonly platform x,y and z. I'm more interested in how I can use a web framework\nthat doesn't hold my hand by providing a bunch of \"one size fits all\" defaults.\nI like flexibility and choice.\n\nI like it when the web framework I'm using allows\nme to mix and match third party systems easily. One third party web framework\ncomponent that is becoming more popular is commenting systems. Let's take a\nbrief look at three of the most popular systems to see what each offers us.\n\n## Intense Debate\n\n![](/img/6538176-media_httpfarm3static_zwrDw.png)\n\n[www.intensedebate.com](https://www.intensedebate.com)\n\n[@photomatt](https://twitter.com/photomatt)\n\nI first experienced using intense debate when reading a couple blog posts on\nJohn W. Longs [wise heart design](https://www.wiseheartdesign.com). Created by\n[automattic](https://twitter.com/automattic) of wordpress fame, Intense Debate\n(ID) is a hosted commenting system that utilizes some sexy javascript and social\nnetwork integration to allow you to add comments to pretty much any page on the\nInternet. My experience with the sign up process for intense debate was actually\npretty frustrating as the log in system didn't seem to recognize my OpenID and\nyou can't create an account for the purposes of installation with anything\nexcept OpenID or their hand rolled registration.\n\nI was expecting to be able to sign up using any of the social networks they\nallow you to sign into their commenting system with. Room for improvement for\nsure but at least it doesn't affect the actual commenting sign system sign in.\nOn the plus side, once you do get an account created setup is pretty painless\nand involves pasting some simple javascript into the page that you want to add\ncomments to.\n\n### Sample Code\n\n![](/img/6538431-media_httpfarm5static_keJjk.png)\n\n![](/img/6538432-media_httpfarm3static_EDxfH.png)\n\nHow about the user experience when commenting on a site? This is where I really\nappreciate the power of third party commenting systems, with the value added by\nextra features I didn't have to code. Things like email notifications when\nsomeone replies to a thread, sign in using any of the social networks I'm a part\nof (ID supports Facebook, Twitter, and Open ID at the time of writing),\nautomated threading, profile linking, upvote/downvote, comment history, and\nintegration with popular blogging platforms like wordpress, blogger (hint hint\nPosterous, it would be nice if you added this!).\n\nI was also pleasantly surprised that a\n[tweet](https://twitter.com/dmosher/status/8168838760) about a bug in the email\nnotification system yielded a really fast response from their technical support\nteam. Did I mention it's free?\n\n## JS-Kit Echo\n\n![](/img/6538178-media_httpfarm3static_rBiqF.png)\n\n[www.js-kit.com](https://www.js-kit.com)\n\n[@echoenabled](https://twitter.com/echoenabled)\n\nI haven't used JS-Kit (JSK) on any live blogs but my good buddy [Nathan\nHeagy](https://www.twitter.com/nheagy) let me know of it's existence a few months\nago and I was intrigued to see what it might offer. Some differences from other\nsystems is that JSK allows you to publish comments from a larger variety of\nplaces and broadcast those comments out to more than just the web page the\ncomment thread is embedded on (ie: google friend, yahoo friends and FriendFeed\nin addition to the regular social networks). JS-Kit also has image uploading,\nYouTube video embedding, a basic comment formatting interface and lots more.\nThese features are nice, but I don't think they add as much value and here's the\nkicker: JS-Kit isn't free. They have a 30 day free trial available but after\nthat [pricing](https://js-kit.com/pricing/) starts at \\$12/year but is based on\nthe amount of traffic your site gets.\n\nThe code seems easy enough to understand:\n\n### Sample Code\n\n![](/img/6538433-media_httpfarm5static_huuwm.png)\n\nJS-Kit is ok but Intense Debate being free and providing essentially the same\ncore features without all the \"bells and whistles\" appeals to me much more. YMMV\n;)\n\n## Disqus\n\n![](/img/6538177-media_httpfarm3static_vHgyp.png)\n\n[www.disqus.com](https://www.disqus.com)\n\n[@disqus](https://twitter.com/disqus)\n\nThe veteran in hosted commenting systems, Disqus has been around for a lot\nlonger than either Intense Debate or JS-Kit and it shows. Disqus offers the most\nin terms of supported platforms for connecting to and rebroadcasting to as well\nas the media features that JSK offers (video and image publishing). Setup is\nslightly more involved; if you want to add things like Facebook Connect and\nAkismet (for spam protection) you need to provide API keys. Again the code is\nvery easy to inject into any page, static or dynamic.\n\n### Sample Code\n\n![](/img/6538434-media_httpfarm5static_jiFnk.png)\n\nDisqus also gives you the power to control the look and feel of the commenting\ninterface right inside their control panel. This is a pretty nice feature for\npeople who aren't so technical that they want to hack away at the CSS manually.\nThe fact that right out of the gate Disqus is free and offers just as much power\nas JS-Kit and Intense Debate makes it a pretty attractive option.\n\n## Conclusion\n\nThese are just a few of the options out there if you want to implement a\ncommenting system and don't want to write it yourself. I hope you learned\nsomething reading this (I sure did writing it). I made sure to research all the\nfacts as best I could before writing but in case I missed anything please feel\nfree to let me know in the .... commenting system Posterous has built in :]\n"
  },
  "attributes": {
    "title": "Third-Party Comment System Roundup",
    "date": "2010-02-12"
  },
  "markdown": "\n> We've all seen it. The classic tutorial on [insert popular web framework here]\nthat has us building a blogging system in twenty minutes or less. It's actually\ngetting kind of old and I'm growing sick of seeing what I'm able to create with\nonly platform x,y and z. I'm more interested in how I can use a web framework\nthat doesn't hold my hand by providing a bunch of \"one size fits all\" defaults.\nI like flexibility and choice.\n\nI like it when the web framework I'm using allows\nme to mix and match third party systems easily. One third party web framework\ncomponent that is becoming more popular is commenting systems. Let's take a\nbrief look at three of the most popular systems to see what each offers us.\n\n## Intense Debate\n\n![](/img/6538176-media_httpfarm3static_zwrDw.png)\n\n[www.intensedebate.com](https://www.intensedebate.com)\n\n[@photomatt](https://twitter.com/photomatt)\n\nI first experienced using intense debate when reading a couple blog posts on\nJohn W. Longs [wise heart design](https://www.wiseheartdesign.com). Created by\n[automattic](https://twitter.com/automattic) of wordpress fame, Intense Debate\n(ID) is a hosted commenting system that utilizes some sexy javascript and social\nnetwork integration to allow you to add comments to pretty much any page on the\nInternet. My experience with the sign up process for intense debate was actually\npretty frustrating as the log in system didn't seem to recognize my OpenID and\nyou can't create an account for the purposes of installation with anything\nexcept OpenID or their hand rolled registration.\n\nI was expecting to be able to sign up using any of the social networks they\nallow you to sign into their commenting system with. Room for improvement for\nsure but at least it doesn't affect the actual commenting sign system sign in.\nOn the plus side, once you do get an account created setup is pretty painless\nand involves pasting some simple javascript into the page that you want to add\ncomments to.\n\n### Sample Code\n\n![](/img/6538431-media_httpfarm5static_keJjk.png)\n\n![](/img/6538432-media_httpfarm3static_EDxfH.png)\n\nHow about the user experience when commenting on a site? This is where I really\nappreciate the power of third party commenting systems, with the value added by\nextra features I didn't have to code. Things like email notifications when\nsomeone replies to a thread, sign in using any of the social networks I'm a part\nof (ID supports Facebook, Twitter, and Open ID at the time of writing),\nautomated threading, profile linking, upvote/downvote, comment history, and\nintegration with popular blogging platforms like wordpress, blogger (hint hint\nPosterous, it would be nice if you added this!).\n\nI was also pleasantly surprised that a\n[tweet](https://twitter.com/dmosher/status/8168838760) about a bug in the email\nnotification system yielded a really fast response from their technical support\nteam. Did I mention it's free?\n\n## JS-Kit Echo\n\n![](/img/6538178-media_httpfarm3static_rBiqF.png)\n\n[www.js-kit.com](https://www.js-kit.com)\n\n[@echoenabled](https://twitter.com/echoenabled)\n\nI haven't used JS-Kit (JSK) on any live blogs but my good buddy [Nathan\nHeagy](https://www.twitter.com/nheagy) let me know of it's existence a few months\nago and I was intrigued to see what it might offer. Some differences from other\nsystems is that JSK allows you to publish comments from a larger variety of\nplaces and broadcast those comments out to more than just the web page the\ncomment thread is embedded on (ie: google friend, yahoo friends and FriendFeed\nin addition to the regular social networks). JS-Kit also has image uploading,\nYouTube video embedding, a basic comment formatting interface and lots more.\nThese features are nice, but I don't think they add as much value and here's the\nkicker: JS-Kit isn't free. They have a 30 day free trial available but after\nthat [pricing](https://js-kit.com/pricing/) starts at \\$12/year but is based on\nthe amount of traffic your site gets.\n\nThe code seems easy enough to understand:\n\n### Sample Code\n\n![](/img/6538433-media_httpfarm5static_huuwm.png)\n\nJS-Kit is ok but Intense Debate being free and providing essentially the same\ncore features without all the \"bells and whistles\" appeals to me much more. YMMV\n;)\n\n## Disqus\n\n![](/img/6538177-media_httpfarm3static_vHgyp.png)\n\n[www.disqus.com](https://www.disqus.com)\n\n[@disqus](https://twitter.com/disqus)\n\nThe veteran in hosted commenting systems, Disqus has been around for a lot\nlonger than either Intense Debate or JS-Kit and it shows. Disqus offers the most\nin terms of supported platforms for connecting to and rebroadcasting to as well\nas the media features that JSK offers (video and image publishing). Setup is\nslightly more involved; if you want to add things like Facebook Connect and\nAkismet (for spam protection) you need to provide API keys. Again the code is\nvery easy to inject into any page, static or dynamic.\n\n### Sample Code\n\n![](/img/6538434-media_httpfarm5static_jiFnk.png)\n\nDisqus also gives you the power to control the look and feel of the commenting\ninterface right inside their control panel. This is a pretty nice feature for\npeople who aren't so technical that they want to hack away at the CSS manually.\nThe fact that right out of the gate Disqus is free and offers just as much power\nas JS-Kit and Intense Debate makes it a pretty attractive option.\n\n## Conclusion\n\nThese are just a few of the options out there if you want to implement a\ncommenting system and don't want to write it yourself. I hope you learned\nsomething reading this (I sure did writing it). I made sure to research all the\nfacts as best I could before writing but in case I missed anything please feel\nfree to let me know in the .... commenting system Posterous has built in :]\n"
}></pre></div><div><a href="/posts/2010-01-12-3-characteristics-of-good-programmers.html">3 Characteristics of Good Programmers</a><pre><{
  "path": "app/posts/2010-01-12-3-characteristics-of-good-programmers.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "3 Characteristics of Good Programmers",
      "date": "2010-01-12"
    },
    "source": "\n> A wise man once told me that the best way to get ahead in life is to learn\nlessons from the experiences and failures of others. That man was my dad. He\ndidn't share often with me when I was growing up but when he did I listened\ncarefully (for the most part..) because what he had to say carried the weight\nand experience of someone who had experienced far more in life than I had.\nProgramming is a lot like learning this way.\n\nThere are people and companies who have tried and failed, sometimes miserably, at coming up with solutions to problems. When compared to other disciplines, I suspect there are more failures in programming than there are successes. This puts us in a unique position as developers because it offers us a distinct advantage over other industries; we have more examples of what not to do ... if we choose to seek them out.\n\n## Passion\n\nI love programming. It's the only job I've had where I feel energized by solving\nproblems. Sometimes my solutions suck but I think that's ok because I'm willing\nto admit it and strive to improve wherever possible. This is what I believe\nconstitutes passion as a programmer. Passion is different than zealotry. A\npassionate programmer seeks out solutions using the best tools and technologies\nhe knows at the time with the willingness to admit that any solution at any\ngiven time is never perfect; it's merely the best at that moment in time.\nZealots spend their time evangelizing solutions based on hype or buzz.\n\nPassionate programmers use logic, prototypes and test cases to prove that what\nthey think works will work. Zealots are always working hard to implement \"the\nnext big thing\" in the hopes of scoring a knockout; they're like the blackjack\nplayer who constantly changes up his strategy in an attempt to influence the\noutcome of the game. Passionate programmers realize that perfection is\nunattainable but they still strive to attain it with care.\n\n## Perfection\n\nIt's been said before, \"if we could only use solution [x] problem [y] would go\naway completely\", \"things will be all better if we just do this\", \"this is\nexactly what we need, let's implement it now!\" I know that these things get said\nbecause I used to say them (and probably still do from time to time; stop me if\nyou hear me). The problem with these \"silver bullet\" solutions is that they\ndon't exist. The \"one size fits all\" mentality is the sign of an immature\ndeveloper. Perfection is dangerous, however the pursuit of perfection can be an\nincredible motivator if it is tempered with pragmatism. Knowing when to\nimplement a solution that is good enough for the task at hand avoids unnecessary\nrefactoring and saves time.\n\nAsk your business analyst or company owner what they think about perfection and\nthe response will likely include the word \"risk\". Far too often the technical is\nall we think about. Our job as passionate programmers is to communicate early\nand often with our business owners to understand the business goals of any\npotential solution. By considering business goals we mitigate against the risk\nof building only the perfect technical solution.\n\n## Perseverance\n\nI'm not an english major but I think that Shakespeare has some good things to\nsay about perseverance.\n\n> \"To be, or not to be: that is the question:\n> Whether 'tis nobler in the mind to suffer\n> The slings and arrows of outrageous fortune,\n> Or to take arms against a sea of troubles,\n> And by opposing end them?\"\n> -- *Hamlet*\n\nThe answer to the question has to be: to be! Giving up is not an option!\nPassionate programmers arm themselves with all of the tools and knowledge they\nhave in order to face problems. They also surround themselves with like minded\npeople and thrive on failure. Failure affords us the chance to persevere and\nrefine our process until we reach a solution that is \"good enough\".\n\n> \"And thus the native hue of resolution\n> Is sicklied o'er with the pale cast of thought,\n> And enterprises of great pith and moment\n> With this regard their currents turn awry,\n> And lose the name of action.\"\n> -- *Hamlet*\n\nHave you resolved in the past to persevere through difficult problems as a\nprogrammer only to find that you get trapped in over thinking how you're going\nto solve them? Startups with great ideas fail so often because of this.\nPassionate programmers are persistent in identifying this shift in focus that\nleads to a cyclical pursuit of perfection which steer's companies off course.\n\nWhat type of programmer are you? *that* is the question.\n"
  },
  "attributes": {
    "title": "3 Characteristics of Good Programmers",
    "date": "2010-01-12"
  },
  "markdown": "\n> A wise man once told me that the best way to get ahead in life is to learn\nlessons from the experiences and failures of others. That man was my dad. He\ndidn't share often with me when I was growing up but when he did I listened\ncarefully (for the most part..) because what he had to say carried the weight\nand experience of someone who had experienced far more in life than I had.\nProgramming is a lot like learning this way.\n\nThere are people and companies who have tried and failed, sometimes miserably, at coming up with solutions to problems. When compared to other disciplines, I suspect there are more failures in programming than there are successes. This puts us in a unique position as developers because it offers us a distinct advantage over other industries; we have more examples of what not to do ... if we choose to seek them out.\n\n## Passion\n\nI love programming. It's the only job I've had where I feel energized by solving\nproblems. Sometimes my solutions suck but I think that's ok because I'm willing\nto admit it and strive to improve wherever possible. This is what I believe\nconstitutes passion as a programmer. Passion is different than zealotry. A\npassionate programmer seeks out solutions using the best tools and technologies\nhe knows at the time with the willingness to admit that any solution at any\ngiven time is never perfect; it's merely the best at that moment in time.\nZealots spend their time evangelizing solutions based on hype or buzz.\n\nPassionate programmers use logic, prototypes and test cases to prove that what\nthey think works will work. Zealots are always working hard to implement \"the\nnext big thing\" in the hopes of scoring a knockout; they're like the blackjack\nplayer who constantly changes up his strategy in an attempt to influence the\noutcome of the game. Passionate programmers realize that perfection is\nunattainable but they still strive to attain it with care.\n\n## Perfection\n\nIt's been said before, \"if we could only use solution [x] problem [y] would go\naway completely\", \"things will be all better if we just do this\", \"this is\nexactly what we need, let's implement it now!\" I know that these things get said\nbecause I used to say them (and probably still do from time to time; stop me if\nyou hear me). The problem with these \"silver bullet\" solutions is that they\ndon't exist. The \"one size fits all\" mentality is the sign of an immature\ndeveloper. Perfection is dangerous, however the pursuit of perfection can be an\nincredible motivator if it is tempered with pragmatism. Knowing when to\nimplement a solution that is good enough for the task at hand avoids unnecessary\nrefactoring and saves time.\n\nAsk your business analyst or company owner what they think about perfection and\nthe response will likely include the word \"risk\". Far too often the technical is\nall we think about. Our job as passionate programmers is to communicate early\nand often with our business owners to understand the business goals of any\npotential solution. By considering business goals we mitigate against the risk\nof building only the perfect technical solution.\n\n## Perseverance\n\nI'm not an english major but I think that Shakespeare has some good things to\nsay about perseverance.\n\n> \"To be, or not to be: that is the question:\n> Whether 'tis nobler in the mind to suffer\n> The slings and arrows of outrageous fortune,\n> Or to take arms against a sea of troubles,\n> And by opposing end them?\"\n> -- *Hamlet*\n\nThe answer to the question has to be: to be! Giving up is not an option!\nPassionate programmers arm themselves with all of the tools and knowledge they\nhave in order to face problems. They also surround themselves with like minded\npeople and thrive on failure. Failure affords us the chance to persevere and\nrefine our process until we reach a solution that is \"good enough\".\n\n> \"And thus the native hue of resolution\n> Is sicklied o'er with the pale cast of thought,\n> And enterprises of great pith and moment\n> With this regard their currents turn awry,\n> And lose the name of action.\"\n> -- *Hamlet*\n\nHave you resolved in the past to persevere through difficult problems as a\nprogrammer only to find that you get trapped in over thinking how you're going\nto solve them? Startups with great ideas fail so often because of this.\nPassionate programmers are persistent in identifying this shift in focus that\nleads to a cyclical pursuit of perfection which steer's companies off course.\n\nWhat type of programmer are you? *that* is the question.\n"
}></{
  "path": "app/posts/2010-01-12-3-characteristics-of-good-programmers.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "3 Characteristics of Good Programmers",
      "date": "2010-01-12"
    },
    "source": "\n> A wise man once told me that the best way to get ahead in life is to learn\nlessons from the experiences and failures of others. That man was my dad. He\ndidn't share often with me when I was growing up but when he did I listened\ncarefully (for the most part..) because what he had to say carried the weight\nand experience of someone who had experienced far more in life than I had.\nProgramming is a lot like learning this way.\n\nThere are people and companies who have tried and failed, sometimes miserably, at coming up with solutions to problems. When compared to other disciplines, I suspect there are more failures in programming than there are successes. This puts us in a unique position as developers because it offers us a distinct advantage over other industries; we have more examples of what not to do ... if we choose to seek them out.\n\n## Passion\n\nI love programming. It's the only job I've had where I feel energized by solving\nproblems. Sometimes my solutions suck but I think that's ok because I'm willing\nto admit it and strive to improve wherever possible. This is what I believe\nconstitutes passion as a programmer. Passion is different than zealotry. A\npassionate programmer seeks out solutions using the best tools and technologies\nhe knows at the time with the willingness to admit that any solution at any\ngiven time is never perfect; it's merely the best at that moment in time.\nZealots spend their time evangelizing solutions based on hype or buzz.\n\nPassionate programmers use logic, prototypes and test cases to prove that what\nthey think works will work. Zealots are always working hard to implement \"the\nnext big thing\" in the hopes of scoring a knockout; they're like the blackjack\nplayer who constantly changes up his strategy in an attempt to influence the\noutcome of the game. Passionate programmers realize that perfection is\nunattainable but they still strive to attain it with care.\n\n## Perfection\n\nIt's been said before, \"if we could only use solution [x] problem [y] would go\naway completely\", \"things will be all better if we just do this\", \"this is\nexactly what we need, let's implement it now!\" I know that these things get said\nbecause I used to say them (and probably still do from time to time; stop me if\nyou hear me). The problem with these \"silver bullet\" solutions is that they\ndon't exist. The \"one size fits all\" mentality is the sign of an immature\ndeveloper. Perfection is dangerous, however the pursuit of perfection can be an\nincredible motivator if it is tempered with pragmatism. Knowing when to\nimplement a solution that is good enough for the task at hand avoids unnecessary\nrefactoring and saves time.\n\nAsk your business analyst or company owner what they think about perfection and\nthe response will likely include the word \"risk\". Far too often the technical is\nall we think about. Our job as passionate programmers is to communicate early\nand often with our business owners to understand the business goals of any\npotential solution. By considering business goals we mitigate against the risk\nof building only the perfect technical solution.\n\n## Perseverance\n\nI'm not an english major but I think that Shakespeare has some good things to\nsay about perseverance.\n\n> \"To be, or not to be: that is the question:\n> Whether 'tis nobler in the mind to suffer\n> The slings and arrows of outrageous fortune,\n> Or to take arms against a sea of troubles,\n> And by opposing end them?\"\n> -- *Hamlet*\n\nThe answer to the question has to be: to be! Giving up is not an option!\nPassionate programmers arm themselves with all of the tools and knowledge they\nhave in order to face problems. They also surround themselves with like minded\npeople and thrive on failure. Failure affords us the chance to persevere and\nrefine our process until we reach a solution that is \"good enough\".\n\n> \"And thus the native hue of resolution\n> Is sicklied o'er with the pale cast of thought,\n> And enterprises of great pith and moment\n> With this regard their currents turn awry,\n> And lose the name of action.\"\n> -- *Hamlet*\n\nHave you resolved in the past to persevere through difficult problems as a\nprogrammer only to find that you get trapped in over thinking how you're going\nto solve them? Startups with great ideas fail so often because of this.\nPassionate programmers are persistent in identifying this shift in focus that\nleads to a cyclical pursuit of perfection which steer's companies off course.\n\nWhat type of programmer are you? *that* is the question.\n"
  },
  "attributes": {
    "title": "3 Characteristics of Good Programmers",
    "date": "2010-01-12"
  },
  "markdown": "\n> A wise man once told me that the best way to get ahead in life is to learn\nlessons from the experiences and failures of others. That man was my dad. He\ndidn't share often with me when I was growing up but when he did I listened\ncarefully (for the most part..) because what he had to say carried the weight\nand experience of someone who had experienced far more in life than I had.\nProgramming is a lot like learning this way.\n\nThere are people and companies who have tried and failed, sometimes miserably, at coming up with solutions to problems. When compared to other disciplines, I suspect there are more failures in programming than there are successes. This puts us in a unique position as developers because it offers us a distinct advantage over other industries; we have more examples of what not to do ... if we choose to seek them out.\n\n## Passion\n\nI love programming. It's the only job I've had where I feel energized by solving\nproblems. Sometimes my solutions suck but I think that's ok because I'm willing\nto admit it and strive to improve wherever possible. This is what I believe\nconstitutes passion as a programmer. Passion is different than zealotry. A\npassionate programmer seeks out solutions using the best tools and technologies\nhe knows at the time with the willingness to admit that any solution at any\ngiven time is never perfect; it's merely the best at that moment in time.\nZealots spend their time evangelizing solutions based on hype or buzz.\n\nPassionate programmers use logic, prototypes and test cases to prove that what\nthey think works will work. Zealots are always working hard to implement \"the\nnext big thing\" in the hopes of scoring a knockout; they're like the blackjack\nplayer who constantly changes up his strategy in an attempt to influence the\noutcome of the game. Passionate programmers realize that perfection is\nunattainable but they still strive to attain it with care.\n\n## Perfection\n\nIt's been said before, \"if we could only use solution [x] problem [y] would go\naway completely\", \"things will be all better if we just do this\", \"this is\nexactly what we need, let's implement it now!\" I know that these things get said\nbecause I used to say them (and probably still do from time to time; stop me if\nyou hear me). The problem with these \"silver bullet\" solutions is that they\ndon't exist. The \"one size fits all\" mentality is the sign of an immature\ndeveloper. Perfection is dangerous, however the pursuit of perfection can be an\nincredible motivator if it is tempered with pragmatism. Knowing when to\nimplement a solution that is good enough for the task at hand avoids unnecessary\nrefactoring and saves time.\n\nAsk your business analyst or company owner what they think about perfection and\nthe response will likely include the word \"risk\". Far too often the technical is\nall we think about. Our job as passionate programmers is to communicate early\nand often with our business owners to understand the business goals of any\npotential solution. By considering business goals we mitigate against the risk\nof building only the perfect technical solution.\n\n## Perseverance\n\nI'm not an english major but I think that Shakespeare has some good things to\nsay about perseverance.\n\n> \"To be, or not to be: that is the question:\n> Whether 'tis nobler in the mind to suffer\n> The slings and arrows of outrageous fortune,\n> Or to take arms against a sea of troubles,\n> And by opposing end them?\"\n> -- *Hamlet*\n\nThe answer to the question has to be: to be! Giving up is not an option!\nPassionate programmers arm themselves with all of the tools and knowledge they\nhave in order to face problems. They also surround themselves with like minded\npeople and thrive on failure. Failure affords us the chance to persevere and\nrefine our process until we reach a solution that is \"good enough\".\n\n> \"And thus the native hue of resolution\n> Is sicklied o'er with the pale cast of thought,\n> And enterprises of great pith and moment\n> With this regard their currents turn awry,\n> And lose the name of action.\"\n> -- *Hamlet*\n\nHave you resolved in the past to persevere through difficult problems as a\nprogrammer only to find that you get trapped in over thinking how you're going\nto solve them? Startups with great ideas fail so often because of this.\nPassionate programmers are persistent in identifying this shift in focus that\nleads to a cyclical pursuit of perfection which steer's companies off course.\n\nWhat type of programmer are you? *that* is the question.\n"
}></pre></div><div><a href="/posts/2009-11-28-3-things-i-learned-at-barcamp-saskatoon-2009.html">3 things I learned at BarCamp Saskatoon 2009</a><pre><{
  "path": "app/posts/2009-11-28-3-things-i-learned-at-barcamp-saskatoon-2009.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "3 things I learned at BarCamp Saskatoon 2009",
      "date": "2009-11-28"
    },
    "source": "\n> I attended Bar Camp Saskatoon today and while I wasn't able to stay for the\nentire series of presentations what I did manage to see was great. I presented\non [SASS](https://www.sass-lang.com), [Compass](https://www.compass-style.org) and\nCSS Frameworks. My presentation didn't go exactly as I'd planned but I learned\nthings from that experience and from other peoples presentations.\n\n## 1. Your presentation doesn't have to be long to be effective.\n\n[Nate Heagy's](https://twitter.com/nheagy) presentation on JavaScript was\nperfect, IMHO. It was about 15 minutes of airtime that offered about another 10\nto 15 minutes of discussion. The time slot allotment is just about an hour\n(including time for questions) but I felt like given the open format of Bar Camp\nless talk and more group discussion works really well. Also, kudos to Nate for\nimbuing his presentation with a healthy dose of humour in addition to the\nexcellent information. **Engaging++**\n\n## 2. If you do live coding, be uber prepared for failure ... and recover\ngracefully if possible.\n\nAfter last years presentation on using Yahoo Pipes for one of our corporate\nwebsite projects I thought it might be nice to do some actual live coding for a\nbar camp presentation. Admittedly I had no idea how this would go over given the\nskill level of attendees, technical capabilities of the presentation\nenvironment, scope of my presentation and a whole bunch of other variables I\nhummed and haah'd over. My goal was to take a web page design from zilch to\ncompletion using the techniques I'd learned in with SASS and Compass while\nproviding some tips / insight into tricks I've integrated into my development\nprocess along the way. It turned out to be more of a brief feature demonstration\nof SASS, some extended use of Firebug as an inspection tool, and some examples\nof what I feel is wrong with the way CSS frameworks are used these days. I think\nI could have condensed it to be shorter with less live coding and focused on the\nidea I opened with, that CSS Frameworks go against the very nature of what CSS\nwas provided to do, but SASS and Compass fix this by allowing you to continue to\nuse the frameworks without presentational class names.\n\nI made a few flubs and things didn't work out exactly how I thought, but the\nexperience of presenting in front of a large group of people is very valuable\nand the more I do it the more I learn what works and what doesn't. (If you're\ninterested in the very disorganized collection of assets I produced for the talk\nthey are available [here](https://bit.ly/6PsWqr)). If I could retool it I think\nI'd go back and stick to my script more (I generated a series of notes that I\nkind of \"forgot\" to use during the presentation -- nerves and all that),\ncondense it significantly and offer more time for discussion.\n\n## 3. Saskatoon has a vibrant, growing tech-community. This is awesome.\n\nI've lived in Saskatoon since 1999. In the 10 years I've been here I have to say\nI don't think I've ever been as excited about living somewhere as I am right now\n(and I've lived coast to coast, north to south within Canada). There are so many\npeople here with similar interests and it's great to see technology enthusiasts\nout at these events. It promotes the development of Saskatoon as even more of a\nwestern tech-mecca than people already perceive. It's great that people like\n[Ginger Koolick](https://twitter.com/gingerk) and [Ryan\nLejbak](https://twitter.com/ryanlejbak) have taken the initiative to develop this\nsort of community (and my apologies if I missed your name and you were a key\npart of the involvement of Bar Camp Saskatoon) and companies like\n[zu](https://www.zu.com), [Point2](https://www.point2.com), [YasTech](https://www.yastech.ca)\n(and more) are willing to spend time and effort sponsoring the events. (Wanted:\n[VendAsta](https://www.vendasta.com) as a sponsor for next year!)\n\nI'm stoked to connect more with people in the tech-community within Saskatoon\nand continue to learn from interesting people. **Can't wait until Bar Camp\nSaskatoon 2010 :D**\n\n"
  },
  "attributes": {
    "title": "3 things I learned at BarCamp Saskatoon 2009",
    "date": "2009-11-28"
  },
  "markdown": "\n> I attended Bar Camp Saskatoon today and while I wasn't able to stay for the\nentire series of presentations what I did manage to see was great. I presented\non [SASS](https://www.sass-lang.com), [Compass](https://www.compass-style.org) and\nCSS Frameworks. My presentation didn't go exactly as I'd planned but I learned\nthings from that experience and from other peoples presentations.\n\n## 1. Your presentation doesn't have to be long to be effective.\n\n[Nate Heagy's](https://twitter.com/nheagy) presentation on JavaScript was\nperfect, IMHO. It was about 15 minutes of airtime that offered about another 10\nto 15 minutes of discussion. The time slot allotment is just about an hour\n(including time for questions) but I felt like given the open format of Bar Camp\nless talk and more group discussion works really well. Also, kudos to Nate for\nimbuing his presentation with a healthy dose of humour in addition to the\nexcellent information. **Engaging++**\n\n## 2. If you do live coding, be uber prepared for failure ... and recover\ngracefully if possible.\n\nAfter last years presentation on using Yahoo Pipes for one of our corporate\nwebsite projects I thought it might be nice to do some actual live coding for a\nbar camp presentation. Admittedly I had no idea how this would go over given the\nskill level of attendees, technical capabilities of the presentation\nenvironment, scope of my presentation and a whole bunch of other variables I\nhummed and haah'd over. My goal was to take a web page design from zilch to\ncompletion using the techniques I'd learned in with SASS and Compass while\nproviding some tips / insight into tricks I've integrated into my development\nprocess along the way. It turned out to be more of a brief feature demonstration\nof SASS, some extended use of Firebug as an inspection tool, and some examples\nof what I feel is wrong with the way CSS frameworks are used these days. I think\nI could have condensed it to be shorter with less live coding and focused on the\nidea I opened with, that CSS Frameworks go against the very nature of what CSS\nwas provided to do, but SASS and Compass fix this by allowing you to continue to\nuse the frameworks without presentational class names.\n\nI made a few flubs and things didn't work out exactly how I thought, but the\nexperience of presenting in front of a large group of people is very valuable\nand the more I do it the more I learn what works and what doesn't. (If you're\ninterested in the very disorganized collection of assets I produced for the talk\nthey are available [here](https://bit.ly/6PsWqr)). If I could retool it I think\nI'd go back and stick to my script more (I generated a series of notes that I\nkind of \"forgot\" to use during the presentation -- nerves and all that),\ncondense it significantly and offer more time for discussion.\n\n## 3. Saskatoon has a vibrant, growing tech-community. This is awesome.\n\nI've lived in Saskatoon since 1999. In the 10 years I've been here I have to say\nI don't think I've ever been as excited about living somewhere as I am right now\n(and I've lived coast to coast, north to south within Canada). There are so many\npeople here with similar interests and it's great to see technology enthusiasts\nout at these events. It promotes the development of Saskatoon as even more of a\nwestern tech-mecca than people already perceive. It's great that people like\n[Ginger Koolick](https://twitter.com/gingerk) and [Ryan\nLejbak](https://twitter.com/ryanlejbak) have taken the initiative to develop this\nsort of community (and my apologies if I missed your name and you were a key\npart of the involvement of Bar Camp Saskatoon) and companies like\n[zu](https://www.zu.com), [Point2](https://www.point2.com), [YasTech](https://www.yastech.ca)\n(and more) are willing to spend time and effort sponsoring the events. (Wanted:\n[VendAsta](https://www.vendasta.com) as a sponsor for next year!)\n\nI'm stoked to connect more with people in the tech-community within Saskatoon\nand continue to learn from interesting people. **Can't wait until Bar Camp\nSaskatoon 2010 :D**\n\n"
}></{
  "path": "app/posts/2009-11-28-3-things-i-learned-at-barcamp-saskatoon-2009.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "3 things I learned at BarCamp Saskatoon 2009",
      "date": "2009-11-28"
    },
    "source": "\n> I attended Bar Camp Saskatoon today and while I wasn't able to stay for the\nentire series of presentations what I did manage to see was great. I presented\non [SASS](https://www.sass-lang.com), [Compass](https://www.compass-style.org) and\nCSS Frameworks. My presentation didn't go exactly as I'd planned but I learned\nthings from that experience and from other peoples presentations.\n\n## 1. Your presentation doesn't have to be long to be effective.\n\n[Nate Heagy's](https://twitter.com/nheagy) presentation on JavaScript was\nperfect, IMHO. It was about 15 minutes of airtime that offered about another 10\nto 15 minutes of discussion. The time slot allotment is just about an hour\n(including time for questions) but I felt like given the open format of Bar Camp\nless talk and more group discussion works really well. Also, kudos to Nate for\nimbuing his presentation with a healthy dose of humour in addition to the\nexcellent information. **Engaging++**\n\n## 2. If you do live coding, be uber prepared for failure ... and recover\ngracefully if possible.\n\nAfter last years presentation on using Yahoo Pipes for one of our corporate\nwebsite projects I thought it might be nice to do some actual live coding for a\nbar camp presentation. Admittedly I had no idea how this would go over given the\nskill level of attendees, technical capabilities of the presentation\nenvironment, scope of my presentation and a whole bunch of other variables I\nhummed and haah'd over. My goal was to take a web page design from zilch to\ncompletion using the techniques I'd learned in with SASS and Compass while\nproviding some tips / insight into tricks I've integrated into my development\nprocess along the way. It turned out to be more of a brief feature demonstration\nof SASS, some extended use of Firebug as an inspection tool, and some examples\nof what I feel is wrong with the way CSS frameworks are used these days. I think\nI could have condensed it to be shorter with less live coding and focused on the\nidea I opened with, that CSS Frameworks go against the very nature of what CSS\nwas provided to do, but SASS and Compass fix this by allowing you to continue to\nuse the frameworks without presentational class names.\n\nI made a few flubs and things didn't work out exactly how I thought, but the\nexperience of presenting in front of a large group of people is very valuable\nand the more I do it the more I learn what works and what doesn't. (If you're\ninterested in the very disorganized collection of assets I produced for the talk\nthey are available [here](https://bit.ly/6PsWqr)). If I could retool it I think\nI'd go back and stick to my script more (I generated a series of notes that I\nkind of \"forgot\" to use during the presentation -- nerves and all that),\ncondense it significantly and offer more time for discussion.\n\n## 3. Saskatoon has a vibrant, growing tech-community. This is awesome.\n\nI've lived in Saskatoon since 1999. In the 10 years I've been here I have to say\nI don't think I've ever been as excited about living somewhere as I am right now\n(and I've lived coast to coast, north to south within Canada). There are so many\npeople here with similar interests and it's great to see technology enthusiasts\nout at these events. It promotes the development of Saskatoon as even more of a\nwestern tech-mecca than people already perceive. It's great that people like\n[Ginger Koolick](https://twitter.com/gingerk) and [Ryan\nLejbak](https://twitter.com/ryanlejbak) have taken the initiative to develop this\nsort of community (and my apologies if I missed your name and you were a key\npart of the involvement of Bar Camp Saskatoon) and companies like\n[zu](https://www.zu.com), [Point2](https://www.point2.com), [YasTech](https://www.yastech.ca)\n(and more) are willing to spend time and effort sponsoring the events. (Wanted:\n[VendAsta](https://www.vendasta.com) as a sponsor for next year!)\n\nI'm stoked to connect more with people in the tech-community within Saskatoon\nand continue to learn from interesting people. **Can't wait until Bar Camp\nSaskatoon 2010 :D**\n\n"
  },
  "attributes": {
    "title": "3 things I learned at BarCamp Saskatoon 2009",
    "date": "2009-11-28"
  },
  "markdown": "\n> I attended Bar Camp Saskatoon today and while I wasn't able to stay for the\nentire series of presentations what I did manage to see was great. I presented\non [SASS](https://www.sass-lang.com), [Compass](https://www.compass-style.org) and\nCSS Frameworks. My presentation didn't go exactly as I'd planned but I learned\nthings from that experience and from other peoples presentations.\n\n## 1. Your presentation doesn't have to be long to be effective.\n\n[Nate Heagy's](https://twitter.com/nheagy) presentation on JavaScript was\nperfect, IMHO. It was about 15 minutes of airtime that offered about another 10\nto 15 minutes of discussion. The time slot allotment is just about an hour\n(including time for questions) but I felt like given the open format of Bar Camp\nless talk and more group discussion works really well. Also, kudos to Nate for\nimbuing his presentation with a healthy dose of humour in addition to the\nexcellent information. **Engaging++**\n\n## 2. If you do live coding, be uber prepared for failure ... and recover\ngracefully if possible.\n\nAfter last years presentation on using Yahoo Pipes for one of our corporate\nwebsite projects I thought it might be nice to do some actual live coding for a\nbar camp presentation. Admittedly I had no idea how this would go over given the\nskill level of attendees, technical capabilities of the presentation\nenvironment, scope of my presentation and a whole bunch of other variables I\nhummed and haah'd over. My goal was to take a web page design from zilch to\ncompletion using the techniques I'd learned in with SASS and Compass while\nproviding some tips / insight into tricks I've integrated into my development\nprocess along the way. It turned out to be more of a brief feature demonstration\nof SASS, some extended use of Firebug as an inspection tool, and some examples\nof what I feel is wrong with the way CSS frameworks are used these days. I think\nI could have condensed it to be shorter with less live coding and focused on the\nidea I opened with, that CSS Frameworks go against the very nature of what CSS\nwas provided to do, but SASS and Compass fix this by allowing you to continue to\nuse the frameworks without presentational class names.\n\nI made a few flubs and things didn't work out exactly how I thought, but the\nexperience of presenting in front of a large group of people is very valuable\nand the more I do it the more I learn what works and what doesn't. (If you're\ninterested in the very disorganized collection of assets I produced for the talk\nthey are available [here](https://bit.ly/6PsWqr)). If I could retool it I think\nI'd go back and stick to my script more (I generated a series of notes that I\nkind of \"forgot\" to use during the presentation -- nerves and all that),\ncondense it significantly and offer more time for discussion.\n\n## 3. Saskatoon has a vibrant, growing tech-community. This is awesome.\n\nI've lived in Saskatoon since 1999. In the 10 years I've been here I have to say\nI don't think I've ever been as excited about living somewhere as I am right now\n(and I've lived coast to coast, north to south within Canada). There are so many\npeople here with similar interests and it's great to see technology enthusiasts\nout at these events. It promotes the development of Saskatoon as even more of a\nwestern tech-mecca than people already perceive. It's great that people like\n[Ginger Koolick](https://twitter.com/gingerk) and [Ryan\nLejbak](https://twitter.com/ryanlejbak) have taken the initiative to develop this\nsort of community (and my apologies if I missed your name and you were a key\npart of the involvement of Bar Camp Saskatoon) and companies like\n[zu](https://www.zu.com), [Point2](https://www.point2.com), [YasTech](https://www.yastech.ca)\n(and more) are willing to spend time and effort sponsoring the events. (Wanted:\n[VendAsta](https://www.vendasta.com) as a sponsor for next year!)\n\nI'm stoked to connect more with people in the tech-community within Saskatoon\nand continue to learn from interesting people. **Can't wait until Bar Camp\nSaskatoon 2010 :D**\n\n"
}></pre></div><div><a href="/posts/2009-10-27-using-the-sed-stream-editor-in-mac-os-x-terminal.html">Using the SED stream editor in macOS terminal.app</a><pre><{
  "path": "app/posts/2009-10-27-using-the-sed-stream-editor-in-mac-os-x-terminal.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Using the SED stream editor in macOS terminal.app",
      "date": "2009-10-27"
    },
    "source": "\n> This is pretty useful, piping the results of the echo to the \"sed\" command which\nstands for \"stream editor\" and then iterating over things in a loop and batch\nrenaming them. I could have renamed them manually, but this was more fun and I\nlearned something!\n\n```bash\nfor x in *\\ *; do y=$(echo \"$x\" | sed y/\\ \\/./); mv \"$x\" \"$y\"; done\n```"
  },
  "attributes": {
    "title": "Using the SED stream editor in macOS terminal.app",
    "date": "2009-10-27"
  },
  "markdown": "\n> This is pretty useful, piping the results of the echo to the \"sed\" command which\nstands for \"stream editor\" and then iterating over things in a loop and batch\nrenaming them. I could have renamed them manually, but this was more fun and I\nlearned something!\n\n```bash\nfor x in *\\ *; do y=$(echo \"$x\" | sed y/\\ \\/./); mv \"$x\" \"$y\"; done\n```"
}></{
  "path": "app/posts/2009-10-27-using-the-sed-stream-editor-in-mac-os-x-terminal.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Using the SED stream editor in macOS terminal.app",
      "date": "2009-10-27"
    },
    "source": "\n> This is pretty useful, piping the results of the echo to the \"sed\" command which\nstands for \"stream editor\" and then iterating over things in a loop and batch\nrenaming them. I could have renamed them manually, but this was more fun and I\nlearned something!\n\n```bash\nfor x in *\\ *; do y=$(echo \"$x\" | sed y/\\ \\/./); mv \"$x\" \"$y\"; done\n```"
  },
  "attributes": {
    "title": "Using the SED stream editor in macOS terminal.app",
    "date": "2009-10-27"
  },
  "markdown": "\n> This is pretty useful, piping the results of the echo to the \"sed\" command which\nstands for \"stream editor\" and then iterating over things in a loop and batch\nrenaming them. I could have renamed them manually, but this was more fun and I\nlearned something!\n\n```bash\nfor x in *\\ *; do y=$(echo \"$x\" | sed y/\\ \\/./); mv \"$x\" \"$y\"; done\n```"
}></pre></div><div><a href="/posts/2009-08-06-vendasta-a-year-in-review.html">VendAsta: a year in review</a><pre><{
  "path": "app/posts/2009-08-06-vendasta-a-year-in-review.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "VendAsta: a year in review",
      "date": "2009-08-06"
    },
    "source": "\n> It was almost a year ago that I [posted](https://davemo.wordpress.com/2008/08/18/work-bliss/) on my experiences as a new employee at [VendAsta](https://www.vendasta.com) Technologies, one of the newest technology companies in Saskatoon. I think it's a good idea to have a blog to look back on, it's a really good indication of the accomplishments you've made and gives you the ability to reflect on what your mindset was and how it's changed since then.\n\nIn re-reading my blog post about work bliss, I've come to some conclusions about my experiences in the past year and decided it would be a good idea to reflect on my experiences with the company in that time and some of the struggles and accomplishments I've worked through.\n\n## Rose Colored Glasses\n\nThere's a certain glow about a person who's just been hired at a new workplace. It's the kind of thing that sometimes makes people see things the way they want\nto see them, instead of the way they really are. The first thing I think about when I re-read my post was \"Geez, I sure went into this job with rose colored glasses on\". I should clarify the preceding statement though; I don't feel that my impressions of the company then were wrong. In fact, having worked here for\nnearly a year I think I'd be accurate in still saying it's a great place to work that provides ample opportunity for self expression and improvement.\n\n> I think the error of my ways in donning rose colored glasses in my outlook to the new job was really one of setting myself up for disappointment.\n\nIt's almost impossible for anyone or anything to be perfect, and companies are no exception. I think initially I may have set my expectations a little too high regarding the company, corporate environment and sometimes the people I worked with. When you do this you create an environment that's setup to disappoint you. I'm not saying we should be pessimists as I think an optimistic outlook is important to the health and well being of employees, but it's easy to become disappointed (and sometimes even hurt) when you place things up on a pedestal expecting perfection.\n\nVendAsta is still a great place to work, filled with ultra-talented individuals. I think in a year of working here I've just learned to not put people and the\ncompany in a place in my mind that's set to inevitably disappoint me. Or, in a manner of speaking, I've taken off the rose colored glasses and started looking\nat things through lenses of realism ;)\n\n## Struggles\n\nThere have been a number of things I've struggled with from a professional point of view in my year at VendAsta. I think examining ones weak-points is a\nbeneficial exercise because it helps us to identify them in the future and come up with strategies for avoiding their pitfalls. Lack of confidence is a huge\nhurdle that I've had to overcome in my time here; a hurdle that I feel, for the most part, I've cleared. Perhaps it's just human nature to be intimidated when\nstarting a new position and coming out of (relative) inexperience. If I look back at what I've accomplished even in my time before working at VendAsta I\nstart to feel more confident; I think my problem initially was that I was too quick to compare my experiences to those of the people around me. This is\ndangerous because it can create a perceived disparity between what you've accomplished and the relative value of what you see other people have\naccomplished. It's easy to get into the comparison game and start to feel a lack of confidence because you inflate the value of other peoples accomplishments\nnext to your own. I've learned to put aside direct comparisons with the accomplishments of others and, instead, started to focus on comparing my own\naccomplishments a year ago versus what I've accomplished now.\n\n> It's sometimes easy to get discouraged that despite your passion and desire to change processes you aren't ultimately having a positive effect on improving\nthem. I have felt this way often in the past year and, at times, given one of two possible responses: apathy or determination.\n\nIt's much easier to become apathetic when you feel like the things you're suggesting are falling on deaf ears, so to speak. The nobler (and harder) thing to do is to persevere despite this and continue to voice your opinions. I haven't quite mastered this yet but I think it's important to at least recognize these responses and choose for yourself on a daily basis which you are going to do. I've felt that sometimes it just isn't worth voicing my opinion and taken the apathetic route, but I always end up feeling like crap after doing this. Even though it's harder to be determined I think it's more rewarding and ultimately builds more character. Going forward I'm going to give it my personal best to stay determined and positive despite these setbacks.\n\nAs a software developer it's so easy to second guess the decisions we make when it comes to coding and design. Some of this is healthy, but it becomes\ndestructive when we enter a mindset that causes us to feel like we must always rely on others to give us direction in order to proceed. Code Review, Peer\nReview and Pair Programming are all things that VendAsta promotes as part of its mandate to implement the Scrum process as closely as possible but I've realized\nthat these tools in and of themselves don't make better programmers; it's really only the ability to learn from ones mistakes that produces a better programmer.\nAm I confident that I'm a good programmer? No, but I've moved away from being scared of making mistakes to embracing them as a learning opportunity. I'm not\nafraid to implement an algorithm I designed, see how it works in code, and then find out that there is an easier way to do things. I've learned that there will\nalways be an easier, better way to do things than the solution I come up with. The work that I'm doing and the people that work here have enabled me to feel\nthat I'm a better programmer than I was a year ago and that I'm heading in the right direction, and that's one of the most important parts of a satisfying work\nexperience.\n\n## Accomplishments\n\nWhen I started at VendAsta I thought my skill-set included a well rounded set of disciplines from my previous experience. Looking back at what I've accomplished\nin the last year I think it's safe to say that my toolbox has grown considerably. I didn't have much in the way of experience writing unit tests,\nwhich is a core philosophy at VendAsta. Writing tests and examining [Test Driven Development](https://en.wikipedia.org/wiki/Test_driven_development) has given me\na new appreciation for efficient ways to tackle development. The \"Red. Green. Refactor\" mantra is something I've taken to heart, not just when writing unit\ntests but when writing my actual code as well. I've learned about things like [Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection), how\nto [refactor](https://en.wikipedia.org/wiki/Refactor) efficiently, and how [abstraction](https://en.wikipedia.org/wiki/Abstraction_(computer_science)) can\nhelp achieve reusability. I've taken my knowledge of CSS and HTML to a new level, something I thought starting out last year that I had mastered. I've also\nlearned that I haven't really mastered anything as a software developer/designer and I probably never will, but that's ok.\n\nI've written more JavaScript in the last year than I did in the previous 6 years combined. Being able to understand the language at it's lower levels has given\nme an appreciation for the abstractions available in current libraries like [jQuery](https://www.jquery.com) and [YUI](https://developer.yahoo.com/yui/).\nReading and learning from [Douglas Crockford](https://crockford.com/) and the YUI Theatre have proved to be an invaluable tool in my JavaScript toolbox. Closures, Prototypal Inheritance, and [Dependency Management](https://davemo.wordpress.com/2009/03/13/javascript-dependency-management-and-yui-loader-quirks/) are all things I've learned to deal with effectively. As much as I've learned about JS in the last year I still feel I've only touched the tip of the ice berg\nin terms of what's capable. JavaScript is truly an expressive and powerful language and I think many people in the software development community\nunderestimate it as something that is the language of web hackers and script kiddies; they couldn't be more wrong.\n\nI had dabbled with [Django](https://www.djangoproject.com) and [Python](https://python.org/) at the beginning of last year, running through the\nmost basic tutorials and building a basic blog with Django. When I started at VendAsta that experience proved to be valuable as we used the experience of\nbuilding our corporate website in Django as a stepping stone to understanding what we'd need to do when building [StepRep](https://steprep.myfrontsteps.com)\nand [MyFrontSteps](https://www.myfrontsteps.com). I participated in the development of both of our core products from the stages of infancy up to where\nthey are today and I'm very proud of what we've accomplished in less than a year. I almost forgot to mention Google AppEngine which we use to host MFS and\nSREP. Learning about GAE has enabled me to expand my knowledge of so many other areas of development that I wouldn't have imagined. It's foundation is in Python\nand we run Django on it. Our applications are tied very tightly to JavaScript (almost to a fault) which has enabled me to learn so much about that language.\nI've learned how to create a project from scratch on AppEngine using alternate frameworks like [WebPy](https://webpy.org/), [CherryPy](https://www.cherrypy.org/)\nand [Google WebApp](https://code.google.com/appengine/docs/python/tools/webapp/). I've deployed several websites on AppEngine [for work](https://take5billiards.appspot.com) and on [my own](https://first.draftmovies.com) as side projects to explore further uses of the platform when coupled with social network platforms like Twitter. In developing MFS I was able to learn how to build a social application on both Facebook and MySpace concurrently as well as supporting a standalone platform (not an easy task). [Jeff Read](https://www.ifisgeek.com) and I customized an open source upload utility, the [YUI Uploader](https://developer.yahoo.com/yui/uploader/), to do client side resizing of photos using the open source version of the Flex SDK.\n\n## The Future\n\nNo job is perfect, and I think it's safe to say that looking into the future I can't predict what's going to happen at VendAsta. However I think looking back\nhas given me a new appreciation for the work I'm able to do here and the things I've been able to accomplish. I think VendAsta will succeed as long as we keep\nhiring exceptional people that strive to improve themselves on a daily basis. I'm trying to continue to do that myself ;)\n"
  },
  "attributes": {
    "title": "VendAsta: a year in review",
    "date": "2009-08-06"
  },
  "markdown": "\n> It was almost a year ago that I [posted](https://davemo.wordpress.com/2008/08/18/work-bliss/) on my experiences as a new employee at [VendAsta](https://www.vendasta.com) Technologies, one of the newest technology companies in Saskatoon. I think it's a good idea to have a blog to look back on, it's a really good indication of the accomplishments you've made and gives you the ability to reflect on what your mindset was and how it's changed since then.\n\nIn re-reading my blog post about work bliss, I've come to some conclusions about my experiences in the past year and decided it would be a good idea to reflect on my experiences with the company in that time and some of the struggles and accomplishments I've worked through.\n\n## Rose Colored Glasses\n\nThere's a certain glow about a person who's just been hired at a new workplace. It's the kind of thing that sometimes makes people see things the way they want\nto see them, instead of the way they really are. The first thing I think about when I re-read my post was \"Geez, I sure went into this job with rose colored glasses on\". I should clarify the preceding statement though; I don't feel that my impressions of the company then were wrong. In fact, having worked here for\nnearly a year I think I'd be accurate in still saying it's a great place to work that provides ample opportunity for self expression and improvement.\n\n> I think the error of my ways in donning rose colored glasses in my outlook to the new job was really one of setting myself up for disappointment.\n\nIt's almost impossible for anyone or anything to be perfect, and companies are no exception. I think initially I may have set my expectations a little too high regarding the company, corporate environment and sometimes the people I worked with. When you do this you create an environment that's setup to disappoint you. I'm not saying we should be pessimists as I think an optimistic outlook is important to the health and well being of employees, but it's easy to become disappointed (and sometimes even hurt) when you place things up on a pedestal expecting perfection.\n\nVendAsta is still a great place to work, filled with ultra-talented individuals. I think in a year of working here I've just learned to not put people and the\ncompany in a place in my mind that's set to inevitably disappoint me. Or, in a manner of speaking, I've taken off the rose colored glasses and started looking\nat things through lenses of realism ;)\n\n## Struggles\n\nThere have been a number of things I've struggled with from a professional point of view in my year at VendAsta. I think examining ones weak-points is a\nbeneficial exercise because it helps us to identify them in the future and come up with strategies for avoiding their pitfalls. Lack of confidence is a huge\nhurdle that I've had to overcome in my time here; a hurdle that I feel, for the most part, I've cleared. Perhaps it's just human nature to be intimidated when\nstarting a new position and coming out of (relative) inexperience. If I look back at what I've accomplished even in my time before working at VendAsta I\nstart to feel more confident; I think my problem initially was that I was too quick to compare my experiences to those of the people around me. This is\ndangerous because it can create a perceived disparity between what you've accomplished and the relative value of what you see other people have\naccomplished. It's easy to get into the comparison game and start to feel a lack of confidence because you inflate the value of other peoples accomplishments\nnext to your own. I've learned to put aside direct comparisons with the accomplishments of others and, instead, started to focus on comparing my own\naccomplishments a year ago versus what I've accomplished now.\n\n> It's sometimes easy to get discouraged that despite your passion and desire to change processes you aren't ultimately having a positive effect on improving\nthem. I have felt this way often in the past year and, at times, given one of two possible responses: apathy or determination.\n\nIt's much easier to become apathetic when you feel like the things you're suggesting are falling on deaf ears, so to speak. The nobler (and harder) thing to do is to persevere despite this and continue to voice your opinions. I haven't quite mastered this yet but I think it's important to at least recognize these responses and choose for yourself on a daily basis which you are going to do. I've felt that sometimes it just isn't worth voicing my opinion and taken the apathetic route, but I always end up feeling like crap after doing this. Even though it's harder to be determined I think it's more rewarding and ultimately builds more character. Going forward I'm going to give it my personal best to stay determined and positive despite these setbacks.\n\nAs a software developer it's so easy to second guess the decisions we make when it comes to coding and design. Some of this is healthy, but it becomes\ndestructive when we enter a mindset that causes us to feel like we must always rely on others to give us direction in order to proceed. Code Review, Peer\nReview and Pair Programming are all things that VendAsta promotes as part of its mandate to implement the Scrum process as closely as possible but I've realized\nthat these tools in and of themselves don't make better programmers; it's really only the ability to learn from ones mistakes that produces a better programmer.\nAm I confident that I'm a good programmer? No, but I've moved away from being scared of making mistakes to embracing them as a learning opportunity. I'm not\nafraid to implement an algorithm I designed, see how it works in code, and then find out that there is an easier way to do things. I've learned that there will\nalways be an easier, better way to do things than the solution I come up with. The work that I'm doing and the people that work here have enabled me to feel\nthat I'm a better programmer than I was a year ago and that I'm heading in the right direction, and that's one of the most important parts of a satisfying work\nexperience.\n\n## Accomplishments\n\nWhen I started at VendAsta I thought my skill-set included a well rounded set of disciplines from my previous experience. Looking back at what I've accomplished\nin the last year I think it's safe to say that my toolbox has grown considerably. I didn't have much in the way of experience writing unit tests,\nwhich is a core philosophy at VendAsta. Writing tests and examining [Test Driven Development](https://en.wikipedia.org/wiki/Test_driven_development) has given me\na new appreciation for efficient ways to tackle development. The \"Red. Green. Refactor\" mantra is something I've taken to heart, not just when writing unit\ntests but when writing my actual code as well. I've learned about things like [Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection), how\nto [refactor](https://en.wikipedia.org/wiki/Refactor) efficiently, and how [abstraction](https://en.wikipedia.org/wiki/Abstraction_(computer_science)) can\nhelp achieve reusability. I've taken my knowledge of CSS and HTML to a new level, something I thought starting out last year that I had mastered. I've also\nlearned that I haven't really mastered anything as a software developer/designer and I probably never will, but that's ok.\n\nI've written more JavaScript in the last year than I did in the previous 6 years combined. Being able to understand the language at it's lower levels has given\nme an appreciation for the abstractions available in current libraries like [jQuery](https://www.jquery.com) and [YUI](https://developer.yahoo.com/yui/).\nReading and learning from [Douglas Crockford](https://crockford.com/) and the YUI Theatre have proved to be an invaluable tool in my JavaScript toolbox. Closures, Prototypal Inheritance, and [Dependency Management](https://davemo.wordpress.com/2009/03/13/javascript-dependency-management-and-yui-loader-quirks/) are all things I've learned to deal with effectively. As much as I've learned about JS in the last year I still feel I've only touched the tip of the ice berg\nin terms of what's capable. JavaScript is truly an expressive and powerful language and I think many people in the software development community\nunderestimate it as something that is the language of web hackers and script kiddies; they couldn't be more wrong.\n\nI had dabbled with [Django](https://www.djangoproject.com) and [Python](https://python.org/) at the beginning of last year, running through the\nmost basic tutorials and building a basic blog with Django. When I started at VendAsta that experience proved to be valuable as we used the experience of\nbuilding our corporate website in Django as a stepping stone to understanding what we'd need to do when building [StepRep](https://steprep.myfrontsteps.com)\nand [MyFrontSteps](https://www.myfrontsteps.com). I participated in the development of both of our core products from the stages of infancy up to where\nthey are today and I'm very proud of what we've accomplished in less than a year. I almost forgot to mention Google AppEngine which we use to host MFS and\nSREP. Learning about GAE has enabled me to expand my knowledge of so many other areas of development that I wouldn't have imagined. It's foundation is in Python\nand we run Django on it. Our applications are tied very tightly to JavaScript (almost to a fault) which has enabled me to learn so much about that language.\nI've learned how to create a project from scratch on AppEngine using alternate frameworks like [WebPy](https://webpy.org/), [CherryPy](https://www.cherrypy.org/)\nand [Google WebApp](https://code.google.com/appengine/docs/python/tools/webapp/). I've deployed several websites on AppEngine [for work](https://take5billiards.appspot.com) and on [my own](https://first.draftmovies.com) as side projects to explore further uses of the platform when coupled with social network platforms like Twitter. In developing MFS I was able to learn how to build a social application on both Facebook and MySpace concurrently as well as supporting a standalone platform (not an easy task). [Jeff Read](https://www.ifisgeek.com) and I customized an open source upload utility, the [YUI Uploader](https://developer.yahoo.com/yui/uploader/), to do client side resizing of photos using the open source version of the Flex SDK.\n\n## The Future\n\nNo job is perfect, and I think it's safe to say that looking into the future I can't predict what's going to happen at VendAsta. However I think looking back\nhas given me a new appreciation for the work I'm able to do here and the things I've been able to accomplish. I think VendAsta will succeed as long as we keep\nhiring exceptional people that strive to improve themselves on a daily basis. I'm trying to continue to do that myself ;)\n"
}></{
  "path": "app/posts/2009-08-06-vendasta-a-year-in-review.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "VendAsta: a year in review",
      "date": "2009-08-06"
    },
    "source": "\n> It was almost a year ago that I [posted](https://davemo.wordpress.com/2008/08/18/work-bliss/) on my experiences as a new employee at [VendAsta](https://www.vendasta.com) Technologies, one of the newest technology companies in Saskatoon. I think it's a good idea to have a blog to look back on, it's a really good indication of the accomplishments you've made and gives you the ability to reflect on what your mindset was and how it's changed since then.\n\nIn re-reading my blog post about work bliss, I've come to some conclusions about my experiences in the past year and decided it would be a good idea to reflect on my experiences with the company in that time and some of the struggles and accomplishments I've worked through.\n\n## Rose Colored Glasses\n\nThere's a certain glow about a person who's just been hired at a new workplace. It's the kind of thing that sometimes makes people see things the way they want\nto see them, instead of the way they really are. The first thing I think about when I re-read my post was \"Geez, I sure went into this job with rose colored glasses on\". I should clarify the preceding statement though; I don't feel that my impressions of the company then were wrong. In fact, having worked here for\nnearly a year I think I'd be accurate in still saying it's a great place to work that provides ample opportunity for self expression and improvement.\n\n> I think the error of my ways in donning rose colored glasses in my outlook to the new job was really one of setting myself up for disappointment.\n\nIt's almost impossible for anyone or anything to be perfect, and companies are no exception. I think initially I may have set my expectations a little too high regarding the company, corporate environment and sometimes the people I worked with. When you do this you create an environment that's setup to disappoint you. I'm not saying we should be pessimists as I think an optimistic outlook is important to the health and well being of employees, but it's easy to become disappointed (and sometimes even hurt) when you place things up on a pedestal expecting perfection.\n\nVendAsta is still a great place to work, filled with ultra-talented individuals. I think in a year of working here I've just learned to not put people and the\ncompany in a place in my mind that's set to inevitably disappoint me. Or, in a manner of speaking, I've taken off the rose colored glasses and started looking\nat things through lenses of realism ;)\n\n## Struggles\n\nThere have been a number of things I've struggled with from a professional point of view in my year at VendAsta. I think examining ones weak-points is a\nbeneficial exercise because it helps us to identify them in the future and come up with strategies for avoiding their pitfalls. Lack of confidence is a huge\nhurdle that I've had to overcome in my time here; a hurdle that I feel, for the most part, I've cleared. Perhaps it's just human nature to be intimidated when\nstarting a new position and coming out of (relative) inexperience. If I look back at what I've accomplished even in my time before working at VendAsta I\nstart to feel more confident; I think my problem initially was that I was too quick to compare my experiences to those of the people around me. This is\ndangerous because it can create a perceived disparity between what you've accomplished and the relative value of what you see other people have\naccomplished. It's easy to get into the comparison game and start to feel a lack of confidence because you inflate the value of other peoples accomplishments\nnext to your own. I've learned to put aside direct comparisons with the accomplishments of others and, instead, started to focus on comparing my own\naccomplishments a year ago versus what I've accomplished now.\n\n> It's sometimes easy to get discouraged that despite your passion and desire to change processes you aren't ultimately having a positive effect on improving\nthem. I have felt this way often in the past year and, at times, given one of two possible responses: apathy or determination.\n\nIt's much easier to become apathetic when you feel like the things you're suggesting are falling on deaf ears, so to speak. The nobler (and harder) thing to do is to persevere despite this and continue to voice your opinions. I haven't quite mastered this yet but I think it's important to at least recognize these responses and choose for yourself on a daily basis which you are going to do. I've felt that sometimes it just isn't worth voicing my opinion and taken the apathetic route, but I always end up feeling like crap after doing this. Even though it's harder to be determined I think it's more rewarding and ultimately builds more character. Going forward I'm going to give it my personal best to stay determined and positive despite these setbacks.\n\nAs a software developer it's so easy to second guess the decisions we make when it comes to coding and design. Some of this is healthy, but it becomes\ndestructive when we enter a mindset that causes us to feel like we must always rely on others to give us direction in order to proceed. Code Review, Peer\nReview and Pair Programming are all things that VendAsta promotes as part of its mandate to implement the Scrum process as closely as possible but I've realized\nthat these tools in and of themselves don't make better programmers; it's really only the ability to learn from ones mistakes that produces a better programmer.\nAm I confident that I'm a good programmer? No, but I've moved away from being scared of making mistakes to embracing them as a learning opportunity. I'm not\nafraid to implement an algorithm I designed, see how it works in code, and then find out that there is an easier way to do things. I've learned that there will\nalways be an easier, better way to do things than the solution I come up with. The work that I'm doing and the people that work here have enabled me to feel\nthat I'm a better programmer than I was a year ago and that I'm heading in the right direction, and that's one of the most important parts of a satisfying work\nexperience.\n\n## Accomplishments\n\nWhen I started at VendAsta I thought my skill-set included a well rounded set of disciplines from my previous experience. Looking back at what I've accomplished\nin the last year I think it's safe to say that my toolbox has grown considerably. I didn't have much in the way of experience writing unit tests,\nwhich is a core philosophy at VendAsta. Writing tests and examining [Test Driven Development](https://en.wikipedia.org/wiki/Test_driven_development) has given me\na new appreciation for efficient ways to tackle development. The \"Red. Green. Refactor\" mantra is something I've taken to heart, not just when writing unit\ntests but when writing my actual code as well. I've learned about things like [Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection), how\nto [refactor](https://en.wikipedia.org/wiki/Refactor) efficiently, and how [abstraction](https://en.wikipedia.org/wiki/Abstraction_(computer_science)) can\nhelp achieve reusability. I've taken my knowledge of CSS and HTML to a new level, something I thought starting out last year that I had mastered. I've also\nlearned that I haven't really mastered anything as a software developer/designer and I probably never will, but that's ok.\n\nI've written more JavaScript in the last year than I did in the previous 6 years combined. Being able to understand the language at it's lower levels has given\nme an appreciation for the abstractions available in current libraries like [jQuery](https://www.jquery.com) and [YUI](https://developer.yahoo.com/yui/).\nReading and learning from [Douglas Crockford](https://crockford.com/) and the YUI Theatre have proved to be an invaluable tool in my JavaScript toolbox. Closures, Prototypal Inheritance, and [Dependency Management](https://davemo.wordpress.com/2009/03/13/javascript-dependency-management-and-yui-loader-quirks/) are all things I've learned to deal with effectively. As much as I've learned about JS in the last year I still feel I've only touched the tip of the ice berg\nin terms of what's capable. JavaScript is truly an expressive and powerful language and I think many people in the software development community\nunderestimate it as something that is the language of web hackers and script kiddies; they couldn't be more wrong.\n\nI had dabbled with [Django](https://www.djangoproject.com) and [Python](https://python.org/) at the beginning of last year, running through the\nmost basic tutorials and building a basic blog with Django. When I started at VendAsta that experience proved to be valuable as we used the experience of\nbuilding our corporate website in Django as a stepping stone to understanding what we'd need to do when building [StepRep](https://steprep.myfrontsteps.com)\nand [MyFrontSteps](https://www.myfrontsteps.com). I participated in the development of both of our core products from the stages of infancy up to where\nthey are today and I'm very proud of what we've accomplished in less than a year. I almost forgot to mention Google AppEngine which we use to host MFS and\nSREP. Learning about GAE has enabled me to expand my knowledge of so many other areas of development that I wouldn't have imagined. It's foundation is in Python\nand we run Django on it. Our applications are tied very tightly to JavaScript (almost to a fault) which has enabled me to learn so much about that language.\nI've learned how to create a project from scratch on AppEngine using alternate frameworks like [WebPy](https://webpy.org/), [CherryPy](https://www.cherrypy.org/)\nand [Google WebApp](https://code.google.com/appengine/docs/python/tools/webapp/). I've deployed several websites on AppEngine [for work](https://take5billiards.appspot.com) and on [my own](https://first.draftmovies.com) as side projects to explore further uses of the platform when coupled with social network platforms like Twitter. In developing MFS I was able to learn how to build a social application on both Facebook and MySpace concurrently as well as supporting a standalone platform (not an easy task). [Jeff Read](https://www.ifisgeek.com) and I customized an open source upload utility, the [YUI Uploader](https://developer.yahoo.com/yui/uploader/), to do client side resizing of photos using the open source version of the Flex SDK.\n\n## The Future\n\nNo job is perfect, and I think it's safe to say that looking into the future I can't predict what's going to happen at VendAsta. However I think looking back\nhas given me a new appreciation for the work I'm able to do here and the things I've been able to accomplish. I think VendAsta will succeed as long as we keep\nhiring exceptional people that strive to improve themselves on a daily basis. I'm trying to continue to do that myself ;)\n"
  },
  "attributes": {
    "title": "VendAsta: a year in review",
    "date": "2009-08-06"
  },
  "markdown": "\n> It was almost a year ago that I [posted](https://davemo.wordpress.com/2008/08/18/work-bliss/) on my experiences as a new employee at [VendAsta](https://www.vendasta.com) Technologies, one of the newest technology companies in Saskatoon. I think it's a good idea to have a blog to look back on, it's a really good indication of the accomplishments you've made and gives you the ability to reflect on what your mindset was and how it's changed since then.\n\nIn re-reading my blog post about work bliss, I've come to some conclusions about my experiences in the past year and decided it would be a good idea to reflect on my experiences with the company in that time and some of the struggles and accomplishments I've worked through.\n\n## Rose Colored Glasses\n\nThere's a certain glow about a person who's just been hired at a new workplace. It's the kind of thing that sometimes makes people see things the way they want\nto see them, instead of the way they really are. The first thing I think about when I re-read my post was \"Geez, I sure went into this job with rose colored glasses on\". I should clarify the preceding statement though; I don't feel that my impressions of the company then were wrong. In fact, having worked here for\nnearly a year I think I'd be accurate in still saying it's a great place to work that provides ample opportunity for self expression and improvement.\n\n> I think the error of my ways in donning rose colored glasses in my outlook to the new job was really one of setting myself up for disappointment.\n\nIt's almost impossible for anyone or anything to be perfect, and companies are no exception. I think initially I may have set my expectations a little too high regarding the company, corporate environment and sometimes the people I worked with. When you do this you create an environment that's setup to disappoint you. I'm not saying we should be pessimists as I think an optimistic outlook is important to the health and well being of employees, but it's easy to become disappointed (and sometimes even hurt) when you place things up on a pedestal expecting perfection.\n\nVendAsta is still a great place to work, filled with ultra-talented individuals. I think in a year of working here I've just learned to not put people and the\ncompany in a place in my mind that's set to inevitably disappoint me. Or, in a manner of speaking, I've taken off the rose colored glasses and started looking\nat things through lenses of realism ;)\n\n## Struggles\n\nThere have been a number of things I've struggled with from a professional point of view in my year at VendAsta. I think examining ones weak-points is a\nbeneficial exercise because it helps us to identify them in the future and come up with strategies for avoiding their pitfalls. Lack of confidence is a huge\nhurdle that I've had to overcome in my time here; a hurdle that I feel, for the most part, I've cleared. Perhaps it's just human nature to be intimidated when\nstarting a new position and coming out of (relative) inexperience. If I look back at what I've accomplished even in my time before working at VendAsta I\nstart to feel more confident; I think my problem initially was that I was too quick to compare my experiences to those of the people around me. This is\ndangerous because it can create a perceived disparity between what you've accomplished and the relative value of what you see other people have\naccomplished. It's easy to get into the comparison game and start to feel a lack of confidence because you inflate the value of other peoples accomplishments\nnext to your own. I've learned to put aside direct comparisons with the accomplishments of others and, instead, started to focus on comparing my own\naccomplishments a year ago versus what I've accomplished now.\n\n> It's sometimes easy to get discouraged that despite your passion and desire to change processes you aren't ultimately having a positive effect on improving\nthem. I have felt this way often in the past year and, at times, given one of two possible responses: apathy or determination.\n\nIt's much easier to become apathetic when you feel like the things you're suggesting are falling on deaf ears, so to speak. The nobler (and harder) thing to do is to persevere despite this and continue to voice your opinions. I haven't quite mastered this yet but I think it's important to at least recognize these responses and choose for yourself on a daily basis which you are going to do. I've felt that sometimes it just isn't worth voicing my opinion and taken the apathetic route, but I always end up feeling like crap after doing this. Even though it's harder to be determined I think it's more rewarding and ultimately builds more character. Going forward I'm going to give it my personal best to stay determined and positive despite these setbacks.\n\nAs a software developer it's so easy to second guess the decisions we make when it comes to coding and design. Some of this is healthy, but it becomes\ndestructive when we enter a mindset that causes us to feel like we must always rely on others to give us direction in order to proceed. Code Review, Peer\nReview and Pair Programming are all things that VendAsta promotes as part of its mandate to implement the Scrum process as closely as possible but I've realized\nthat these tools in and of themselves don't make better programmers; it's really only the ability to learn from ones mistakes that produces a better programmer.\nAm I confident that I'm a good programmer? No, but I've moved away from being scared of making mistakes to embracing them as a learning opportunity. I'm not\nafraid to implement an algorithm I designed, see how it works in code, and then find out that there is an easier way to do things. I've learned that there will\nalways be an easier, better way to do things than the solution I come up with. The work that I'm doing and the people that work here have enabled me to feel\nthat I'm a better programmer than I was a year ago and that I'm heading in the right direction, and that's one of the most important parts of a satisfying work\nexperience.\n\n## Accomplishments\n\nWhen I started at VendAsta I thought my skill-set included a well rounded set of disciplines from my previous experience. Looking back at what I've accomplished\nin the last year I think it's safe to say that my toolbox has grown considerably. I didn't have much in the way of experience writing unit tests,\nwhich is a core philosophy at VendAsta. Writing tests and examining [Test Driven Development](https://en.wikipedia.org/wiki/Test_driven_development) has given me\na new appreciation for efficient ways to tackle development. The \"Red. Green. Refactor\" mantra is something I've taken to heart, not just when writing unit\ntests but when writing my actual code as well. I've learned about things like [Dependency Injection](https://en.wikipedia.org/wiki/Dependency_injection), how\nto [refactor](https://en.wikipedia.org/wiki/Refactor) efficiently, and how [abstraction](https://en.wikipedia.org/wiki/Abstraction_(computer_science)) can\nhelp achieve reusability. I've taken my knowledge of CSS and HTML to a new level, something I thought starting out last year that I had mastered. I've also\nlearned that I haven't really mastered anything as a software developer/designer and I probably never will, but that's ok.\n\nI've written more JavaScript in the last year than I did in the previous 6 years combined. Being able to understand the language at it's lower levels has given\nme an appreciation for the abstractions available in current libraries like [jQuery](https://www.jquery.com) and [YUI](https://developer.yahoo.com/yui/).\nReading and learning from [Douglas Crockford](https://crockford.com/) and the YUI Theatre have proved to be an invaluable tool in my JavaScript toolbox. Closures, Prototypal Inheritance, and [Dependency Management](https://davemo.wordpress.com/2009/03/13/javascript-dependency-management-and-yui-loader-quirks/) are all things I've learned to deal with effectively. As much as I've learned about JS in the last year I still feel I've only touched the tip of the ice berg\nin terms of what's capable. JavaScript is truly an expressive and powerful language and I think many people in the software development community\nunderestimate it as something that is the language of web hackers and script kiddies; they couldn't be more wrong.\n\nI had dabbled with [Django](https://www.djangoproject.com) and [Python](https://python.org/) at the beginning of last year, running through the\nmost basic tutorials and building a basic blog with Django. When I started at VendAsta that experience proved to be valuable as we used the experience of\nbuilding our corporate website in Django as a stepping stone to understanding what we'd need to do when building [StepRep](https://steprep.myfrontsteps.com)\nand [MyFrontSteps](https://www.myfrontsteps.com). I participated in the development of both of our core products from the stages of infancy up to where\nthey are today and I'm very proud of what we've accomplished in less than a year. I almost forgot to mention Google AppEngine which we use to host MFS and\nSREP. Learning about GAE has enabled me to expand my knowledge of so many other areas of development that I wouldn't have imagined. It's foundation is in Python\nand we run Django on it. Our applications are tied very tightly to JavaScript (almost to a fault) which has enabled me to learn so much about that language.\nI've learned how to create a project from scratch on AppEngine using alternate frameworks like [WebPy](https://webpy.org/), [CherryPy](https://www.cherrypy.org/)\nand [Google WebApp](https://code.google.com/appengine/docs/python/tools/webapp/). I've deployed several websites on AppEngine [for work](https://take5billiards.appspot.com) and on [my own](https://first.draftmovies.com) as side projects to explore further uses of the platform when coupled with social network platforms like Twitter. In developing MFS I was able to learn how to build a social application on both Facebook and MySpace concurrently as well as supporting a standalone platform (not an easy task). [Jeff Read](https://www.ifisgeek.com) and I customized an open source upload utility, the [YUI Uploader](https://developer.yahoo.com/yui/uploader/), to do client side resizing of photos using the open source version of the Flex SDK.\n\n## The Future\n\nNo job is perfect, and I think it's safe to say that looking into the future I can't predict what's going to happen at VendAsta. However I think looking back\nhas given me a new appreciation for the work I'm able to do here and the things I've been able to accomplish. I think VendAsta will succeed as long as we keep\nhiring exceptional people that strive to improve themselves on a daily basis. I'm trying to continue to do that myself ;)\n"
}></pre></div><div><a href="/posts/2009-07-31-the-new-twitter-homepage-now-with-114-percent-more-blue.html">The new Twitter homepage, now with 114% more blue</a><pre><{
  "path": "app/posts/2009-07-31-the-new-twitter-homepage-now-with-114-percent-more-blue.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The new Twitter homepage, now with 114% more blue",
      "date": "2009-07-31"
    },
    "source": "\n> Everyone has been submitting reviews of the new [Twitter](https://www.twitter.com) homepage. Most of them focus on usability or\nhow the brand will be affected with search being front and center. I'd like to forget all that for a moment and strictly focus on the most significant change\nof all: the addition of over 114% more blue on the new homepage. Yes, that's right, there's much more blue in the Twitter brand and I found it interesting to\ntake a look at some of the differences with a few screencaps.\n\nThe new homepage does indeed have a new logo and a radically different look than previously and without digging into that too much I'll just say this: I do like\nthe new look and feel. However, I do have to ask the question: \"Why so much more blue?\" Does the extra blue help or hinder? Is it too busy or does it help unify\nthings on the page more? What do you think?\n\n(Old site: 7 blues that I could count, New site: 16 blues!)\n\n![](/img/1158376-Picture%2014.png)\n![](/img/1158377-Picture%2015.png)\n"
  },
  "attributes": {
    "title": "The new Twitter homepage, now with 114% more blue",
    "date": "2009-07-31"
  },
  "markdown": "\n> Everyone has been submitting reviews of the new [Twitter](https://www.twitter.com) homepage. Most of them focus on usability or\nhow the brand will be affected with search being front and center. I'd like to forget all that for a moment and strictly focus on the most significant change\nof all: the addition of over 114% more blue on the new homepage. Yes, that's right, there's much more blue in the Twitter brand and I found it interesting to\ntake a look at some of the differences with a few screencaps.\n\nThe new homepage does indeed have a new logo and a radically different look than previously and without digging into that too much I'll just say this: I do like\nthe new look and feel. However, I do have to ask the question: \"Why so much more blue?\" Does the extra blue help or hinder? Is it too busy or does it help unify\nthings on the page more? What do you think?\n\n(Old site: 7 blues that I could count, New site: 16 blues!)\n\n![](/img/1158376-Picture%2014.png)\n![](/img/1158377-Picture%2015.png)\n"
}></{
  "path": "app/posts/2009-07-31-the-new-twitter-homepage-now-with-114-percent-more-blue.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "The new Twitter homepage, now with 114% more blue",
      "date": "2009-07-31"
    },
    "source": "\n> Everyone has been submitting reviews of the new [Twitter](https://www.twitter.com) homepage. Most of them focus on usability or\nhow the brand will be affected with search being front and center. I'd like to forget all that for a moment and strictly focus on the most significant change\nof all: the addition of over 114% more blue on the new homepage. Yes, that's right, there's much more blue in the Twitter brand and I found it interesting to\ntake a look at some of the differences with a few screencaps.\n\nThe new homepage does indeed have a new logo and a radically different look than previously and without digging into that too much I'll just say this: I do like\nthe new look and feel. However, I do have to ask the question: \"Why so much more blue?\" Does the extra blue help or hinder? Is it too busy or does it help unify\nthings on the page more? What do you think?\n\n(Old site: 7 blues that I could count, New site: 16 blues!)\n\n![](/img/1158376-Picture%2014.png)\n![](/img/1158377-Picture%2015.png)\n"
  },
  "attributes": {
    "title": "The new Twitter homepage, now with 114% more blue",
    "date": "2009-07-31"
  },
  "markdown": "\n> Everyone has been submitting reviews of the new [Twitter](https://www.twitter.com) homepage. Most of them focus on usability or\nhow the brand will be affected with search being front and center. I'd like to forget all that for a moment and strictly focus on the most significant change\nof all: the addition of over 114% more blue on the new homepage. Yes, that's right, there's much more blue in the Twitter brand and I found it interesting to\ntake a look at some of the differences with a few screencaps.\n\nThe new homepage does indeed have a new logo and a radically different look than previously and without digging into that too much I'll just say this: I do like\nthe new look and feel. However, I do have to ask the question: \"Why so much more blue?\" Does the extra blue help or hinder? Is it too busy or does it help unify\nthings on the page more? What do you think?\n\n(Old site: 7 blues that I could count, New site: 16 blues!)\n\n![](/img/1158376-Picture%2014.png)\n![](/img/1158377-Picture%2015.png)\n"
}></pre></div><div><a href="/posts/2009-07-08-usability-failures-in-the-wild-lego-and-petro-canada.html">Usability failures in the wild on lego.com</a><pre><{
  "path": "app/posts/2009-07-08-usability-failures-in-the-wild-lego-and-petro-canada.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Usability failures in the wild on lego.com",
      "date": "2009-07-08"
    },
    "source": "\n> I've been doing a lot of reading about usability. It's made me think a lot about the user experience when I'm designing and developing. It's also made me think a lot about the user experience when I'm *NOT* doing anything computer related.\n\nI recently went to the [Lego](www.lego.com) website to try and get a catalog sent to my house. I remember reading through these catalogs as a kid and coming\nup with all sorts of creative things I would be able to do when/if I received a certain set. Heck, half the fun for me was just looking at what the Lego designers had come up with. So yesterday I wanted to order a catalog for Andy, my 2.5 year old son, as he's been really enjoying our Lego collection. When I got to the last screen in the slideshow and tried to go back to re-enter my correct age, it wouldn't let me! It cookied me and I had to clear my cache to be able to re-enter the form information. **Grrr..**\n\n[Here's the [catalog request form](https://shop.lego.com/TermsPolicies/request_catalog.asp), so you don't have to hunt for it]\n\n![](/img/890217-Picture%208.png)\n![](/img/890218-Picture%209.png)\n![](/img/890219-Picture%2010.png)\n![](/img/890220-Picture%2011.png)\n![](/img/890221-Picture%2012.png)\n![](/img/890222-Picture%2013.png)\n![](/img/890223-Picture%2014.png)"
  },
  "attributes": {
    "title": "Usability failures in the wild on lego.com",
    "date": "2009-07-08"
  },
  "markdown": "\n> I've been doing a lot of reading about usability. It's made me think a lot about the user experience when I'm designing and developing. It's also made me think a lot about the user experience when I'm *NOT* doing anything computer related.\n\nI recently went to the [Lego](www.lego.com) website to try and get a catalog sent to my house. I remember reading through these catalogs as a kid and coming\nup with all sorts of creative things I would be able to do when/if I received a certain set. Heck, half the fun for me was just looking at what the Lego designers had come up with. So yesterday I wanted to order a catalog for Andy, my 2.5 year old son, as he's been really enjoying our Lego collection. When I got to the last screen in the slideshow and tried to go back to re-enter my correct age, it wouldn't let me! It cookied me and I had to clear my cache to be able to re-enter the form information. **Grrr..**\n\n[Here's the [catalog request form](https://shop.lego.com/TermsPolicies/request_catalog.asp), so you don't have to hunt for it]\n\n![](/img/890217-Picture%208.png)\n![](/img/890218-Picture%209.png)\n![](/img/890219-Picture%2010.png)\n![](/img/890220-Picture%2011.png)\n![](/img/890221-Picture%2012.png)\n![](/img/890222-Picture%2013.png)\n![](/img/890223-Picture%2014.png)"
}></{
  "path": "app/posts/2009-07-08-usability-failures-in-the-wild-lego-and-petro-canada.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Usability failures in the wild on lego.com",
      "date": "2009-07-08"
    },
    "source": "\n> I've been doing a lot of reading about usability. It's made me think a lot about the user experience when I'm designing and developing. It's also made me think a lot about the user experience when I'm *NOT* doing anything computer related.\n\nI recently went to the [Lego](www.lego.com) website to try and get a catalog sent to my house. I remember reading through these catalogs as a kid and coming\nup with all sorts of creative things I would be able to do when/if I received a certain set. Heck, half the fun for me was just looking at what the Lego designers had come up with. So yesterday I wanted to order a catalog for Andy, my 2.5 year old son, as he's been really enjoying our Lego collection. When I got to the last screen in the slideshow and tried to go back to re-enter my correct age, it wouldn't let me! It cookied me and I had to clear my cache to be able to re-enter the form information. **Grrr..**\n\n[Here's the [catalog request form](https://shop.lego.com/TermsPolicies/request_catalog.asp), so you don't have to hunt for it]\n\n![](/img/890217-Picture%208.png)\n![](/img/890218-Picture%209.png)\n![](/img/890219-Picture%2010.png)\n![](/img/890220-Picture%2011.png)\n![](/img/890221-Picture%2012.png)\n![](/img/890222-Picture%2013.png)\n![](/img/890223-Picture%2014.png)"
  },
  "attributes": {
    "title": "Usability failures in the wild on lego.com",
    "date": "2009-07-08"
  },
  "markdown": "\n> I've been doing a lot of reading about usability. It's made me think a lot about the user experience when I'm designing and developing. It's also made me think a lot about the user experience when I'm *NOT* doing anything computer related.\n\nI recently went to the [Lego](www.lego.com) website to try and get a catalog sent to my house. I remember reading through these catalogs as a kid and coming\nup with all sorts of creative things I would be able to do when/if I received a certain set. Heck, half the fun for me was just looking at what the Lego designers had come up with. So yesterday I wanted to order a catalog for Andy, my 2.5 year old son, as he's been really enjoying our Lego collection. When I got to the last screen in the slideshow and tried to go back to re-enter my correct age, it wouldn't let me! It cookied me and I had to clear my cache to be able to re-enter the form information. **Grrr..**\n\n[Here's the [catalog request form](https://shop.lego.com/TermsPolicies/request_catalog.asp), so you don't have to hunt for it]\n\n![](/img/890217-Picture%208.png)\n![](/img/890218-Picture%209.png)\n![](/img/890219-Picture%2010.png)\n![](/img/890220-Picture%2011.png)\n![](/img/890221-Picture%2012.png)\n![](/img/890222-Picture%2013.png)\n![](/img/890223-Picture%2014.png)"
}></pre></div><div><a href="/posts/2009-07-06-static-design-processes-lead-to-usability-failures.html">Static design processes lead to usability failures</a><pre><{
  "path": "app/posts/2009-07-06-static-design-processes-lead-to-usability-failures.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Static design processes lead to usability failures",
      "date": "2009-07-06"
    },
    "source": "\nSince my excursion to [AEA](https://www.aneventapart.com) '09 in Boston I've been doing a lot of thinking about all of this \"User Experience\" stuff. Much of what Andy Clarke said in his [Walls Come Tumbling Down presentation](https://www.forabeautifulweb.com/blog/about/walls_come_tumbling_down_presentation_slides_and_transcript/) has been ringing around in my head, resonating with so much of my experiences over the last few years. Without diving into the entire presentations coverage of the current economic situation being a stimulator for workflow process change, I want to focus on a few thoughts from 1 [slide](https://www.stuffandnonsense.co.uk/content/img/2009-06-26-020.jpg) in Andy's presentation.\n\n> **\"Designers work on static look and feel visuals\"**\n\nThere is a design disconnect problem when the medium we publish to (the web) doesn't match the medium we design in (static images). The web is dynamic, elastic, portable, modular and can be repurposed in any number of ways. Many web designers work in Photoshop and Fireworks to produce mockups that are static, rigid, not portable and often discarded after the initial design process. By designing in these static tools it is nearly impossible to answer the \"what if?\" type questions that we need to be asked in order to improve the efficiency of our design process and, most importantly, the usability of our websites and applications. What if the font size is increased by the user? How does that affect neighboring content? What happens if this column appears second in the markup? These things are all dynamic in nature and these questions cannot be effectively answered when the tool we use to produce mockups is static in nature.\n\n> **\"Designers and developers often work separately\"**\n\nI firmly believe that if we are to improve the user experience of our applications that designers and developers need to work in harmony from the very beginning. Traditional \"designer/ux\" work processes such as paper prototyping, white-boarding and lo-fidelity mockup construction should be participated in by developers. In fact, the entire design process needs to have input from both designer and developers in order to be successful. Far too often designers pitch concepts and hi-fidelity mockups \"over the wall\" to developers once things have been finalized, creating a disconnect between the two; this promotes division and resentment. Designers often don't understand the limitations that might be imposed given the technology that developers have been given to work with, and developers often don't understand the usability considerations that went into design decisions. Developers might have insight into usability based on past experience that can go unheard because they aren't included in the design process, and designers might know what the best way to develop a certain feature might be. (You can see how this could go on and on).\n\nIn a perfect world we'd all be designer/developers with the capability to have enough foresight to solve all these problems before they happen; unfortunately this is not a perfect world. I think the solution to this disconnect isn't that complicated though; mutual respect for each part of the process is a start. If design and development can co-exist with unburdened communication in the early stages of a project things will be in much better shape. Part of this has to do with breaking down the traditional barriers that seem to exist between these two disciplines, but I believe Kent Beck covers this [subject](https://www.threeriversinstitute.org/blog/?p=205) in much more elegance than I would.\n\n> **\"Testing, by users and for browsers and accessibility comes last\"**\n\nIt's interesting to me that the people we build websites and web applications for are often consulted last when it comes to design and usability considerations. Even when there are people on a project team who have usability experience it seems that \\_they\\_ are the ones consulted when really we should be pouring our initial efforts into getting feedback from potential users. It is so arrogant of us as designers/developers to make assumptions about what is \"best for the user\" without ever asking them. This can be a hard problem to tackle because many teams don't have dedicated testers and some teams utilize developers to do nearly all of the functional testing. Developers \\_can\\_ test, but they aren't the best testers in my opinion; developers are often working in an isolated area of a website/application and don't have the \"birds-eye view\" required to really understand how all of the components fit together. When developers are the primary people doing user/functional testing, and this testing comes at the end of an iteration it can lead to design implementations that often overlook simple usability problems.\n\nThese problems are all solvable, they just involve a lot of open communication and respect between developers and designers and the willingness to abandon processes that are based on static models. The web is dynamic and we should be in our design/development methods as well.\n"
  },
  "attributes": {
    "title": "Static design processes lead to usability failures",
    "date": "2009-07-06"
  },
  "markdown": "\nSince my excursion to [AEA](https://www.aneventapart.com) '09 in Boston I've been doing a lot of thinking about all of this \"User Experience\" stuff. Much of what Andy Clarke said in his [Walls Come Tumbling Down presentation](https://www.forabeautifulweb.com/blog/about/walls_come_tumbling_down_presentation_slides_and_transcript/) has been ringing around in my head, resonating with so much of my experiences over the last few years. Without diving into the entire presentations coverage of the current economic situation being a stimulator for workflow process change, I want to focus on a few thoughts from 1 [slide](https://www.stuffandnonsense.co.uk/content/img/2009-06-26-020.jpg) in Andy's presentation.\n\n> **\"Designers work on static look and feel visuals\"**\n\nThere is a design disconnect problem when the medium we publish to (the web) doesn't match the medium we design in (static images). The web is dynamic, elastic, portable, modular and can be repurposed in any number of ways. Many web designers work in Photoshop and Fireworks to produce mockups that are static, rigid, not portable and often discarded after the initial design process. By designing in these static tools it is nearly impossible to answer the \"what if?\" type questions that we need to be asked in order to improve the efficiency of our design process and, most importantly, the usability of our websites and applications. What if the font size is increased by the user? How does that affect neighboring content? What happens if this column appears second in the markup? These things are all dynamic in nature and these questions cannot be effectively answered when the tool we use to produce mockups is static in nature.\n\n> **\"Designers and developers often work separately\"**\n\nI firmly believe that if we are to improve the user experience of our applications that designers and developers need to work in harmony from the very beginning. Traditional \"designer/ux\" work processes such as paper prototyping, white-boarding and lo-fidelity mockup construction should be participated in by developers. In fact, the entire design process needs to have input from both designer and developers in order to be successful. Far too often designers pitch concepts and hi-fidelity mockups \"over the wall\" to developers once things have been finalized, creating a disconnect between the two; this promotes division and resentment. Designers often don't understand the limitations that might be imposed given the technology that developers have been given to work with, and developers often don't understand the usability considerations that went into design decisions. Developers might have insight into usability based on past experience that can go unheard because they aren't included in the design process, and designers might know what the best way to develop a certain feature might be. (You can see how this could go on and on).\n\nIn a perfect world we'd all be designer/developers with the capability to have enough foresight to solve all these problems before they happen; unfortunately this is not a perfect world. I think the solution to this disconnect isn't that complicated though; mutual respect for each part of the process is a start. If design and development can co-exist with unburdened communication in the early stages of a project things will be in much better shape. Part of this has to do with breaking down the traditional barriers that seem to exist between these two disciplines, but I believe Kent Beck covers this [subject](https://www.threeriversinstitute.org/blog/?p=205) in much more elegance than I would.\n\n> **\"Testing, by users and for browsers and accessibility comes last\"**\n\nIt's interesting to me that the people we build websites and web applications for are often consulted last when it comes to design and usability considerations. Even when there are people on a project team who have usability experience it seems that \\_they\\_ are the ones consulted when really we should be pouring our initial efforts into getting feedback from potential users. It is so arrogant of us as designers/developers to make assumptions about what is \"best for the user\" without ever asking them. This can be a hard problem to tackle because many teams don't have dedicated testers and some teams utilize developers to do nearly all of the functional testing. Developers \\_can\\_ test, but they aren't the best testers in my opinion; developers are often working in an isolated area of a website/application and don't have the \"birds-eye view\" required to really understand how all of the components fit together. When developers are the primary people doing user/functional testing, and this testing comes at the end of an iteration it can lead to design implementations that often overlook simple usability problems.\n\nThese problems are all solvable, they just involve a lot of open communication and respect between developers and designers and the willingness to abandon processes that are based on static models. The web is dynamic and we should be in our design/development methods as well.\n"
}></{
  "path": "app/posts/2009-07-06-static-design-processes-lead-to-usability-failures.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Static design processes lead to usability failures",
      "date": "2009-07-06"
    },
    "source": "\nSince my excursion to [AEA](https://www.aneventapart.com) '09 in Boston I've been doing a lot of thinking about all of this \"User Experience\" stuff. Much of what Andy Clarke said in his [Walls Come Tumbling Down presentation](https://www.forabeautifulweb.com/blog/about/walls_come_tumbling_down_presentation_slides_and_transcript/) has been ringing around in my head, resonating with so much of my experiences over the last few years. Without diving into the entire presentations coverage of the current economic situation being a stimulator for workflow process change, I want to focus on a few thoughts from 1 [slide](https://www.stuffandnonsense.co.uk/content/img/2009-06-26-020.jpg) in Andy's presentation.\n\n> **\"Designers work on static look and feel visuals\"**\n\nThere is a design disconnect problem when the medium we publish to (the web) doesn't match the medium we design in (static images). The web is dynamic, elastic, portable, modular and can be repurposed in any number of ways. Many web designers work in Photoshop and Fireworks to produce mockups that are static, rigid, not portable and often discarded after the initial design process. By designing in these static tools it is nearly impossible to answer the \"what if?\" type questions that we need to be asked in order to improve the efficiency of our design process and, most importantly, the usability of our websites and applications. What if the font size is increased by the user? How does that affect neighboring content? What happens if this column appears second in the markup? These things are all dynamic in nature and these questions cannot be effectively answered when the tool we use to produce mockups is static in nature.\n\n> **\"Designers and developers often work separately\"**\n\nI firmly believe that if we are to improve the user experience of our applications that designers and developers need to work in harmony from the very beginning. Traditional \"designer/ux\" work processes such as paper prototyping, white-boarding and lo-fidelity mockup construction should be participated in by developers. In fact, the entire design process needs to have input from both designer and developers in order to be successful. Far too often designers pitch concepts and hi-fidelity mockups \"over the wall\" to developers once things have been finalized, creating a disconnect between the two; this promotes division and resentment. Designers often don't understand the limitations that might be imposed given the technology that developers have been given to work with, and developers often don't understand the usability considerations that went into design decisions. Developers might have insight into usability based on past experience that can go unheard because they aren't included in the design process, and designers might know what the best way to develop a certain feature might be. (You can see how this could go on and on).\n\nIn a perfect world we'd all be designer/developers with the capability to have enough foresight to solve all these problems before they happen; unfortunately this is not a perfect world. I think the solution to this disconnect isn't that complicated though; mutual respect for each part of the process is a start. If design and development can co-exist with unburdened communication in the early stages of a project things will be in much better shape. Part of this has to do with breaking down the traditional barriers that seem to exist between these two disciplines, but I believe Kent Beck covers this [subject](https://www.threeriversinstitute.org/blog/?p=205) in much more elegance than I would.\n\n> **\"Testing, by users and for browsers and accessibility comes last\"**\n\nIt's interesting to me that the people we build websites and web applications for are often consulted last when it comes to design and usability considerations. Even when there are people on a project team who have usability experience it seems that \\_they\\_ are the ones consulted when really we should be pouring our initial efforts into getting feedback from potential users. It is so arrogant of us as designers/developers to make assumptions about what is \"best for the user\" without ever asking them. This can be a hard problem to tackle because many teams don't have dedicated testers and some teams utilize developers to do nearly all of the functional testing. Developers \\_can\\_ test, but they aren't the best testers in my opinion; developers are often working in an isolated area of a website/application and don't have the \"birds-eye view\" required to really understand how all of the components fit together. When developers are the primary people doing user/functional testing, and this testing comes at the end of an iteration it can lead to design implementations that often overlook simple usability problems.\n\nThese problems are all solvable, they just involve a lot of open communication and respect between developers and designers and the willingness to abandon processes that are based on static models. The web is dynamic and we should be in our design/development methods as well.\n"
  },
  "attributes": {
    "title": "Static design processes lead to usability failures",
    "date": "2009-07-06"
  },
  "markdown": "\nSince my excursion to [AEA](https://www.aneventapart.com) '09 in Boston I've been doing a lot of thinking about all of this \"User Experience\" stuff. Much of what Andy Clarke said in his [Walls Come Tumbling Down presentation](https://www.forabeautifulweb.com/blog/about/walls_come_tumbling_down_presentation_slides_and_transcript/) has been ringing around in my head, resonating with so much of my experiences over the last few years. Without diving into the entire presentations coverage of the current economic situation being a stimulator for workflow process change, I want to focus on a few thoughts from 1 [slide](https://www.stuffandnonsense.co.uk/content/img/2009-06-26-020.jpg) in Andy's presentation.\n\n> **\"Designers work on static look and feel visuals\"**\n\nThere is a design disconnect problem when the medium we publish to (the web) doesn't match the medium we design in (static images). The web is dynamic, elastic, portable, modular and can be repurposed in any number of ways. Many web designers work in Photoshop and Fireworks to produce mockups that are static, rigid, not portable and often discarded after the initial design process. By designing in these static tools it is nearly impossible to answer the \"what if?\" type questions that we need to be asked in order to improve the efficiency of our design process and, most importantly, the usability of our websites and applications. What if the font size is increased by the user? How does that affect neighboring content? What happens if this column appears second in the markup? These things are all dynamic in nature and these questions cannot be effectively answered when the tool we use to produce mockups is static in nature.\n\n> **\"Designers and developers often work separately\"**\n\nI firmly believe that if we are to improve the user experience of our applications that designers and developers need to work in harmony from the very beginning. Traditional \"designer/ux\" work processes such as paper prototyping, white-boarding and lo-fidelity mockup construction should be participated in by developers. In fact, the entire design process needs to have input from both designer and developers in order to be successful. Far too often designers pitch concepts and hi-fidelity mockups \"over the wall\" to developers once things have been finalized, creating a disconnect between the two; this promotes division and resentment. Designers often don't understand the limitations that might be imposed given the technology that developers have been given to work with, and developers often don't understand the usability considerations that went into design decisions. Developers might have insight into usability based on past experience that can go unheard because they aren't included in the design process, and designers might know what the best way to develop a certain feature might be. (You can see how this could go on and on).\n\nIn a perfect world we'd all be designer/developers with the capability to have enough foresight to solve all these problems before they happen; unfortunately this is not a perfect world. I think the solution to this disconnect isn't that complicated though; mutual respect for each part of the process is a start. If design and development can co-exist with unburdened communication in the early stages of a project things will be in much better shape. Part of this has to do with breaking down the traditional barriers that seem to exist between these two disciplines, but I believe Kent Beck covers this [subject](https://www.threeriversinstitute.org/blog/?p=205) in much more elegance than I would.\n\n> **\"Testing, by users and for browsers and accessibility comes last\"**\n\nIt's interesting to me that the people we build websites and web applications for are often consulted last when it comes to design and usability considerations. Even when there are people on a project team who have usability experience it seems that \\_they\\_ are the ones consulted when really we should be pouring our initial efforts into getting feedback from potential users. It is so arrogant of us as designers/developers to make assumptions about what is \"best for the user\" without ever asking them. This can be a hard problem to tackle because many teams don't have dedicated testers and some teams utilize developers to do nearly all of the functional testing. Developers \\_can\\_ test, but they aren't the best testers in my opinion; developers are often working in an isolated area of a website/application and don't have the \"birds-eye view\" required to really understand how all of the components fit together. When developers are the primary people doing user/functional testing, and this testing comes at the end of an iteration it can lead to design implementations that often overlook simple usability problems.\n\nThese problems are all solvable, they just involve a lot of open communication and respect between developers and designers and the willingness to abandon processes that are based on static models. The web is dynamic and we should be in our design/development methods as well.\n"
}></pre></div><div><a href="/posts/2009-06-24-aea-09-themes-and-perspective.html">An Event Apart 2009 - themes and perspective</a><pre><{
  "path": "app/posts/2009-06-24-aea-09-themes-and-perspective.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "An Event Apart 2009 - themes and perspective",
      "date": "2009-06-24"
    },
    "source": "\n> I'm sitting in Boston's Logan International Airport because my flight was delayed. Normally I'd be tired and cranky but I'm just tired;  the rest of me is so encouraged due to the emotional and motivational high I'm on after participating in [An Event Apart: Boston, 2009](https://www.aneventapart.com/2009/boston/).\n\nHaving not attended before, I arrived not knowing what to expect and was fairly intimidated by the number of people in attendance. My fear quickly dissipated after the first day of presentations and the opening night party, which brings me to the first of a couple themes I identified throughout the conference.\n\n## Connection\n\nThere was connection everywhere at AEA09; mobile devices, laptops, business cards, conversations and ideas that connected with each other to form a common framework for the event. The most important type of connection I participated in was personal interaction and meeting new people. At the opening night party I had the privilege to speak with some of the presenters including [Jeremy Keith](https://www.adactio.com) (@adactio), [Joshua Porter](https://www.bokardo.com) (@bokardo) and [Whitney Hess](https://www.whitneyhess.com) (@whitneyhess). All of them had really interesting things to say but what struck me was the common thread amongst them all: passion for the content, the standards, and the users. Even amongst non-presenters this seemed to be a common theme.\n\nThat evening I also had an engaging discussion with a Googler and two Facebook employees. We talked about MyFrontSteps and Homebook, development strategies, front-end unit testing, user experience and what the most successful types of social software are. An interesting point they raised was that the most successful applications are those that don't compete with what the Facebook platform currently offers users. I learned that Google and Facebook don't do any javascript unit testing. The Gmail team doesn't use GWT (as it was experimental when Gmail was being built). Facebook has a fairly small team of front end developers and 1 person was responsible for the Facebook iPhone application.\n\n## Pixel Perfection is Dead\n\nFor about a year now I've thought that being required to produce pixel perfect websites across so many different browsers is insane. This theme was definitely apparent throughout AEA09 as multiple presenters hammered this point across. It's almost like they wanted to really drill it into the attendees so that we can go back to our clients and continue to communicate the point.\n\n> [Dan Cederholm](https://www.simplebits.com), Jeremy Keith and [Andy Clarke](https://www.stuffandnonsense.co.uk/) all provided audience participation moments where they would yell \"[Do websites have to look the same in everybrowser?](https://dowebsitesneedtolookexactlythesameineverybrowser.com/)\" to which the crowd would emphatically (and sometimes, not so emphatically) respond **\"NO!\"**\n\nIt definitely seems like a touchy subject; at one point someone in the crowd shouted \"YES!\" because she was convinced that her clients could never be persuaded that this was the way to go. I think it's inevitable that web developers and designers are going to get to a turning point where supporting 8 or 9 browser rendering differences is just not going to be feasible to clients from a monetary point of view. As Andy Clarke put it during his presentation:\n\n> \"your clients will quit worrying about pixel perfection when you convince them of the value you can offer by producing more features that make them money in less time.\" -(rough paraphrase).\n\nThere was much talk of \"visual rewards\", basically offering the nice visual touches to the browsers that support them without worrying if IE looks good. Safari4, Firefox3.5 support border-radius, text-shadow, box-shadow and rgba; Internet Explorer doesn't. That's ok, IE can live without those flourishes because ultimately it's all about the content anyways, right? ;) In fact, Andy Clarke has gone as far as creating a [style sheet](https://forabeautifulweb.com/blog/about/universal_internet_explorer_6_css/) that can be fed to IE6 that strips away all substance except the text and\npositioning.\n\nPerhaps it would be more accurate to say that IE needs to die, but web developers have been saying that for years and it hasn't happened yet. We need to convince our clients that the time spent creating unsemantic markup and hacks to get things to work in IE just isn't worth it.\n\n## User Experience (UX) is Exploding\n\nUX, IA, IxD: all these terms seem fairly new to me but there were so many people at AEA09 who were involved with these disciplines in one way or another. The importance of these positions should NOT be underestimated. Interaction Design, in particular, is an area I feel is severely underrepresented in most organizations. So many times design teams produce static mockups in a very high-fidelity mode through applications like photoshop or fireworks without giving any consideration to user interaction.\n\n> It's virtually impossible to uncover problems with interaction usability through static mockups and often these issues are not extracted until late in the development process.\n\nThe solution is to start with a much lower-fidelity solution like paper prototypes and then possibly interactive html mockups. Once these have been created usability testing should be performed at each stage and iterations in design should be rapid. Too often usability testing happens at the end of the development process and this needs to change.\n\n[Whitney Hess](https://www.whitneyhess.com), a presenter and UX Engineer who I had the pleasure of meeting, encouraged me greatly in this area. Producing web interfaces that are clunky and unusable is a surefire way to limit revenue, but aside from the business concerns I feel that at the heart of UX there is a method to connect people with technology in ways that aren't limiting. I can't take full credit for that initial thought however, as a great conversation with [Matt Ventre](https://www.matthewventre.com/) is what really prompted me to see the true nature of UX. If anything, we should be producing web interfaces that focus on providing great content that is portable and formatted in a standards compliant way, housed in an interface that makes the entire experience seamless.\n\n## Epiblog\n\nI head back to Saskatoon with a sense of determination and optimism. An Event Apart is truly a special place, one that empowers people to spread the gospel of\nstandards, openness, user experience and excellent design. I think Andy Clarke is right when he says that we're in a transition time in the web development world. I tweeted the other day that I couldn't remember how I managed to develop before Firebug;\n\nI think it will be the same way 5 years from now except we'll be asking how we ever managed without making UX a priority ;)\n\n"
  },
  "attributes": {
    "title": "An Event Apart 2009 - themes and perspective",
    "date": "2009-06-24"
  },
  "markdown": "\n> I'm sitting in Boston's Logan International Airport because my flight was delayed. Normally I'd be tired and cranky but I'm just tired;  the rest of me is so encouraged due to the emotional and motivational high I'm on after participating in [An Event Apart: Boston, 2009](https://www.aneventapart.com/2009/boston/).\n\nHaving not attended before, I arrived not knowing what to expect and was fairly intimidated by the number of people in attendance. My fear quickly dissipated after the first day of presentations and the opening night party, which brings me to the first of a couple themes I identified throughout the conference.\n\n## Connection\n\nThere was connection everywhere at AEA09; mobile devices, laptops, business cards, conversations and ideas that connected with each other to form a common framework for the event. The most important type of connection I participated in was personal interaction and meeting new people. At the opening night party I had the privilege to speak with some of the presenters including [Jeremy Keith](https://www.adactio.com) (@adactio), [Joshua Porter](https://www.bokardo.com) (@bokardo) and [Whitney Hess](https://www.whitneyhess.com) (@whitneyhess). All of them had really interesting things to say but what struck me was the common thread amongst them all: passion for the content, the standards, and the users. Even amongst non-presenters this seemed to be a common theme.\n\nThat evening I also had an engaging discussion with a Googler and two Facebook employees. We talked about MyFrontSteps and Homebook, development strategies, front-end unit testing, user experience and what the most successful types of social software are. An interesting point they raised was that the most successful applications are those that don't compete with what the Facebook platform currently offers users. I learned that Google and Facebook don't do any javascript unit testing. The Gmail team doesn't use GWT (as it was experimental when Gmail was being built). Facebook has a fairly small team of front end developers and 1 person was responsible for the Facebook iPhone application.\n\n## Pixel Perfection is Dead\n\nFor about a year now I've thought that being required to produce pixel perfect websites across so many different browsers is insane. This theme was definitely apparent throughout AEA09 as multiple presenters hammered this point across. It's almost like they wanted to really drill it into the attendees so that we can go back to our clients and continue to communicate the point.\n\n> [Dan Cederholm](https://www.simplebits.com), Jeremy Keith and [Andy Clarke](https://www.stuffandnonsense.co.uk/) all provided audience participation moments where they would yell \"[Do websites have to look the same in everybrowser?](https://dowebsitesneedtolookexactlythesameineverybrowser.com/)\" to which the crowd would emphatically (and sometimes, not so emphatically) respond **\"NO!\"**\n\nIt definitely seems like a touchy subject; at one point someone in the crowd shouted \"YES!\" because she was convinced that her clients could never be persuaded that this was the way to go. I think it's inevitable that web developers and designers are going to get to a turning point where supporting 8 or 9 browser rendering differences is just not going to be feasible to clients from a monetary point of view. As Andy Clarke put it during his presentation:\n\n> \"your clients will quit worrying about pixel perfection when you convince them of the value you can offer by producing more features that make them money in less time.\" -(rough paraphrase).\n\nThere was much talk of \"visual rewards\", basically offering the nice visual touches to the browsers that support them without worrying if IE looks good. Safari4, Firefox3.5 support border-radius, text-shadow, box-shadow and rgba; Internet Explorer doesn't. That's ok, IE can live without those flourishes because ultimately it's all about the content anyways, right? ;) In fact, Andy Clarke has gone as far as creating a [style sheet](https://forabeautifulweb.com/blog/about/universal_internet_explorer_6_css/) that can be fed to IE6 that strips away all substance except the text and\npositioning.\n\nPerhaps it would be more accurate to say that IE needs to die, but web developers have been saying that for years and it hasn't happened yet. We need to convince our clients that the time spent creating unsemantic markup and hacks to get things to work in IE just isn't worth it.\n\n## User Experience (UX) is Exploding\n\nUX, IA, IxD: all these terms seem fairly new to me but there were so many people at AEA09 who were involved with these disciplines in one way or another. The importance of these positions should NOT be underestimated. Interaction Design, in particular, is an area I feel is severely underrepresented in most organizations. So many times design teams produce static mockups in a very high-fidelity mode through applications like photoshop or fireworks without giving any consideration to user interaction.\n\n> It's virtually impossible to uncover problems with interaction usability through static mockups and often these issues are not extracted until late in the development process.\n\nThe solution is to start with a much lower-fidelity solution like paper prototypes and then possibly interactive html mockups. Once these have been created usability testing should be performed at each stage and iterations in design should be rapid. Too often usability testing happens at the end of the development process and this needs to change.\n\n[Whitney Hess](https://www.whitneyhess.com), a presenter and UX Engineer who I had the pleasure of meeting, encouraged me greatly in this area. Producing web interfaces that are clunky and unusable is a surefire way to limit revenue, but aside from the business concerns I feel that at the heart of UX there is a method to connect people with technology in ways that aren't limiting. I can't take full credit for that initial thought however, as a great conversation with [Matt Ventre](https://www.matthewventre.com/) is what really prompted me to see the true nature of UX. If anything, we should be producing web interfaces that focus on providing great content that is portable and formatted in a standards compliant way, housed in an interface that makes the entire experience seamless.\n\n## Epiblog\n\nI head back to Saskatoon with a sense of determination and optimism. An Event Apart is truly a special place, one that empowers people to spread the gospel of\nstandards, openness, user experience and excellent design. I think Andy Clarke is right when he says that we're in a transition time in the web development world. I tweeted the other day that I couldn't remember how I managed to develop before Firebug;\n\nI think it will be the same way 5 years from now except we'll be asking how we ever managed without making UX a priority ;)\n\n"
}></{
  "path": "app/posts/2009-06-24-aea-09-themes-and-perspective.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "An Event Apart 2009 - themes and perspective",
      "date": "2009-06-24"
    },
    "source": "\n> I'm sitting in Boston's Logan International Airport because my flight was delayed. Normally I'd be tired and cranky but I'm just tired;  the rest of me is so encouraged due to the emotional and motivational high I'm on after participating in [An Event Apart: Boston, 2009](https://www.aneventapart.com/2009/boston/).\n\nHaving not attended before, I arrived not knowing what to expect and was fairly intimidated by the number of people in attendance. My fear quickly dissipated after the first day of presentations and the opening night party, which brings me to the first of a couple themes I identified throughout the conference.\n\n## Connection\n\nThere was connection everywhere at AEA09; mobile devices, laptops, business cards, conversations and ideas that connected with each other to form a common framework for the event. The most important type of connection I participated in was personal interaction and meeting new people. At the opening night party I had the privilege to speak with some of the presenters including [Jeremy Keith](https://www.adactio.com) (@adactio), [Joshua Porter](https://www.bokardo.com) (@bokardo) and [Whitney Hess](https://www.whitneyhess.com) (@whitneyhess). All of them had really interesting things to say but what struck me was the common thread amongst them all: passion for the content, the standards, and the users. Even amongst non-presenters this seemed to be a common theme.\n\nThat evening I also had an engaging discussion with a Googler and two Facebook employees. We talked about MyFrontSteps and Homebook, development strategies, front-end unit testing, user experience and what the most successful types of social software are. An interesting point they raised was that the most successful applications are those that don't compete with what the Facebook platform currently offers users. I learned that Google and Facebook don't do any javascript unit testing. The Gmail team doesn't use GWT (as it was experimental when Gmail was being built). Facebook has a fairly small team of front end developers and 1 person was responsible for the Facebook iPhone application.\n\n## Pixel Perfection is Dead\n\nFor about a year now I've thought that being required to produce pixel perfect websites across so many different browsers is insane. This theme was definitely apparent throughout AEA09 as multiple presenters hammered this point across. It's almost like they wanted to really drill it into the attendees so that we can go back to our clients and continue to communicate the point.\n\n> [Dan Cederholm](https://www.simplebits.com), Jeremy Keith and [Andy Clarke](https://www.stuffandnonsense.co.uk/) all provided audience participation moments where they would yell \"[Do websites have to look the same in everybrowser?](https://dowebsitesneedtolookexactlythesameineverybrowser.com/)\" to which the crowd would emphatically (and sometimes, not so emphatically) respond **\"NO!\"**\n\nIt definitely seems like a touchy subject; at one point someone in the crowd shouted \"YES!\" because she was convinced that her clients could never be persuaded that this was the way to go. I think it's inevitable that web developers and designers are going to get to a turning point where supporting 8 or 9 browser rendering differences is just not going to be feasible to clients from a monetary point of view. As Andy Clarke put it during his presentation:\n\n> \"your clients will quit worrying about pixel perfection when you convince them of the value you can offer by producing more features that make them money in less time.\" -(rough paraphrase).\n\nThere was much talk of \"visual rewards\", basically offering the nice visual touches to the browsers that support them without worrying if IE looks good. Safari4, Firefox3.5 support border-radius, text-shadow, box-shadow and rgba; Internet Explorer doesn't. That's ok, IE can live without those flourishes because ultimately it's all about the content anyways, right? ;) In fact, Andy Clarke has gone as far as creating a [style sheet](https://forabeautifulweb.com/blog/about/universal_internet_explorer_6_css/) that can be fed to IE6 that strips away all substance except the text and\npositioning.\n\nPerhaps it would be more accurate to say that IE needs to die, but web developers have been saying that for years and it hasn't happened yet. We need to convince our clients that the time spent creating unsemantic markup and hacks to get things to work in IE just isn't worth it.\n\n## User Experience (UX) is Exploding\n\nUX, IA, IxD: all these terms seem fairly new to me but there were so many people at AEA09 who were involved with these disciplines in one way or another. The importance of these positions should NOT be underestimated. Interaction Design, in particular, is an area I feel is severely underrepresented in most organizations. So many times design teams produce static mockups in a very high-fidelity mode through applications like photoshop or fireworks without giving any consideration to user interaction.\n\n> It's virtually impossible to uncover problems with interaction usability through static mockups and often these issues are not extracted until late in the development process.\n\nThe solution is to start with a much lower-fidelity solution like paper prototypes and then possibly interactive html mockups. Once these have been created usability testing should be performed at each stage and iterations in design should be rapid. Too often usability testing happens at the end of the development process and this needs to change.\n\n[Whitney Hess](https://www.whitneyhess.com), a presenter and UX Engineer who I had the pleasure of meeting, encouraged me greatly in this area. Producing web interfaces that are clunky and unusable is a surefire way to limit revenue, but aside from the business concerns I feel that at the heart of UX there is a method to connect people with technology in ways that aren't limiting. I can't take full credit for that initial thought however, as a great conversation with [Matt Ventre](https://www.matthewventre.com/) is what really prompted me to see the true nature of UX. If anything, we should be producing web interfaces that focus on providing great content that is portable and formatted in a standards compliant way, housed in an interface that makes the entire experience seamless.\n\n## Epiblog\n\nI head back to Saskatoon with a sense of determination and optimism. An Event Apart is truly a special place, one that empowers people to spread the gospel of\nstandards, openness, user experience and excellent design. I think Andy Clarke is right when he says that we're in a transition time in the web development world. I tweeted the other day that I couldn't remember how I managed to develop before Firebug;\n\nI think it will be the same way 5 years from now except we'll be asking how we ever managed without making UX a priority ;)\n\n"
  },
  "attributes": {
    "title": "An Event Apart 2009 - themes and perspective",
    "date": "2009-06-24"
  },
  "markdown": "\n> I'm sitting in Boston's Logan International Airport because my flight was delayed. Normally I'd be tired and cranky but I'm just tired;  the rest of me is so encouraged due to the emotional and motivational high I'm on after participating in [An Event Apart: Boston, 2009](https://www.aneventapart.com/2009/boston/).\n\nHaving not attended before, I arrived not knowing what to expect and was fairly intimidated by the number of people in attendance. My fear quickly dissipated after the first day of presentations and the opening night party, which brings me to the first of a couple themes I identified throughout the conference.\n\n## Connection\n\nThere was connection everywhere at AEA09; mobile devices, laptops, business cards, conversations and ideas that connected with each other to form a common framework for the event. The most important type of connection I participated in was personal interaction and meeting new people. At the opening night party I had the privilege to speak with some of the presenters including [Jeremy Keith](https://www.adactio.com) (@adactio), [Joshua Porter](https://www.bokardo.com) (@bokardo) and [Whitney Hess](https://www.whitneyhess.com) (@whitneyhess). All of them had really interesting things to say but what struck me was the common thread amongst them all: passion for the content, the standards, and the users. Even amongst non-presenters this seemed to be a common theme.\n\nThat evening I also had an engaging discussion with a Googler and two Facebook employees. We talked about MyFrontSteps and Homebook, development strategies, front-end unit testing, user experience and what the most successful types of social software are. An interesting point they raised was that the most successful applications are those that don't compete with what the Facebook platform currently offers users. I learned that Google and Facebook don't do any javascript unit testing. The Gmail team doesn't use GWT (as it was experimental when Gmail was being built). Facebook has a fairly small team of front end developers and 1 person was responsible for the Facebook iPhone application.\n\n## Pixel Perfection is Dead\n\nFor about a year now I've thought that being required to produce pixel perfect websites across so many different browsers is insane. This theme was definitely apparent throughout AEA09 as multiple presenters hammered this point across. It's almost like they wanted to really drill it into the attendees so that we can go back to our clients and continue to communicate the point.\n\n> [Dan Cederholm](https://www.simplebits.com), Jeremy Keith and [Andy Clarke](https://www.stuffandnonsense.co.uk/) all provided audience participation moments where they would yell \"[Do websites have to look the same in everybrowser?](https://dowebsitesneedtolookexactlythesameineverybrowser.com/)\" to which the crowd would emphatically (and sometimes, not so emphatically) respond **\"NO!\"**\n\nIt definitely seems like a touchy subject; at one point someone in the crowd shouted \"YES!\" because she was convinced that her clients could never be persuaded that this was the way to go. I think it's inevitable that web developers and designers are going to get to a turning point where supporting 8 or 9 browser rendering differences is just not going to be feasible to clients from a monetary point of view. As Andy Clarke put it during his presentation:\n\n> \"your clients will quit worrying about pixel perfection when you convince them of the value you can offer by producing more features that make them money in less time.\" -(rough paraphrase).\n\nThere was much talk of \"visual rewards\", basically offering the nice visual touches to the browsers that support them without worrying if IE looks good. Safari4, Firefox3.5 support border-radius, text-shadow, box-shadow and rgba; Internet Explorer doesn't. That's ok, IE can live without those flourishes because ultimately it's all about the content anyways, right? ;) In fact, Andy Clarke has gone as far as creating a [style sheet](https://forabeautifulweb.com/blog/about/universal_internet_explorer_6_css/) that can be fed to IE6 that strips away all substance except the text and\npositioning.\n\nPerhaps it would be more accurate to say that IE needs to die, but web developers have been saying that for years and it hasn't happened yet. We need to convince our clients that the time spent creating unsemantic markup and hacks to get things to work in IE just isn't worth it.\n\n## User Experience (UX) is Exploding\n\nUX, IA, IxD: all these terms seem fairly new to me but there were so many people at AEA09 who were involved with these disciplines in one way or another. The importance of these positions should NOT be underestimated. Interaction Design, in particular, is an area I feel is severely underrepresented in most organizations. So many times design teams produce static mockups in a very high-fidelity mode through applications like photoshop or fireworks without giving any consideration to user interaction.\n\n> It's virtually impossible to uncover problems with interaction usability through static mockups and often these issues are not extracted until late in the development process.\n\nThe solution is to start with a much lower-fidelity solution like paper prototypes and then possibly interactive html mockups. Once these have been created usability testing should be performed at each stage and iterations in design should be rapid. Too often usability testing happens at the end of the development process and this needs to change.\n\n[Whitney Hess](https://www.whitneyhess.com), a presenter and UX Engineer who I had the pleasure of meeting, encouraged me greatly in this area. Producing web interfaces that are clunky and unusable is a surefire way to limit revenue, but aside from the business concerns I feel that at the heart of UX there is a method to connect people with technology in ways that aren't limiting. I can't take full credit for that initial thought however, as a great conversation with [Matt Ventre](https://www.matthewventre.com/) is what really prompted me to see the true nature of UX. If anything, we should be producing web interfaces that focus on providing great content that is portable and formatted in a standards compliant way, housed in an interface that makes the entire experience seamless.\n\n## Epiblog\n\nI head back to Saskatoon with a sense of determination and optimism. An Event Apart is truly a special place, one that empowers people to spread the gospel of\nstandards, openness, user experience and excellent design. I think Andy Clarke is right when he says that we're in a transition time in the web development world. I tweeted the other day that I couldn't remember how I managed to develop before Firebug;\n\nI think it will be the same way 5 years from now except we'll be asking how we ever managed without making UX a priority ;)\n\n"
}></pre></div><div><a href="/posts/2009-04-06-yahoo-pipes-at-vendasta.html">Yahoo Pipes at VendAsta</a><pre><{
  "path": "app/posts/2009-04-06-yahoo-pipes-at-vendasta.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Yahoo Pipes at VendAsta",
      "date": "2009-06-24"
    },
    "source": "\n> **Note**: this post was originally started in September/November, 2008. It's\nbeen sitting in my drafts for quite a while and I decided it was time to finish\nit up.\n\nWe finished off a short 1 week development sprint last Friday [edit: sometime in Sep/Nov 2008] which culminated in the current live version of the [VendAsta](https://www.vendasta.com) website. Despite such a short dev-cycle, I feel we were able to accomplish most of our research goals.\n\nOne of the tools we used that I didn't have much experience with prior was [Yahoo Pipes](https://pipes.yahoo.com). We had somewhat of a unique problem to solve; we wanted to be able to draw from a variety of Feed sources that would filter through to different sections of the site. Before I dove into using Pipes my gut feeling was just to use some sort of feed parsing library in Python that was compatible with AppEngine. One of the requirements for implementing the feed sources was that it be very easy to update should a feed need to be changed. If we stuck with the Python library implementation and statically coded some feed\nsources, changes would take significantly more overhead to implement.\n\nWe started investigating Pipes as a platform to aggregate all of the content we wanted to re-publish and were impressed by what we found. It turns out that the Pipes interface is much better at providing an easy-to-update set of feed sources for non-programmers. If you haven't looked at the Pipes interface I highly recommend you do so. I think Pipes offers so much advanced filtering and splicing functionality in a really tight package, so I'll attempt to break down some of the modules we used specifically for the VendAsta website.\n\n![A screenshot of the Yahoo Pipes interface](/img/yahoo-pipes-at-vendasta/v-blogroll.png)\n\nThe image above is a shot of the Pipes interface, and more specifically the Pipe that we use to aggregate all of the feed-based content on the VendAsta website. I should clarify, by feed-based content I'm referring to all of the official employee, product, and corporate blogs. Yes you read that right, employee blog posts (when tagged appropriately) end up on our corporate website. But let's set aside the trust/ethical issues related to that and focus on the technology we're\nusing. There are a few components to the root pipe we use to collect all this content, and the Pipes documentation isn't always entirely clear on the best way to use things, so I will attempt to decompose it and discuss each module in detail.\n\n## Feed Auto-Discovery\n\n![Feed Auto-Discovery](/img/yahoo-pipes-at-vendasta/feed-auto-discovery.png)\n\nWe have a URL mounted on VendAsta.com that provides only 1 function: spitting out a list of link tags in the following format:\n\n```html\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Dave Mosher\" href=\"https://www.davemo.com\">\n```\n\nInternally, we store a list of all employees with some meta information like blogURL, linkedinURL etc. This url is what we provide to the auto-discovery module so it can do it's magic and go out to all of the rss+xml links and gather a list of feeds from the blogs. Here's a sample of the output you get from this URL in the Pipes debug console.\n\n![Feed Auto-Discovery Output](/img/yahoo-pipes-at-vendasta/feed-auto-discovery-output.png)\n\nOnce we have this list of blogs and the links to them, we can pass the output from the auto-discovery module on to the Loop + Fetch Site Feed modules.\n\n## Loop + Fetch Site Feed\n\nThe loop module is pretty self explanatory, you use it when you want to iterate over a group of results and operate on them somehow. It's kind of similar to providing an AJAX onSuccess callback; you send out a request for the content (the iteration) and you define a 'callback' by dragging a supporting pipes function into the available box to process each item. In our case, we're using the Fetch Site Feed module from the toolbox to snag a feed from each site in our blogroll. We configure the module to emit all results to our next module, the Filter, which does most of the magic in determining which content ends up on the corporate website.\n\n![Pipes Loop + Fetch Site Feed Modules](/img/yahoo-pipes-at-vendasta/picture-3.png)\n\n## Filter\n\nThe filter module works really well for grabbing a set of elements based on a certain set of criteria; in our case we use the Regexp option to explicitly allow any content with the tag/category 'VendAsta'.\n\n![The Filter Module](/img/yahoo-pipes-at-vendasta/picture-4.png)\n\n## Union, Sort, Rename + Pipe Output\n\nThe final layer of our pipe involves combining results from some other static sources independent of filters (VendAsta blog and the StepRep blog), sorting them based on the date published descending, renaming a specific RSS feed field (item.dc:creator) to 'author' to fix a problem in the feed reading library we're using server side (feedparser.py) and finally the output of all these operations: 'Pipe Output' module. All these modules are really easy to string together with the Pipes interface and are clickable at any point during the creation which will toggle the debug output to stop at the currently selected module. This is very useful for seeing what the modules you are using do at each step of the process.\n\n![Union Sort Rename and Pipe Output Modules](/img/yahoo-pipes-at-vendasta/picture-51.png)\n\n## Pipes as abstract components ties it all together\n\nSo now that we have a completed Pipes module, we can do a number of things with it. We can get the output in RSS or JSON format, define a custom url for the pipe, and even give it a name and make it public so other people can use it in their mashups. However, the coolest feature IMHO is that you can use any created pipes module as an abstracted pipes component on it's own which can be part of another pipes component that you can then perform further operations on. We chose to separate a few of the layers in our feed hierarchy this way for simplicity sake and to keep it loosely coupled if we wanted to make changes to what feeds appear on certain pages. Here's an example of our previous Blogroll pipe being used as input for further filtering and display on 1 section of the VendAsta website: the [Projects](https://www.vendasta.com/projects/) page.\n\n![The blogroll pipe as input](/img/yahoo-pipes-at-vendasta/picture-6.png)\n"
  },
  "attributes": {
    "title": "Yahoo Pipes at VendAsta",
    "date": "2009-06-24"
  },
  "markdown": "\n> **Note**: this post was originally started in September/November, 2008. It's\nbeen sitting in my drafts for quite a while and I decided it was time to finish\nit up.\n\nWe finished off a short 1 week development sprint last Friday [edit: sometime in Sep/Nov 2008] which culminated in the current live version of the [VendAsta](https://www.vendasta.com) website. Despite such a short dev-cycle, I feel we were able to accomplish most of our research goals.\n\nOne of the tools we used that I didn't have much experience with prior was [Yahoo Pipes](https://pipes.yahoo.com). We had somewhat of a unique problem to solve; we wanted to be able to draw from a variety of Feed sources that would filter through to different sections of the site. Before I dove into using Pipes my gut feeling was just to use some sort of feed parsing library in Python that was compatible with AppEngine. One of the requirements for implementing the feed sources was that it be very easy to update should a feed need to be changed. If we stuck with the Python library implementation and statically coded some feed\nsources, changes would take significantly more overhead to implement.\n\nWe started investigating Pipes as a platform to aggregate all of the content we wanted to re-publish and were impressed by what we found. It turns out that the Pipes interface is much better at providing an easy-to-update set of feed sources for non-programmers. If you haven't looked at the Pipes interface I highly recommend you do so. I think Pipes offers so much advanced filtering and splicing functionality in a really tight package, so I'll attempt to break down some of the modules we used specifically for the VendAsta website.\n\n![A screenshot of the Yahoo Pipes interface](/img/yahoo-pipes-at-vendasta/v-blogroll.png)\n\nThe image above is a shot of the Pipes interface, and more specifically the Pipe that we use to aggregate all of the feed-based content on the VendAsta website. I should clarify, by feed-based content I'm referring to all of the official employee, product, and corporate blogs. Yes you read that right, employee blog posts (when tagged appropriately) end up on our corporate website. But let's set aside the trust/ethical issues related to that and focus on the technology we're\nusing. There are a few components to the root pipe we use to collect all this content, and the Pipes documentation isn't always entirely clear on the best way to use things, so I will attempt to decompose it and discuss each module in detail.\n\n## Feed Auto-Discovery\n\n![Feed Auto-Discovery](/img/yahoo-pipes-at-vendasta/feed-auto-discovery.png)\n\nWe have a URL mounted on VendAsta.com that provides only 1 function: spitting out a list of link tags in the following format:\n\n```html\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Dave Mosher\" href=\"https://www.davemo.com\">\n```\n\nInternally, we store a list of all employees with some meta information like blogURL, linkedinURL etc. This url is what we provide to the auto-discovery module so it can do it's magic and go out to all of the rss+xml links and gather a list of feeds from the blogs. Here's a sample of the output you get from this URL in the Pipes debug console.\n\n![Feed Auto-Discovery Output](/img/yahoo-pipes-at-vendasta/feed-auto-discovery-output.png)\n\nOnce we have this list of blogs and the links to them, we can pass the output from the auto-discovery module on to the Loop + Fetch Site Feed modules.\n\n## Loop + Fetch Site Feed\n\nThe loop module is pretty self explanatory, you use it when you want to iterate over a group of results and operate on them somehow. It's kind of similar to providing an AJAX onSuccess callback; you send out a request for the content (the iteration) and you define a 'callback' by dragging a supporting pipes function into the available box to process each item. In our case, we're using the Fetch Site Feed module from the toolbox to snag a feed from each site in our blogroll. We configure the module to emit all results to our next module, the Filter, which does most of the magic in determining which content ends up on the corporate website.\n\n![Pipes Loop + Fetch Site Feed Modules](/img/yahoo-pipes-at-vendasta/picture-3.png)\n\n## Filter\n\nThe filter module works really well for grabbing a set of elements based on a certain set of criteria; in our case we use the Regexp option to explicitly allow any content with the tag/category 'VendAsta'.\n\n![The Filter Module](/img/yahoo-pipes-at-vendasta/picture-4.png)\n\n## Union, Sort, Rename + Pipe Output\n\nThe final layer of our pipe involves combining results from some other static sources independent of filters (VendAsta blog and the StepRep blog), sorting them based on the date published descending, renaming a specific RSS feed field (item.dc:creator) to 'author' to fix a problem in the feed reading library we're using server side (feedparser.py) and finally the output of all these operations: 'Pipe Output' module. All these modules are really easy to string together with the Pipes interface and are clickable at any point during the creation which will toggle the debug output to stop at the currently selected module. This is very useful for seeing what the modules you are using do at each step of the process.\n\n![Union Sort Rename and Pipe Output Modules](/img/yahoo-pipes-at-vendasta/picture-51.png)\n\n## Pipes as abstract components ties it all together\n\nSo now that we have a completed Pipes module, we can do a number of things with it. We can get the output in RSS or JSON format, define a custom url for the pipe, and even give it a name and make it public so other people can use it in their mashups. However, the coolest feature IMHO is that you can use any created pipes module as an abstracted pipes component on it's own which can be part of another pipes component that you can then perform further operations on. We chose to separate a few of the layers in our feed hierarchy this way for simplicity sake and to keep it loosely coupled if we wanted to make changes to what feeds appear on certain pages. Here's an example of our previous Blogroll pipe being used as input for further filtering and display on 1 section of the VendAsta website: the [Projects](https://www.vendasta.com/projects/) page.\n\n![The blogroll pipe as input](/img/yahoo-pipes-at-vendasta/picture-6.png)\n"
}></{
  "path": "app/posts/2009-04-06-yahoo-pipes-at-vendasta.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Yahoo Pipes at VendAsta",
      "date": "2009-06-24"
    },
    "source": "\n> **Note**: this post was originally started in September/November, 2008. It's\nbeen sitting in my drafts for quite a while and I decided it was time to finish\nit up.\n\nWe finished off a short 1 week development sprint last Friday [edit: sometime in Sep/Nov 2008] which culminated in the current live version of the [VendAsta](https://www.vendasta.com) website. Despite such a short dev-cycle, I feel we were able to accomplish most of our research goals.\n\nOne of the tools we used that I didn't have much experience with prior was [Yahoo Pipes](https://pipes.yahoo.com). We had somewhat of a unique problem to solve; we wanted to be able to draw from a variety of Feed sources that would filter through to different sections of the site. Before I dove into using Pipes my gut feeling was just to use some sort of feed parsing library in Python that was compatible with AppEngine. One of the requirements for implementing the feed sources was that it be very easy to update should a feed need to be changed. If we stuck with the Python library implementation and statically coded some feed\nsources, changes would take significantly more overhead to implement.\n\nWe started investigating Pipes as a platform to aggregate all of the content we wanted to re-publish and were impressed by what we found. It turns out that the Pipes interface is much better at providing an easy-to-update set of feed sources for non-programmers. If you haven't looked at the Pipes interface I highly recommend you do so. I think Pipes offers so much advanced filtering and splicing functionality in a really tight package, so I'll attempt to break down some of the modules we used specifically for the VendAsta website.\n\n![A screenshot of the Yahoo Pipes interface](/img/yahoo-pipes-at-vendasta/v-blogroll.png)\n\nThe image above is a shot of the Pipes interface, and more specifically the Pipe that we use to aggregate all of the feed-based content on the VendAsta website. I should clarify, by feed-based content I'm referring to all of the official employee, product, and corporate blogs. Yes you read that right, employee blog posts (when tagged appropriately) end up on our corporate website. But let's set aside the trust/ethical issues related to that and focus on the technology we're\nusing. There are a few components to the root pipe we use to collect all this content, and the Pipes documentation isn't always entirely clear on the best way to use things, so I will attempt to decompose it and discuss each module in detail.\n\n## Feed Auto-Discovery\n\n![Feed Auto-Discovery](/img/yahoo-pipes-at-vendasta/feed-auto-discovery.png)\n\nWe have a URL mounted on VendAsta.com that provides only 1 function: spitting out a list of link tags in the following format:\n\n```html\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Dave Mosher\" href=\"https://www.davemo.com\">\n```\n\nInternally, we store a list of all employees with some meta information like blogURL, linkedinURL etc. This url is what we provide to the auto-discovery module so it can do it's magic and go out to all of the rss+xml links and gather a list of feeds from the blogs. Here's a sample of the output you get from this URL in the Pipes debug console.\n\n![Feed Auto-Discovery Output](/img/yahoo-pipes-at-vendasta/feed-auto-discovery-output.png)\n\nOnce we have this list of blogs and the links to them, we can pass the output from the auto-discovery module on to the Loop + Fetch Site Feed modules.\n\n## Loop + Fetch Site Feed\n\nThe loop module is pretty self explanatory, you use it when you want to iterate over a group of results and operate on them somehow. It's kind of similar to providing an AJAX onSuccess callback; you send out a request for the content (the iteration) and you define a 'callback' by dragging a supporting pipes function into the available box to process each item. In our case, we're using the Fetch Site Feed module from the toolbox to snag a feed from each site in our blogroll. We configure the module to emit all results to our next module, the Filter, which does most of the magic in determining which content ends up on the corporate website.\n\n![Pipes Loop + Fetch Site Feed Modules](/img/yahoo-pipes-at-vendasta/picture-3.png)\n\n## Filter\n\nThe filter module works really well for grabbing a set of elements based on a certain set of criteria; in our case we use the Regexp option to explicitly allow any content with the tag/category 'VendAsta'.\n\n![The Filter Module](/img/yahoo-pipes-at-vendasta/picture-4.png)\n\n## Union, Sort, Rename + Pipe Output\n\nThe final layer of our pipe involves combining results from some other static sources independent of filters (VendAsta blog and the StepRep blog), sorting them based on the date published descending, renaming a specific RSS feed field (item.dc:creator) to 'author' to fix a problem in the feed reading library we're using server side (feedparser.py) and finally the output of all these operations: 'Pipe Output' module. All these modules are really easy to string together with the Pipes interface and are clickable at any point during the creation which will toggle the debug output to stop at the currently selected module. This is very useful for seeing what the modules you are using do at each step of the process.\n\n![Union Sort Rename and Pipe Output Modules](/img/yahoo-pipes-at-vendasta/picture-51.png)\n\n## Pipes as abstract components ties it all together\n\nSo now that we have a completed Pipes module, we can do a number of things with it. We can get the output in RSS or JSON format, define a custom url for the pipe, and even give it a name and make it public so other people can use it in their mashups. However, the coolest feature IMHO is that you can use any created pipes module as an abstracted pipes component on it's own which can be part of another pipes component that you can then perform further operations on. We chose to separate a few of the layers in our feed hierarchy this way for simplicity sake and to keep it loosely coupled if we wanted to make changes to what feeds appear on certain pages. Here's an example of our previous Blogroll pipe being used as input for further filtering and display on 1 section of the VendAsta website: the [Projects](https://www.vendasta.com/projects/) page.\n\n![The blogroll pipe as input](/img/yahoo-pipes-at-vendasta/picture-6.png)\n"
  },
  "attributes": {
    "title": "Yahoo Pipes at VendAsta",
    "date": "2009-06-24"
  },
  "markdown": "\n> **Note**: this post was originally started in September/November, 2008. It's\nbeen sitting in my drafts for quite a while and I decided it was time to finish\nit up.\n\nWe finished off a short 1 week development sprint last Friday [edit: sometime in Sep/Nov 2008] which culminated in the current live version of the [VendAsta](https://www.vendasta.com) website. Despite such a short dev-cycle, I feel we were able to accomplish most of our research goals.\n\nOne of the tools we used that I didn't have much experience with prior was [Yahoo Pipes](https://pipes.yahoo.com). We had somewhat of a unique problem to solve; we wanted to be able to draw from a variety of Feed sources that would filter through to different sections of the site. Before I dove into using Pipes my gut feeling was just to use some sort of feed parsing library in Python that was compatible with AppEngine. One of the requirements for implementing the feed sources was that it be very easy to update should a feed need to be changed. If we stuck with the Python library implementation and statically coded some feed\nsources, changes would take significantly more overhead to implement.\n\nWe started investigating Pipes as a platform to aggregate all of the content we wanted to re-publish and were impressed by what we found. It turns out that the Pipes interface is much better at providing an easy-to-update set of feed sources for non-programmers. If you haven't looked at the Pipes interface I highly recommend you do so. I think Pipes offers so much advanced filtering and splicing functionality in a really tight package, so I'll attempt to break down some of the modules we used specifically for the VendAsta website.\n\n![A screenshot of the Yahoo Pipes interface](/img/yahoo-pipes-at-vendasta/v-blogroll.png)\n\nThe image above is a shot of the Pipes interface, and more specifically the Pipe that we use to aggregate all of the feed-based content on the VendAsta website. I should clarify, by feed-based content I'm referring to all of the official employee, product, and corporate blogs. Yes you read that right, employee blog posts (when tagged appropriately) end up on our corporate website. But let's set aside the trust/ethical issues related to that and focus on the technology we're\nusing. There are a few components to the root pipe we use to collect all this content, and the Pipes documentation isn't always entirely clear on the best way to use things, so I will attempt to decompose it and discuss each module in detail.\n\n## Feed Auto-Discovery\n\n![Feed Auto-Discovery](/img/yahoo-pipes-at-vendasta/feed-auto-discovery.png)\n\nWe have a URL mounted on VendAsta.com that provides only 1 function: spitting out a list of link tags in the following format:\n\n```html\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Dave Mosher\" href=\"https://www.davemo.com\">\n```\n\nInternally, we store a list of all employees with some meta information like blogURL, linkedinURL etc. This url is what we provide to the auto-discovery module so it can do it's magic and go out to all of the rss+xml links and gather a list of feeds from the blogs. Here's a sample of the output you get from this URL in the Pipes debug console.\n\n![Feed Auto-Discovery Output](/img/yahoo-pipes-at-vendasta/feed-auto-discovery-output.png)\n\nOnce we have this list of blogs and the links to them, we can pass the output from the auto-discovery module on to the Loop + Fetch Site Feed modules.\n\n## Loop + Fetch Site Feed\n\nThe loop module is pretty self explanatory, you use it when you want to iterate over a group of results and operate on them somehow. It's kind of similar to providing an AJAX onSuccess callback; you send out a request for the content (the iteration) and you define a 'callback' by dragging a supporting pipes function into the available box to process each item. In our case, we're using the Fetch Site Feed module from the toolbox to snag a feed from each site in our blogroll. We configure the module to emit all results to our next module, the Filter, which does most of the magic in determining which content ends up on the corporate website.\n\n![Pipes Loop + Fetch Site Feed Modules](/img/yahoo-pipes-at-vendasta/picture-3.png)\n\n## Filter\n\nThe filter module works really well for grabbing a set of elements based on a certain set of criteria; in our case we use the Regexp option to explicitly allow any content with the tag/category 'VendAsta'.\n\n![The Filter Module](/img/yahoo-pipes-at-vendasta/picture-4.png)\n\n## Union, Sort, Rename + Pipe Output\n\nThe final layer of our pipe involves combining results from some other static sources independent of filters (VendAsta blog and the StepRep blog), sorting them based on the date published descending, renaming a specific RSS feed field (item.dc:creator) to 'author' to fix a problem in the feed reading library we're using server side (feedparser.py) and finally the output of all these operations: 'Pipe Output' module. All these modules are really easy to string together with the Pipes interface and are clickable at any point during the creation which will toggle the debug output to stop at the currently selected module. This is very useful for seeing what the modules you are using do at each step of the process.\n\n![Union Sort Rename and Pipe Output Modules](/img/yahoo-pipes-at-vendasta/picture-51.png)\n\n## Pipes as abstract components ties it all together\n\nSo now that we have a completed Pipes module, we can do a number of things with it. We can get the output in RSS or JSON format, define a custom url for the pipe, and even give it a name and make it public so other people can use it in their mashups. However, the coolest feature IMHO is that you can use any created pipes module as an abstracted pipes component on it's own which can be part of another pipes component that you can then perform further operations on. We chose to separate a few of the layers in our feed hierarchy this way for simplicity sake and to keep it loosely coupled if we wanted to make changes to what feeds appear on certain pages. Here's an example of our previous Blogroll pipe being used as input for further filtering and display on 1 section of the VendAsta website: the [Projects](https://www.vendasta.com/projects/) page.\n\n![The blogroll pipe as input](/img/yahoo-pipes-at-vendasta/picture-6.png)\n"
}></pre></div><div><a href="/posts/2009-06-19-useful-bash-scripting.html">Useful bash scripting</a><pre><{
  "path": "app/posts/2009-06-19-useful-bash-scripting.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Useful bash scripting",
      "date": "2009-06-19"
    },
    "source": "\n> Kevin Pierce showed me some handy scripting when I was updating some svn stuff.\n\n```bash\nfor x in static/ yourapp/ index.yamltemplates/; do svn mv $x appengine_starter_kit/; done\n```\n\nBasically, this sets up a for loop that's iterating over some directories that I\nwanted to move into a sub directory. I hadn't done much bash scripting, but this\nis much more efficient than typing out the lines 1 at a time.\n\nUseful!\n\n"
  },
  "attributes": {
    "title": "Useful bash scripting",
    "date": "2009-06-19"
  },
  "markdown": "\n> Kevin Pierce showed me some handy scripting when I was updating some svn stuff.\n\n```bash\nfor x in static/ yourapp/ index.yamltemplates/; do svn mv $x appengine_starter_kit/; done\n```\n\nBasically, this sets up a for loop that's iterating over some directories that I\nwanted to move into a sub directory. I hadn't done much bash scripting, but this\nis much more efficient than typing out the lines 1 at a time.\n\nUseful!\n\n"
}></{
  "path": "app/posts/2009-06-19-useful-bash-scripting.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Useful bash scripting",
      "date": "2009-06-19"
    },
    "source": "\n> Kevin Pierce showed me some handy scripting when I was updating some svn stuff.\n\n```bash\nfor x in static/ yourapp/ index.yamltemplates/; do svn mv $x appengine_starter_kit/; done\n```\n\nBasically, this sets up a for loop that's iterating over some directories that I\nwanted to move into a sub directory. I hadn't done much bash scripting, but this\nis much more efficient than typing out the lines 1 at a time.\n\nUseful!\n\n"
  },
  "attributes": {
    "title": "Useful bash scripting",
    "date": "2009-06-19"
  },
  "markdown": "\n> Kevin Pierce showed me some handy scripting when I was updating some svn stuff.\n\n```bash\nfor x in static/ yourapp/ index.yamltemplates/; do svn mv $x appengine_starter_kit/; done\n```\n\nBasically, this sets up a for loop that's iterating over some directories that I\nwanted to move into a sub directory. I hadn't done much bash scripting, but this\nis much more efficient than typing out the lines 1 at a time.\n\nUseful!\n\n"
}></pre></div><div><a href="/posts/2009-06-17-using-the-cloud-as-a-blog.html">Using 'the cloud' as a blog</a><pre><{
  "path": "app/posts/2009-06-17-using-the-cloud-as-a-blog.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Using 'the cloud' as a blog",
      "date": "2009-06-17"
    },
    "source": "\n> I saw Posterous through the [TweetDeck](https://www.tweetdeck.com) update and was pleasantly intrigued by the interface. Couldn't have a simpler concept for publishing personal stuff if you ask me, so I decided to give it a try and see what it looked like.\n\nI'm pretty impressed to be honest, driving content via email, sms, or any other number of input methods and having it appear automagically on a website somewhere with panache is a pretty cool idea.\n\n**Update**: I've since dug into the Posterous interface and I've been even more impressed. It was easy to add a DNS record for [www.davemo.com](https://www.davemo.com) in EasyDNS and have it point to this site in a matter of minutes. Yay!\n\nFacebook connect integration, auto embedding of media including images, video, music and the ability to post via so many methods. This just makes blogging as easy as sending email.\n\n"
  },
  "attributes": {
    "title": "Using 'the cloud' as a blog",
    "date": "2009-06-17"
  },
  "markdown": "\n> I saw Posterous through the [TweetDeck](https://www.tweetdeck.com) update and was pleasantly intrigued by the interface. Couldn't have a simpler concept for publishing personal stuff if you ask me, so I decided to give it a try and see what it looked like.\n\nI'm pretty impressed to be honest, driving content via email, sms, or any other number of input methods and having it appear automagically on a website somewhere with panache is a pretty cool idea.\n\n**Update**: I've since dug into the Posterous interface and I've been even more impressed. It was easy to add a DNS record for [www.davemo.com](https://www.davemo.com) in EasyDNS and have it point to this site in a matter of minutes. Yay!\n\nFacebook connect integration, auto embedding of media including images, video, music and the ability to post via so many methods. This just makes blogging as easy as sending email.\n\n"
}></{
  "path": "app/posts/2009-06-17-using-the-cloud-as-a-blog.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Using 'the cloud' as a blog",
      "date": "2009-06-17"
    },
    "source": "\n> I saw Posterous through the [TweetDeck](https://www.tweetdeck.com) update and was pleasantly intrigued by the interface. Couldn't have a simpler concept for publishing personal stuff if you ask me, so I decided to give it a try and see what it looked like.\n\nI'm pretty impressed to be honest, driving content via email, sms, or any other number of input methods and having it appear automagically on a website somewhere with panache is a pretty cool idea.\n\n**Update**: I've since dug into the Posterous interface and I've been even more impressed. It was easy to add a DNS record for [www.davemo.com](https://www.davemo.com) in EasyDNS and have it point to this site in a matter of minutes. Yay!\n\nFacebook connect integration, auto embedding of media including images, video, music and the ability to post via so many methods. This just makes blogging as easy as sending email.\n\n"
  },
  "attributes": {
    "title": "Using 'the cloud' as a blog",
    "date": "2009-06-17"
  },
  "markdown": "\n> I saw Posterous through the [TweetDeck](https://www.tweetdeck.com) update and was pleasantly intrigued by the interface. Couldn't have a simpler concept for publishing personal stuff if you ask me, so I decided to give it a try and see what it looked like.\n\nI'm pretty impressed to be honest, driving content via email, sms, or any other number of input methods and having it appear automagically on a website somewhere with panache is a pretty cool idea.\n\n**Update**: I've since dug into the Posterous interface and I've been even more impressed. It was easy to add a DNS record for [www.davemo.com](https://www.davemo.com) in EasyDNS and have it point to this site in a matter of minutes. Yay!\n\nFacebook connect integration, auto embedding of media including images, video, music and the ability to post via so many methods. This just makes blogging as easy as sending email.\n\n"
}></pre></div><div><a href="/posts/2009-03-24-yui-uploader-and-ie7-flash-bugs.html">YUI Uploader and IE7 Flash Bugs</a><pre><{
  "path": "app/posts/2009-03-24-yui-uploader-and-ie7-flash-bugs.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "YUI Uploader and IE7 Flash Bugs",
      "date": "2009-03-24"
    },
    "source": "\n> We covered a lot of ground on the [MyFrontSteps](https://www.myfrontsteps.com) project this week. We managed to migrate our Photo Management / Uploading solution on Homebook from [SWFUpload](https://swfupload.org/) and a lot of hacked together [jQuery](https://www.jquery.com) to a more elegant solution (albeit one that could still use some refactoring - but what code can't use refactoring really).\n\nWe decided to use the \"still-in-beta\" [YUI Uploader](https://developer.yahoo.com/yui/uploader/) coupled with some custom jQuery. The implementation seems much more cohesive than our previous solution but there were a few gotchas we rant into when trying to get things working properly in IE7.\n\n## YUI Uploader\n\nI know this component is still in beta support from Yahoo, but I had given it a\nvery brief try in our supported browser baseline (currently FF2+, Safari3+,\nIE7+) and it seemed to work really well. All of the YUI stuff we're using works\nreally well and the graded browser support and testing the YUI team puts behind\ntheir work makes implementation that much more reliable. That being said, no\npiece of software is perfect and we ran into a pretty frustrating bug\nimplementing the YUI Uploader in a specific area of the application.\n\n![A flyover context menu with an embedded YUI Uploader.](/img/yui-uploader-and-ie7-flash-bugs/picture-24.png)\n\nWe have a number of context menus in Homebook that appear to the user on mouseover. This particular thumbnail represents the default image for a users Home, and clicking it prompts the user with a file dialog to select a new photo which is then uploaded via the YUI Uploader. When instantiated, the uploader inserts a transparent Flash object using the [SWFObject](https://blog.deconcept.com/swfobject/) plugin into the markup in the container specified. In our case we had the following markup:\n\n```jade\nul class='mfs-context-menu invisible' id='default-image-menu'\n   li\n      a\n        span class='uploader' id='upload-profile-picture' /span\n        'Change Profile Picture'\n     /a\n  /li\n/ul\n```\n\nWe use a class of invisible to set the css property 'display:none;' on the 'ul' so it's hidden by default when the page loads. When the page loads and the script triggers, the uploader sits nicely in the span tag directly above the link in the li tag. The user then clicks on the transparent flash object and the upload can start. Now, this approach works fine in every browser EXCEPT IE7. For some reason when the uploader is instantiated in IE7 if it becomes hidden and then shown again at any point the YUI Uploader loses all binding to the functions that trigger submission to the server side url. I tried doing some searching to see if this was documented anywhere and came up empty everywhere I looked.\n\n> My best guess is that the IE7 security model doesn't like the fact that an 'embed' tag with the Flash object is being manipulated from JavaScript and decided to turn off something that disables the uploader from completing an upload. The file dialog will still popup, and the embedded Flash remains in the DOM but the uploader doesn't trigger sending of the files to the server.\n\nIt took us a while to figure out what was going on, and the only way we tracked it down was by a process of elimination commenting out lines of code in the uploader instantiation script until we discovered it was our context menu show/hide trigger that made the uploader behave this way. So, the solution in our case was to move the uploader 'span' tag outside of the 'li' but still inside the thumbnail container, give it a fixed width and height directly above the image (like a transparent rectangle) and bind mouseover/mouseout events to it that triggered show/hide of the 'li' element with the 'a' inside:\n\n```jade\nul class='mfs-context-menu invisible' id='default-image-menu'\n  span class='uploader' id='upload-profile-picture' /span\n    li a 'Change Profile Picture' /a /li\n/ul\n```\n\n\nThis way the flash element never gets hidden, and IE7 doesn't do anything funky to it so the uploader remains operational.\n\n"
  },
  "attributes": {
    "title": "YUI Uploader and IE7 Flash Bugs",
    "date": "2009-03-24"
  },
  "markdown": "\n> We covered a lot of ground on the [MyFrontSteps](https://www.myfrontsteps.com) project this week. We managed to migrate our Photo Management / Uploading solution on Homebook from [SWFUpload](https://swfupload.org/) and a lot of hacked together [jQuery](https://www.jquery.com) to a more elegant solution (albeit one that could still use some refactoring - but what code can't use refactoring really).\n\nWe decided to use the \"still-in-beta\" [YUI Uploader](https://developer.yahoo.com/yui/uploader/) coupled with some custom jQuery. The implementation seems much more cohesive than our previous solution but there were a few gotchas we rant into when trying to get things working properly in IE7.\n\n## YUI Uploader\n\nI know this component is still in beta support from Yahoo, but I had given it a\nvery brief try in our supported browser baseline (currently FF2+, Safari3+,\nIE7+) and it seemed to work really well. All of the YUI stuff we're using works\nreally well and the graded browser support and testing the YUI team puts behind\ntheir work makes implementation that much more reliable. That being said, no\npiece of software is perfect and we ran into a pretty frustrating bug\nimplementing the YUI Uploader in a specific area of the application.\n\n![A flyover context menu with an embedded YUI Uploader.](/img/yui-uploader-and-ie7-flash-bugs/picture-24.png)\n\nWe have a number of context menus in Homebook that appear to the user on mouseover. This particular thumbnail represents the default image for a users Home, and clicking it prompts the user with a file dialog to select a new photo which is then uploaded via the YUI Uploader. When instantiated, the uploader inserts a transparent Flash object using the [SWFObject](https://blog.deconcept.com/swfobject/) plugin into the markup in the container specified. In our case we had the following markup:\n\n```jade\nul class='mfs-context-menu invisible' id='default-image-menu'\n   li\n      a\n        span class='uploader' id='upload-profile-picture' /span\n        'Change Profile Picture'\n     /a\n  /li\n/ul\n```\n\nWe use a class of invisible to set the css property 'display:none;' on the 'ul' so it's hidden by default when the page loads. When the page loads and the script triggers, the uploader sits nicely in the span tag directly above the link in the li tag. The user then clicks on the transparent flash object and the upload can start. Now, this approach works fine in every browser EXCEPT IE7. For some reason when the uploader is instantiated in IE7 if it becomes hidden and then shown again at any point the YUI Uploader loses all binding to the functions that trigger submission to the server side url. I tried doing some searching to see if this was documented anywhere and came up empty everywhere I looked.\n\n> My best guess is that the IE7 security model doesn't like the fact that an 'embed' tag with the Flash object is being manipulated from JavaScript and decided to turn off something that disables the uploader from completing an upload. The file dialog will still popup, and the embedded Flash remains in the DOM but the uploader doesn't trigger sending of the files to the server.\n\nIt took us a while to figure out what was going on, and the only way we tracked it down was by a process of elimination commenting out lines of code in the uploader instantiation script until we discovered it was our context menu show/hide trigger that made the uploader behave this way. So, the solution in our case was to move the uploader 'span' tag outside of the 'li' but still inside the thumbnail container, give it a fixed width and height directly above the image (like a transparent rectangle) and bind mouseover/mouseout events to it that triggered show/hide of the 'li' element with the 'a' inside:\n\n```jade\nul class='mfs-context-menu invisible' id='default-image-menu'\n  span class='uploader' id='upload-profile-picture' /span\n    li a 'Change Profile Picture' /a /li\n/ul\n```\n\n\nThis way the flash element never gets hidden, and IE7 doesn't do anything funky to it so the uploader remains operational.\n\n"
}></{
  "path": "app/posts/2009-03-24-yui-uploader-and-ie7-flash-bugs.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "YUI Uploader and IE7 Flash Bugs",
      "date": "2009-03-24"
    },
    "source": "\n> We covered a lot of ground on the [MyFrontSteps](https://www.myfrontsteps.com) project this week. We managed to migrate our Photo Management / Uploading solution on Homebook from [SWFUpload](https://swfupload.org/) and a lot of hacked together [jQuery](https://www.jquery.com) to a more elegant solution (albeit one that could still use some refactoring - but what code can't use refactoring really).\n\nWe decided to use the \"still-in-beta\" [YUI Uploader](https://developer.yahoo.com/yui/uploader/) coupled with some custom jQuery. The implementation seems much more cohesive than our previous solution but there were a few gotchas we rant into when trying to get things working properly in IE7.\n\n## YUI Uploader\n\nI know this component is still in beta support from Yahoo, but I had given it a\nvery brief try in our supported browser baseline (currently FF2+, Safari3+,\nIE7+) and it seemed to work really well. All of the YUI stuff we're using works\nreally well and the graded browser support and testing the YUI team puts behind\ntheir work makes implementation that much more reliable. That being said, no\npiece of software is perfect and we ran into a pretty frustrating bug\nimplementing the YUI Uploader in a specific area of the application.\n\n![A flyover context menu with an embedded YUI Uploader.](/img/yui-uploader-and-ie7-flash-bugs/picture-24.png)\n\nWe have a number of context menus in Homebook that appear to the user on mouseover. This particular thumbnail represents the default image for a users Home, and clicking it prompts the user with a file dialog to select a new photo which is then uploaded via the YUI Uploader. When instantiated, the uploader inserts a transparent Flash object using the [SWFObject](https://blog.deconcept.com/swfobject/) plugin into the markup in the container specified. In our case we had the following markup:\n\n```jade\nul class='mfs-context-menu invisible' id='default-image-menu'\n   li\n      a\n        span class='uploader' id='upload-profile-picture' /span\n        'Change Profile Picture'\n     /a\n  /li\n/ul\n```\n\nWe use a class of invisible to set the css property 'display:none;' on the 'ul' so it's hidden by default when the page loads. When the page loads and the script triggers, the uploader sits nicely in the span tag directly above the link in the li tag. The user then clicks on the transparent flash object and the upload can start. Now, this approach works fine in every browser EXCEPT IE7. For some reason when the uploader is instantiated in IE7 if it becomes hidden and then shown again at any point the YUI Uploader loses all binding to the functions that trigger submission to the server side url. I tried doing some searching to see if this was documented anywhere and came up empty everywhere I looked.\n\n> My best guess is that the IE7 security model doesn't like the fact that an 'embed' tag with the Flash object is being manipulated from JavaScript and decided to turn off something that disables the uploader from completing an upload. The file dialog will still popup, and the embedded Flash remains in the DOM but the uploader doesn't trigger sending of the files to the server.\n\nIt took us a while to figure out what was going on, and the only way we tracked it down was by a process of elimination commenting out lines of code in the uploader instantiation script until we discovered it was our context menu show/hide trigger that made the uploader behave this way. So, the solution in our case was to move the uploader 'span' tag outside of the 'li' but still inside the thumbnail container, give it a fixed width and height directly above the image (like a transparent rectangle) and bind mouseover/mouseout events to it that triggered show/hide of the 'li' element with the 'a' inside:\n\n```jade\nul class='mfs-context-menu invisible' id='default-image-menu'\n  span class='uploader' id='upload-profile-picture' /span\n    li a 'Change Profile Picture' /a /li\n/ul\n```\n\n\nThis way the flash element never gets hidden, and IE7 doesn't do anything funky to it so the uploader remains operational.\n\n"
  },
  "attributes": {
    "title": "YUI Uploader and IE7 Flash Bugs",
    "date": "2009-03-24"
  },
  "markdown": "\n> We covered a lot of ground on the [MyFrontSteps](https://www.myfrontsteps.com) project this week. We managed to migrate our Photo Management / Uploading solution on Homebook from [SWFUpload](https://swfupload.org/) and a lot of hacked together [jQuery](https://www.jquery.com) to a more elegant solution (albeit one that could still use some refactoring - but what code can't use refactoring really).\n\nWe decided to use the \"still-in-beta\" [YUI Uploader](https://developer.yahoo.com/yui/uploader/) coupled with some custom jQuery. The implementation seems much more cohesive than our previous solution but there were a few gotchas we rant into when trying to get things working properly in IE7.\n\n## YUI Uploader\n\nI know this component is still in beta support from Yahoo, but I had given it a\nvery brief try in our supported browser baseline (currently FF2+, Safari3+,\nIE7+) and it seemed to work really well. All of the YUI stuff we're using works\nreally well and the graded browser support and testing the YUI team puts behind\ntheir work makes implementation that much more reliable. That being said, no\npiece of software is perfect and we ran into a pretty frustrating bug\nimplementing the YUI Uploader in a specific area of the application.\n\n![A flyover context menu with an embedded YUI Uploader.](/img/yui-uploader-and-ie7-flash-bugs/picture-24.png)\n\nWe have a number of context menus in Homebook that appear to the user on mouseover. This particular thumbnail represents the default image for a users Home, and clicking it prompts the user with a file dialog to select a new photo which is then uploaded via the YUI Uploader. When instantiated, the uploader inserts a transparent Flash object using the [SWFObject](https://blog.deconcept.com/swfobject/) plugin into the markup in the container specified. In our case we had the following markup:\n\n```jade\nul class='mfs-context-menu invisible' id='default-image-menu'\n   li\n      a\n        span class='uploader' id='upload-profile-picture' /span\n        'Change Profile Picture'\n     /a\n  /li\n/ul\n```\n\nWe use a class of invisible to set the css property 'display:none;' on the 'ul' so it's hidden by default when the page loads. When the page loads and the script triggers, the uploader sits nicely in the span tag directly above the link in the li tag. The user then clicks on the transparent flash object and the upload can start. Now, this approach works fine in every browser EXCEPT IE7. For some reason when the uploader is instantiated in IE7 if it becomes hidden and then shown again at any point the YUI Uploader loses all binding to the functions that trigger submission to the server side url. I tried doing some searching to see if this was documented anywhere and came up empty everywhere I looked.\n\n> My best guess is that the IE7 security model doesn't like the fact that an 'embed' tag with the Flash object is being manipulated from JavaScript and decided to turn off something that disables the uploader from completing an upload. The file dialog will still popup, and the embedded Flash remains in the DOM but the uploader doesn't trigger sending of the files to the server.\n\nIt took us a while to figure out what was going on, and the only way we tracked it down was by a process of elimination commenting out lines of code in the uploader instantiation script until we discovered it was our context menu show/hide trigger that made the uploader behave this way. So, the solution in our case was to move the uploader 'span' tag outside of the 'li' but still inside the thumbnail container, give it a fixed width and height directly above the image (like a transparent rectangle) and bind mouseover/mouseout events to it that triggered show/hide of the 'li' element with the 'a' inside:\n\n```jade\nul class='mfs-context-menu invisible' id='default-image-menu'\n  span class='uploader' id='upload-profile-picture' /span\n    li a 'Change Profile Picture' /a /li\n/ul\n```\n\n\nThis way the flash element never gets hidden, and IE7 doesn't do anything funky to it so the uploader remains operational.\n\n"
}></pre></div><div><a href="/posts/2009-03-13-javascript-dependency-management-and-yui-loader-quirks.html">JavaScript Dependency Management and YUI Loader Quirks</a><pre><{
  "path": "app/posts/2009-03-13-javascript-dependency-management-and-yui-loader-quirks.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "JavaScript Dependency Management and YUI Loader Quirks",
      "date": "2009-03-13"
    },
    "source": "\n[Brett](https://bzabos.wordpress.com/) and I recently began refactoring a significant amount of the JavaScript that is currently in [MyFrontSteps](https://www.myfrontsteps.com) and [Homebook](https://www.myfrontsteps.com/myfrontsteps/home/). One of the areas we identified as needing improvement was controlling when scripts get loaded in the page; it's a challenging subject especially when utilizing Django templates which can extend and include bits of HTML that are both static and dynamic. We're not finished the refactoring quite yet but I thought it would be valuable to blog about the lessons we've learned early on about how to manage JavaScript loading without having script tags all over the place.\n\n## Manual Dependency Management is Hard\n\nNot too long ago, Yahoo put out a list of [guidelines](https://developer.yahoo.com/performance/rules.html) that web developers can use to enhance the performance of their websites. I won't get into it in this post but there is a Firefox plugin called [YSlow](https://developer.yahoo.com/yslow/) available that can automate some of the performance checking. The recommendation I'm going to focus on here is the one regarding moving scripts as close to the bottom of the page as possible.\n\nI'll just quote the [Yahoo doc](https://developer.yahoo.com/performance/rules.html) as they explain it very clearly:\n\n> The problem caused by scripts is that they block parallel downloads. The > [HTTP/1.1 specification](https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.1.4) suggests that browsers download no more than two components in parallel per hostname. If you serve your images from multiple hostnames, you can get more than two downloads to occur in parallel. While a script is downloading, however, the browser won't start any other downloads, even on different hostnames. In some situations it's not easy to move scripts to the bottom. If, for example, the script uses `document.write`to insert part of the page's content, it can't be moved lower in the page. There might also be scoping issues. In many cases, there are ways to workaround these situations.\n\nIn the case of the code we're using on MyFrontSteps we had all kinds of Django templates with includes and templatetags that include other little bits of dynamic JavaScript that was adding markup to the DOM and manipulating DOM content. Some of this code would appear prior to certain dependent scripts being loaded which created a real nightmare for us as we had to manually track down the position of the dependent scripts in the page that was fed to the browser after a variable number of layers of templates and includes. We decided to research a better way to manage all these scripts and since we had been using the YUI library for many other parts of the website we settled on the [YUI loader](https://developer.yahoo.com/yui/yuiloader/).\n\n## YUI Loader Makes Dependency Management Easy\n\n> The YUI Loader Utility is a client-side JavaScript component that allows you to load specific YUI components and their dependencies into your page via script. YUI Loader can operate as a holistic solution by loading all of your necessary YUI components, or it can be used to add one or more components to a page on which some YUI content already exists.\n\nThe great thing about the YUI Loader is that you can use it to manage dependency sorting for all of the YUI components you use on a page but the *killer* feature\nimho is the fact that it allows you to create custom modules to load your own JS and CSS libraries. The basic pattern we're using in our root level Django template is as follows:\n\n1.  Load all CSS Files at the top of the template\n2.  Place all YUI Loader and other statically included scripts at the bottom of\n    the page prior to the closing BODY tag\n3.  Define the YUI Loader instance\n4.  Define custom modules for the YUI loader\n5.  Provide a Django template block to allow manipulation of the onSuccess\n    callback\n6.  Call the YUI Loaders .insert() method to trigger insertion of all dependency\n    sorted scripts into the DOM\n\nThe advantage to using the loader in conjunction with our root Django template is clear; all of our scripts are loaded at the bottom of the page and CSS is loaded at the top. When a user requests the pages they will start receiving the content from the server immediately and not have to wait for scripts to process as the loader dynamically inserts them into the HEAD element after the page content has been rendered. Another trick we're using to control when scripts get executed is by manipulating how the onSuccess callback of the loader works. Here's the code:\n\n```javascript\n// Instantiate and configure YUI Loader:\nMFSLoader = new YAHOO.util.YUILoader({\n    base: \"\",\n    require: [\"base\",\"reset-fonts-grids\",\"MFS\"],\n    loadOptional: false,\n    combine: true,\n    filter: \"MIN\",\n    allowRollup: true,\n    onSuccess: function() {\n        while( MFSLoader.onReady.length )  {\n            MFSLoader.onReady.shift()();\n        }\n    }\n});\n// Define a list of executables that we\n// can add to prior to page load completion\nMFSLoader.onReady = [];\n// Custom Modules for Loader\nMFSLoader.addModule({\n    name: 'MFS', type: 'js', varName: 'MFS',\n    path: '{% vurl \"/static/script/MFS.js\" %}',\n    requires: ['jQuery', 'jQueryUI']\n});\n{# Override this block if you need script at the global level. #}\n{% block global.script %}{% endblock %}\n// Trigger insertion of all dependency sorted scripts into the DOM\nMFSLoader.insert();\n```\n\nAs you can see we have a few of the custom modules defined here, which include a 'requires' attribute in the configuration object. This lets the YUI Loader know\nthat these files require the other modules to be loaded. The Loader then determines sort order for inclusion based on all required modules and goes to work inserting the scripts for you.\n\n## Tying it all Together\n\nThe key to making this work in the varying levels of Django templates is to manipulate the onSuccess callback. When the YUI Loader finishes loading all the dependency sorted scripts it will execute this callback and allow you to then execute any additional code that depends on the dynamically inserted scripts. We have a number of namespaced JS objects for MyFrontSteps (MFS.js, MFS.DataGrid.js etc..) and when we need to call functions defined in these objects we do so by extending the global.script block in our child template and pushing a new anonymous function onto the MFSLoader.onReady list we defined in the root template.\n\nHere's a simple example:\n\n```javascript\n{# A CHILD TEMPLATE #}\n{% block global.script %}\n    #include the parent templates global.script contents\n    {{ block.super }}\n    // Load our required features\n    MFSLoader.require( 'MFS.DataGrid', 'uploader', 'MFS.Uploader' );\n    // Push an anonymous function onto the list\n    // to get executed when all required scripts have been loaded\n    MFSLoader.onReady.push( function()  {\n        MFS.DataGrid.initPhotosGrid();\n    });\n{% endblock %}\n```\n\nOnce the page is rendered and the YUI Loader has finished parsing the loaded scripts the code we have in the onSuccess callback pops all the anonymous functions off the list which causes them to be executed.\n\n```javascript\n{# THE ONSUCCESS CALLBACK #}\nonSuccess: function() {\n    while( MFSLoader.onReady.length )  {\n        MFSLoader.onReady.shift()();\n    }\n}\n```\n\nWe still have a number of files to refactor, but the performance benefits we've seen so far using this approach have really made us confident that this is the way to go. Using a dependency manager that works for custom JS / CSS libraries is just so much more liberating than having to manually keep track of where scripts are getting executed. Because we're also migrating all of our code to external library files it makes things that much easier to debug in Firebug as\nwell.\n"
  },
  "attributes": {
    "title": "JavaScript Dependency Management and YUI Loader Quirks",
    "date": "2009-03-13"
  },
  "markdown": "\n[Brett](https://bzabos.wordpress.com/) and I recently began refactoring a significant amount of the JavaScript that is currently in [MyFrontSteps](https://www.myfrontsteps.com) and [Homebook](https://www.myfrontsteps.com/myfrontsteps/home/). One of the areas we identified as needing improvement was controlling when scripts get loaded in the page; it's a challenging subject especially when utilizing Django templates which can extend and include bits of HTML that are both static and dynamic. We're not finished the refactoring quite yet but I thought it would be valuable to blog about the lessons we've learned early on about how to manage JavaScript loading without having script tags all over the place.\n\n## Manual Dependency Management is Hard\n\nNot too long ago, Yahoo put out a list of [guidelines](https://developer.yahoo.com/performance/rules.html) that web developers can use to enhance the performance of their websites. I won't get into it in this post but there is a Firefox plugin called [YSlow](https://developer.yahoo.com/yslow/) available that can automate some of the performance checking. The recommendation I'm going to focus on here is the one regarding moving scripts as close to the bottom of the page as possible.\n\nI'll just quote the [Yahoo doc](https://developer.yahoo.com/performance/rules.html) as they explain it very clearly:\n\n> The problem caused by scripts is that they block parallel downloads. The > [HTTP/1.1 specification](https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.1.4) suggests that browsers download no more than two components in parallel per hostname. If you serve your images from multiple hostnames, you can get more than two downloads to occur in parallel. While a script is downloading, however, the browser won't start any other downloads, even on different hostnames. In some situations it's not easy to move scripts to the bottom. If, for example, the script uses `document.write`to insert part of the page's content, it can't be moved lower in the page. There might also be scoping issues. In many cases, there are ways to workaround these situations.\n\nIn the case of the code we're using on MyFrontSteps we had all kinds of Django templates with includes and templatetags that include other little bits of dynamic JavaScript that was adding markup to the DOM and manipulating DOM content. Some of this code would appear prior to certain dependent scripts being loaded which created a real nightmare for us as we had to manually track down the position of the dependent scripts in the page that was fed to the browser after a variable number of layers of templates and includes. We decided to research a better way to manage all these scripts and since we had been using the YUI library for many other parts of the website we settled on the [YUI loader](https://developer.yahoo.com/yui/yuiloader/).\n\n## YUI Loader Makes Dependency Management Easy\n\n> The YUI Loader Utility is a client-side JavaScript component that allows you to load specific YUI components and their dependencies into your page via script. YUI Loader can operate as a holistic solution by loading all of your necessary YUI components, or it can be used to add one or more components to a page on which some YUI content already exists.\n\nThe great thing about the YUI Loader is that you can use it to manage dependency sorting for all of the YUI components you use on a page but the *killer* feature\nimho is the fact that it allows you to create custom modules to load your own JS and CSS libraries. The basic pattern we're using in our root level Django template is as follows:\n\n1.  Load all CSS Files at the top of the template\n2.  Place all YUI Loader and other statically included scripts at the bottom of\n    the page prior to the closing BODY tag\n3.  Define the YUI Loader instance\n4.  Define custom modules for the YUI loader\n5.  Provide a Django template block to allow manipulation of the onSuccess\n    callback\n6.  Call the YUI Loaders .insert() method to trigger insertion of all dependency\n    sorted scripts into the DOM\n\nThe advantage to using the loader in conjunction with our root Django template is clear; all of our scripts are loaded at the bottom of the page and CSS is loaded at the top. When a user requests the pages they will start receiving the content from the server immediately and not have to wait for scripts to process as the loader dynamically inserts them into the HEAD element after the page content has been rendered. Another trick we're using to control when scripts get executed is by manipulating how the onSuccess callback of the loader works. Here's the code:\n\n```javascript\n// Instantiate and configure YUI Loader:\nMFSLoader = new YAHOO.util.YUILoader({\n    base: \"\",\n    require: [\"base\",\"reset-fonts-grids\",\"MFS\"],\n    loadOptional: false,\n    combine: true,\n    filter: \"MIN\",\n    allowRollup: true,\n    onSuccess: function() {\n        while( MFSLoader.onReady.length )  {\n            MFSLoader.onReady.shift()();\n        }\n    }\n});\n// Define a list of executables that we\n// can add to prior to page load completion\nMFSLoader.onReady = [];\n// Custom Modules for Loader\nMFSLoader.addModule({\n    name: 'MFS', type: 'js', varName: 'MFS',\n    path: '{% vurl \"/static/script/MFS.js\" %}',\n    requires: ['jQuery', 'jQueryUI']\n});\n{# Override this block if you need script at the global level. #}\n{% block global.script %}{% endblock %}\n// Trigger insertion of all dependency sorted scripts into the DOM\nMFSLoader.insert();\n```\n\nAs you can see we have a few of the custom modules defined here, which include a 'requires' attribute in the configuration object. This lets the YUI Loader know\nthat these files require the other modules to be loaded. The Loader then determines sort order for inclusion based on all required modules and goes to work inserting the scripts for you.\n\n## Tying it all Together\n\nThe key to making this work in the varying levels of Django templates is to manipulate the onSuccess callback. When the YUI Loader finishes loading all the dependency sorted scripts it will execute this callback and allow you to then execute any additional code that depends on the dynamically inserted scripts. We have a number of namespaced JS objects for MyFrontSteps (MFS.js, MFS.DataGrid.js etc..) and when we need to call functions defined in these objects we do so by extending the global.script block in our child template and pushing a new anonymous function onto the MFSLoader.onReady list we defined in the root template.\n\nHere's a simple example:\n\n```javascript\n{# A CHILD TEMPLATE #}\n{% block global.script %}\n    #include the parent templates global.script contents\n    {{ block.super }}\n    // Load our required features\n    MFSLoader.require( 'MFS.DataGrid', 'uploader', 'MFS.Uploader' );\n    // Push an anonymous function onto the list\n    // to get executed when all required scripts have been loaded\n    MFSLoader.onReady.push( function()  {\n        MFS.DataGrid.initPhotosGrid();\n    });\n{% endblock %}\n```\n\nOnce the page is rendered and the YUI Loader has finished parsing the loaded scripts the code we have in the onSuccess callback pops all the anonymous functions off the list which causes them to be executed.\n\n```javascript\n{# THE ONSUCCESS CALLBACK #}\nonSuccess: function() {\n    while( MFSLoader.onReady.length )  {\n        MFSLoader.onReady.shift()();\n    }\n}\n```\n\nWe still have a number of files to refactor, but the performance benefits we've seen so far using this approach have really made us confident that this is the way to go. Using a dependency manager that works for custom JS / CSS libraries is just so much more liberating than having to manually keep track of where scripts are getting executed. Because we're also migrating all of our code to external library files it makes things that much easier to debug in Firebug as\nwell.\n"
}></{
  "path": "app/posts/2009-03-13-javascript-dependency-management-and-yui-loader-quirks.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "JavaScript Dependency Management and YUI Loader Quirks",
      "date": "2009-03-13"
    },
    "source": "\n[Brett](https://bzabos.wordpress.com/) and I recently began refactoring a significant amount of the JavaScript that is currently in [MyFrontSteps](https://www.myfrontsteps.com) and [Homebook](https://www.myfrontsteps.com/myfrontsteps/home/). One of the areas we identified as needing improvement was controlling when scripts get loaded in the page; it's a challenging subject especially when utilizing Django templates which can extend and include bits of HTML that are both static and dynamic. We're not finished the refactoring quite yet but I thought it would be valuable to blog about the lessons we've learned early on about how to manage JavaScript loading without having script tags all over the place.\n\n## Manual Dependency Management is Hard\n\nNot too long ago, Yahoo put out a list of [guidelines](https://developer.yahoo.com/performance/rules.html) that web developers can use to enhance the performance of their websites. I won't get into it in this post but there is a Firefox plugin called [YSlow](https://developer.yahoo.com/yslow/) available that can automate some of the performance checking. The recommendation I'm going to focus on here is the one regarding moving scripts as close to the bottom of the page as possible.\n\nI'll just quote the [Yahoo doc](https://developer.yahoo.com/performance/rules.html) as they explain it very clearly:\n\n> The problem caused by scripts is that they block parallel downloads. The > [HTTP/1.1 specification](https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.1.4) suggests that browsers download no more than two components in parallel per hostname. If you serve your images from multiple hostnames, you can get more than two downloads to occur in parallel. While a script is downloading, however, the browser won't start any other downloads, even on different hostnames. In some situations it's not easy to move scripts to the bottom. If, for example, the script uses `document.write`to insert part of the page's content, it can't be moved lower in the page. There might also be scoping issues. In many cases, there are ways to workaround these situations.\n\nIn the case of the code we're using on MyFrontSteps we had all kinds of Django templates with includes and templatetags that include other little bits of dynamic JavaScript that was adding markup to the DOM and manipulating DOM content. Some of this code would appear prior to certain dependent scripts being loaded which created a real nightmare for us as we had to manually track down the position of the dependent scripts in the page that was fed to the browser after a variable number of layers of templates and includes. We decided to research a better way to manage all these scripts and since we had been using the YUI library for many other parts of the website we settled on the [YUI loader](https://developer.yahoo.com/yui/yuiloader/).\n\n## YUI Loader Makes Dependency Management Easy\n\n> The YUI Loader Utility is a client-side JavaScript component that allows you to load specific YUI components and their dependencies into your page via script. YUI Loader can operate as a holistic solution by loading all of your necessary YUI components, or it can be used to add one or more components to a page on which some YUI content already exists.\n\nThe great thing about the YUI Loader is that you can use it to manage dependency sorting for all of the YUI components you use on a page but the *killer* feature\nimho is the fact that it allows you to create custom modules to load your own JS and CSS libraries. The basic pattern we're using in our root level Django template is as follows:\n\n1.  Load all CSS Files at the top of the template\n2.  Place all YUI Loader and other statically included scripts at the bottom of\n    the page prior to the closing BODY tag\n3.  Define the YUI Loader instance\n4.  Define custom modules for the YUI loader\n5.  Provide a Django template block to allow manipulation of the onSuccess\n    callback\n6.  Call the YUI Loaders .insert() method to trigger insertion of all dependency\n    sorted scripts into the DOM\n\nThe advantage to using the loader in conjunction with our root Django template is clear; all of our scripts are loaded at the bottom of the page and CSS is loaded at the top. When a user requests the pages they will start receiving the content from the server immediately and not have to wait for scripts to process as the loader dynamically inserts them into the HEAD element after the page content has been rendered. Another trick we're using to control when scripts get executed is by manipulating how the onSuccess callback of the loader works. Here's the code:\n\n```javascript\n// Instantiate and configure YUI Loader:\nMFSLoader = new YAHOO.util.YUILoader({\n    base: \"\",\n    require: [\"base\",\"reset-fonts-grids\",\"MFS\"],\n    loadOptional: false,\n    combine: true,\n    filter: \"MIN\",\n    allowRollup: true,\n    onSuccess: function() {\n        while( MFSLoader.onReady.length )  {\n            MFSLoader.onReady.shift()();\n        }\n    }\n});\n// Define a list of executables that we\n// can add to prior to page load completion\nMFSLoader.onReady = [];\n// Custom Modules for Loader\nMFSLoader.addModule({\n    name: 'MFS', type: 'js', varName: 'MFS',\n    path: '{% vurl \"/static/script/MFS.js\" %}',\n    requires: ['jQuery', 'jQueryUI']\n});\n{# Override this block if you need script at the global level. #}\n{% block global.script %}{% endblock %}\n// Trigger insertion of all dependency sorted scripts into the DOM\nMFSLoader.insert();\n```\n\nAs you can see we have a few of the custom modules defined here, which include a 'requires' attribute in the configuration object. This lets the YUI Loader know\nthat these files require the other modules to be loaded. The Loader then determines sort order for inclusion based on all required modules and goes to work inserting the scripts for you.\n\n## Tying it all Together\n\nThe key to making this work in the varying levels of Django templates is to manipulate the onSuccess callback. When the YUI Loader finishes loading all the dependency sorted scripts it will execute this callback and allow you to then execute any additional code that depends on the dynamically inserted scripts. We have a number of namespaced JS objects for MyFrontSteps (MFS.js, MFS.DataGrid.js etc..) and when we need to call functions defined in these objects we do so by extending the global.script block in our child template and pushing a new anonymous function onto the MFSLoader.onReady list we defined in the root template.\n\nHere's a simple example:\n\n```javascript\n{# A CHILD TEMPLATE #}\n{% block global.script %}\n    #include the parent templates global.script contents\n    {{ block.super }}\n    // Load our required features\n    MFSLoader.require( 'MFS.DataGrid', 'uploader', 'MFS.Uploader' );\n    // Push an anonymous function onto the list\n    // to get executed when all required scripts have been loaded\n    MFSLoader.onReady.push( function()  {\n        MFS.DataGrid.initPhotosGrid();\n    });\n{% endblock %}\n```\n\nOnce the page is rendered and the YUI Loader has finished parsing the loaded scripts the code we have in the onSuccess callback pops all the anonymous functions off the list which causes them to be executed.\n\n```javascript\n{# THE ONSUCCESS CALLBACK #}\nonSuccess: function() {\n    while( MFSLoader.onReady.length )  {\n        MFSLoader.onReady.shift()();\n    }\n}\n```\n\nWe still have a number of files to refactor, but the performance benefits we've seen so far using this approach have really made us confident that this is the way to go. Using a dependency manager that works for custom JS / CSS libraries is just so much more liberating than having to manually keep track of where scripts are getting executed. Because we're also migrating all of our code to external library files it makes things that much easier to debug in Firebug as\nwell.\n"
  },
  "attributes": {
    "title": "JavaScript Dependency Management and YUI Loader Quirks",
    "date": "2009-03-13"
  },
  "markdown": "\n[Brett](https://bzabos.wordpress.com/) and I recently began refactoring a significant amount of the JavaScript that is currently in [MyFrontSteps](https://www.myfrontsteps.com) and [Homebook](https://www.myfrontsteps.com/myfrontsteps/home/). One of the areas we identified as needing improvement was controlling when scripts get loaded in the page; it's a challenging subject especially when utilizing Django templates which can extend and include bits of HTML that are both static and dynamic. We're not finished the refactoring quite yet but I thought it would be valuable to blog about the lessons we've learned early on about how to manage JavaScript loading without having script tags all over the place.\n\n## Manual Dependency Management is Hard\n\nNot too long ago, Yahoo put out a list of [guidelines](https://developer.yahoo.com/performance/rules.html) that web developers can use to enhance the performance of their websites. I won't get into it in this post but there is a Firefox plugin called [YSlow](https://developer.yahoo.com/yslow/) available that can automate some of the performance checking. The recommendation I'm going to focus on here is the one regarding moving scripts as close to the bottom of the page as possible.\n\nI'll just quote the [Yahoo doc](https://developer.yahoo.com/performance/rules.html) as they explain it very clearly:\n\n> The problem caused by scripts is that they block parallel downloads. The > [HTTP/1.1 specification](https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.1.4) suggests that browsers download no more than two components in parallel per hostname. If you serve your images from multiple hostnames, you can get more than two downloads to occur in parallel. While a script is downloading, however, the browser won't start any other downloads, even on different hostnames. In some situations it's not easy to move scripts to the bottom. If, for example, the script uses `document.write`to insert part of the page's content, it can't be moved lower in the page. There might also be scoping issues. In many cases, there are ways to workaround these situations.\n\nIn the case of the code we're using on MyFrontSteps we had all kinds of Django templates with includes and templatetags that include other little bits of dynamic JavaScript that was adding markup to the DOM and manipulating DOM content. Some of this code would appear prior to certain dependent scripts being loaded which created a real nightmare for us as we had to manually track down the position of the dependent scripts in the page that was fed to the browser after a variable number of layers of templates and includes. We decided to research a better way to manage all these scripts and since we had been using the YUI library for many other parts of the website we settled on the [YUI loader](https://developer.yahoo.com/yui/yuiloader/).\n\n## YUI Loader Makes Dependency Management Easy\n\n> The YUI Loader Utility is a client-side JavaScript component that allows you to load specific YUI components and their dependencies into your page via script. YUI Loader can operate as a holistic solution by loading all of your necessary YUI components, or it can be used to add one or more components to a page on which some YUI content already exists.\n\nThe great thing about the YUI Loader is that you can use it to manage dependency sorting for all of the YUI components you use on a page but the *killer* feature\nimho is the fact that it allows you to create custom modules to load your own JS and CSS libraries. The basic pattern we're using in our root level Django template is as follows:\n\n1.  Load all CSS Files at the top of the template\n2.  Place all YUI Loader and other statically included scripts at the bottom of\n    the page prior to the closing BODY tag\n3.  Define the YUI Loader instance\n4.  Define custom modules for the YUI loader\n5.  Provide a Django template block to allow manipulation of the onSuccess\n    callback\n6.  Call the YUI Loaders .insert() method to trigger insertion of all dependency\n    sorted scripts into the DOM\n\nThe advantage to using the loader in conjunction with our root Django template is clear; all of our scripts are loaded at the bottom of the page and CSS is loaded at the top. When a user requests the pages they will start receiving the content from the server immediately and not have to wait for scripts to process as the loader dynamically inserts them into the HEAD element after the page content has been rendered. Another trick we're using to control when scripts get executed is by manipulating how the onSuccess callback of the loader works. Here's the code:\n\n```javascript\n// Instantiate and configure YUI Loader:\nMFSLoader = new YAHOO.util.YUILoader({\n    base: \"\",\n    require: [\"base\",\"reset-fonts-grids\",\"MFS\"],\n    loadOptional: false,\n    combine: true,\n    filter: \"MIN\",\n    allowRollup: true,\n    onSuccess: function() {\n        while( MFSLoader.onReady.length )  {\n            MFSLoader.onReady.shift()();\n        }\n    }\n});\n// Define a list of executables that we\n// can add to prior to page load completion\nMFSLoader.onReady = [];\n// Custom Modules for Loader\nMFSLoader.addModule({\n    name: 'MFS', type: 'js', varName: 'MFS',\n    path: '{% vurl \"/static/script/MFS.js\" %}',\n    requires: ['jQuery', 'jQueryUI']\n});\n{# Override this block if you need script at the global level. #}\n{% block global.script %}{% endblock %}\n// Trigger insertion of all dependency sorted scripts into the DOM\nMFSLoader.insert();\n```\n\nAs you can see we have a few of the custom modules defined here, which include a 'requires' attribute in the configuration object. This lets the YUI Loader know\nthat these files require the other modules to be loaded. The Loader then determines sort order for inclusion based on all required modules and goes to work inserting the scripts for you.\n\n## Tying it all Together\n\nThe key to making this work in the varying levels of Django templates is to manipulate the onSuccess callback. When the YUI Loader finishes loading all the dependency sorted scripts it will execute this callback and allow you to then execute any additional code that depends on the dynamically inserted scripts. We have a number of namespaced JS objects for MyFrontSteps (MFS.js, MFS.DataGrid.js etc..) and when we need to call functions defined in these objects we do so by extending the global.script block in our child template and pushing a new anonymous function onto the MFSLoader.onReady list we defined in the root template.\n\nHere's a simple example:\n\n```javascript\n{# A CHILD TEMPLATE #}\n{% block global.script %}\n    #include the parent templates global.script contents\n    {{ block.super }}\n    // Load our required features\n    MFSLoader.require( 'MFS.DataGrid', 'uploader', 'MFS.Uploader' );\n    // Push an anonymous function onto the list\n    // to get executed when all required scripts have been loaded\n    MFSLoader.onReady.push( function()  {\n        MFS.DataGrid.initPhotosGrid();\n    });\n{% endblock %}\n```\n\nOnce the page is rendered and the YUI Loader has finished parsing the loaded scripts the code we have in the onSuccess callback pops all the anonymous functions off the list which causes them to be executed.\n\n```javascript\n{# THE ONSUCCESS CALLBACK #}\nonSuccess: function() {\n    while( MFSLoader.onReady.length )  {\n        MFSLoader.onReady.shift()();\n    }\n}\n```\n\nWe still have a number of files to refactor, but the performance benefits we've seen so far using this approach have really made us confident that this is the way to go. Using a dependency manager that works for custom JS / CSS libraries is just so much more liberating than having to manually keep track of where scripts are getting executed. Because we're also migrating all of our code to external library files it makes things that much easier to debug in Firebug as\nwell.\n"
}></pre></div><div><a href="/posts/2008-12-17-application-usage-trends.html">Application Usage Trends</a><pre><{
  "path": "app/posts/2008-12-17-application-usage-trends.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Application Usage Trends",
      "date": "2008-12-17"
    },
    "source": "\n> If I had captured a snapshot of my application usage habits during each year of the last few years I think I would have discovered something like this:\n\n- **2005:**(Windows): Photoshop, Fireworks, Dreamweaver, Firefox\n- **2006:** (Windows/Linux): Fireworks, Komodo, Linux Terminal, Notepad, PHPMySQL, WAMP, Firefox (+Firebug)\n- **2007:**(Windows/OS X): Fireworks, Notepad, IntelliJ IDEA, Visual Studio, Firefox (+Firebug)\n- **2008:**(OS X): Fireworks, Textmate, OSX Terminal, Firefox (+Firebug)\n\nI've got nothing really insightful about these pseudo-stats, it just kind of struck me as I was working that I really don't use much of an IDE at all now.\n"
  },
  "attributes": {
    "title": "Application Usage Trends",
    "date": "2008-12-17"
  },
  "markdown": "\n> If I had captured a snapshot of my application usage habits during each year of the last few years I think I would have discovered something like this:\n\n- **2005:**(Windows): Photoshop, Fireworks, Dreamweaver, Firefox\n- **2006:** (Windows/Linux): Fireworks, Komodo, Linux Terminal, Notepad, PHPMySQL, WAMP, Firefox (+Firebug)\n- **2007:**(Windows/OS X): Fireworks, Notepad, IntelliJ IDEA, Visual Studio, Firefox (+Firebug)\n- **2008:**(OS X): Fireworks, Textmate, OSX Terminal, Firefox (+Firebug)\n\nI've got nothing really insightful about these pseudo-stats, it just kind of struck me as I was working that I really don't use much of an IDE at all now.\n"
}></{
  "path": "app/posts/2008-12-17-application-usage-trends.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Application Usage Trends",
      "date": "2008-12-17"
    },
    "source": "\n> If I had captured a snapshot of my application usage habits during each year of the last few years I think I would have discovered something like this:\n\n- **2005:**(Windows): Photoshop, Fireworks, Dreamweaver, Firefox\n- **2006:** (Windows/Linux): Fireworks, Komodo, Linux Terminal, Notepad, PHPMySQL, WAMP, Firefox (+Firebug)\n- **2007:**(Windows/OS X): Fireworks, Notepad, IntelliJ IDEA, Visual Studio, Firefox (+Firebug)\n- **2008:**(OS X): Fireworks, Textmate, OSX Terminal, Firefox (+Firebug)\n\nI've got nothing really insightful about these pseudo-stats, it just kind of struck me as I was working that I really don't use much of an IDE at all now.\n"
  },
  "attributes": {
    "title": "Application Usage Trends",
    "date": "2008-12-17"
  },
  "markdown": "\n> If I had captured a snapshot of my application usage habits during each year of the last few years I think I would have discovered something like this:\n\n- **2005:**(Windows): Photoshop, Fireworks, Dreamweaver, Firefox\n- **2006:** (Windows/Linux): Fireworks, Komodo, Linux Terminal, Notepad, PHPMySQL, WAMP, Firefox (+Firebug)\n- **2007:**(Windows/OS X): Fireworks, Notepad, IntelliJ IDEA, Visual Studio, Firefox (+Firebug)\n- **2008:**(OS X): Fireworks, Textmate, OSX Terminal, Firefox (+Firebug)\n\nI've got nothing really insightful about these pseudo-stats, it just kind of struck me as I was working that I really don't use much of an IDE at all now.\n"
}></pre></div><div><a href="/posts/2008-09-11-positive-dissatisfaction-and-scrum.html">Positive Dissatisfaction &amp; Scrum</a><pre><{
  "path": "app/posts/2008-09-11-positive-dissatisfaction-and-scrum.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Positive Dissatisfaction & Scrum",
      "date": "2008-09-11"
    },
    "source": "\n> There are some interesting things that happen when a job comes to you as opposed to the alternative (read: job hunting trying to find a company that fits you). When *you* fit the company things click.\n\nPerhaps I'm being a bit presumptuous with that last sentence, but it's truly how I feel working at VendAsta. This feeling is one of the things that has solidified this idea of positive dissatisfaction in my mind and how it can be a huge benefit to people in any field of work, but even more so to those in the world of software development.\n\nOur small development team for the MFS ([My Front Steps](https://www.myfrontsteps.com)) project is nearly completed now and I'm amazed at how well things are coming together. We have a very well rounded team of developers who all seem to be on the same page about things. Our experiences are varied and cover a broad spectrum of disciplines which gives great depth to such a small team. However, I believe the common uniting factor in what is going to make us such a great development team is the fact that we all realize that we haven't *arrived* in terms of our abilities. We don't know it all. *I* certainly don't know it all, and I'll switch to the first person from this point on as I don't want to put words in anyone's mouth.\n\n> I define \"*Positive* *Dissatisfaction*\" as a state of mind that reflects an individuals desire to continually better themselves by coming to the realization that they cannot be satisfied with the knowledge they have attained at any given point in time.\n\nI feel that in order to truly succeed in the field of software development that I have to continually admit that there is always a better way to do things than the way I think things should be done. My goal is to reinvent myself every day with the knowledge I learn from others, the web, and, more generally, my life experience.\n\nI believe that Positive Dissatisfaction fits great with the Scrum development methodology. Short iterations offer a huge opportunity for team members to improve their development practices and experience the benefits of learning quickly from one another. The fact that the team is self regulating in terms of task load, allocation, and followup promotes a great sense of ownership in the project that reinforces a sense of continual refinement of processes. I certainly don't want to be contributing code/resources to the project that was the result of some half-assed effort. All of these factors help me to keep myself in a continual state of Positive Dissatisfaction (have I said that enough yet?) so that I'm attempting to contribute with a 110% effort.\n\nWhen you fit the company, it really makes you want to contribute that way\n"
  },
  "attributes": {
    "title": "Positive Dissatisfaction & Scrum",
    "date": "2008-09-11"
  },
  "markdown": "\n> There are some interesting things that happen when a job comes to you as opposed to the alternative (read: job hunting trying to find a company that fits you). When *you* fit the company things click.\n\nPerhaps I'm being a bit presumptuous with that last sentence, but it's truly how I feel working at VendAsta. This feeling is one of the things that has solidified this idea of positive dissatisfaction in my mind and how it can be a huge benefit to people in any field of work, but even more so to those in the world of software development.\n\nOur small development team for the MFS ([My Front Steps](https://www.myfrontsteps.com)) project is nearly completed now and I'm amazed at how well things are coming together. We have a very well rounded team of developers who all seem to be on the same page about things. Our experiences are varied and cover a broad spectrum of disciplines which gives great depth to such a small team. However, I believe the common uniting factor in what is going to make us such a great development team is the fact that we all realize that we haven't *arrived* in terms of our abilities. We don't know it all. *I* certainly don't know it all, and I'll switch to the first person from this point on as I don't want to put words in anyone's mouth.\n\n> I define \"*Positive* *Dissatisfaction*\" as a state of mind that reflects an individuals desire to continually better themselves by coming to the realization that they cannot be satisfied with the knowledge they have attained at any given point in time.\n\nI feel that in order to truly succeed in the field of software development that I have to continually admit that there is always a better way to do things than the way I think things should be done. My goal is to reinvent myself every day with the knowledge I learn from others, the web, and, more generally, my life experience.\n\nI believe that Positive Dissatisfaction fits great with the Scrum development methodology. Short iterations offer a huge opportunity for team members to improve their development practices and experience the benefits of learning quickly from one another. The fact that the team is self regulating in terms of task load, allocation, and followup promotes a great sense of ownership in the project that reinforces a sense of continual refinement of processes. I certainly don't want to be contributing code/resources to the project that was the result of some half-assed effort. All of these factors help me to keep myself in a continual state of Positive Dissatisfaction (have I said that enough yet?) so that I'm attempting to contribute with a 110% effort.\n\nWhen you fit the company, it really makes you want to contribute that way\n"
}></{
  "path": "app/posts/2008-09-11-positive-dissatisfaction-and-scrum.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Positive Dissatisfaction & Scrum",
      "date": "2008-09-11"
    },
    "source": "\n> There are some interesting things that happen when a job comes to you as opposed to the alternative (read: job hunting trying to find a company that fits you). When *you* fit the company things click.\n\nPerhaps I'm being a bit presumptuous with that last sentence, but it's truly how I feel working at VendAsta. This feeling is one of the things that has solidified this idea of positive dissatisfaction in my mind and how it can be a huge benefit to people in any field of work, but even more so to those in the world of software development.\n\nOur small development team for the MFS ([My Front Steps](https://www.myfrontsteps.com)) project is nearly completed now and I'm amazed at how well things are coming together. We have a very well rounded team of developers who all seem to be on the same page about things. Our experiences are varied and cover a broad spectrum of disciplines which gives great depth to such a small team. However, I believe the common uniting factor in what is going to make us such a great development team is the fact that we all realize that we haven't *arrived* in terms of our abilities. We don't know it all. *I* certainly don't know it all, and I'll switch to the first person from this point on as I don't want to put words in anyone's mouth.\n\n> I define \"*Positive* *Dissatisfaction*\" as a state of mind that reflects an individuals desire to continually better themselves by coming to the realization that they cannot be satisfied with the knowledge they have attained at any given point in time.\n\nI feel that in order to truly succeed in the field of software development that I have to continually admit that there is always a better way to do things than the way I think things should be done. My goal is to reinvent myself every day with the knowledge I learn from others, the web, and, more generally, my life experience.\n\nI believe that Positive Dissatisfaction fits great with the Scrum development methodology. Short iterations offer a huge opportunity for team members to improve their development practices and experience the benefits of learning quickly from one another. The fact that the team is self regulating in terms of task load, allocation, and followup promotes a great sense of ownership in the project that reinforces a sense of continual refinement of processes. I certainly don't want to be contributing code/resources to the project that was the result of some half-assed effort. All of these factors help me to keep myself in a continual state of Positive Dissatisfaction (have I said that enough yet?) so that I'm attempting to contribute with a 110% effort.\n\nWhen you fit the company, it really makes you want to contribute that way\n"
  },
  "attributes": {
    "title": "Positive Dissatisfaction & Scrum",
    "date": "2008-09-11"
  },
  "markdown": "\n> There are some interesting things that happen when a job comes to you as opposed to the alternative (read: job hunting trying to find a company that fits you). When *you* fit the company things click.\n\nPerhaps I'm being a bit presumptuous with that last sentence, but it's truly how I feel working at VendAsta. This feeling is one of the things that has solidified this idea of positive dissatisfaction in my mind and how it can be a huge benefit to people in any field of work, but even more so to those in the world of software development.\n\nOur small development team for the MFS ([My Front Steps](https://www.myfrontsteps.com)) project is nearly completed now and I'm amazed at how well things are coming together. We have a very well rounded team of developers who all seem to be on the same page about things. Our experiences are varied and cover a broad spectrum of disciplines which gives great depth to such a small team. However, I believe the common uniting factor in what is going to make us such a great development team is the fact that we all realize that we haven't *arrived* in terms of our abilities. We don't know it all. *I* certainly don't know it all, and I'll switch to the first person from this point on as I don't want to put words in anyone's mouth.\n\n> I define \"*Positive* *Dissatisfaction*\" as a state of mind that reflects an individuals desire to continually better themselves by coming to the realization that they cannot be satisfied with the knowledge they have attained at any given point in time.\n\nI feel that in order to truly succeed in the field of software development that I have to continually admit that there is always a better way to do things than the way I think things should be done. My goal is to reinvent myself every day with the knowledge I learn from others, the web, and, more generally, my life experience.\n\nI believe that Positive Dissatisfaction fits great with the Scrum development methodology. Short iterations offer a huge opportunity for team members to improve their development practices and experience the benefits of learning quickly from one another. The fact that the team is self regulating in terms of task load, allocation, and followup promotes a great sense of ownership in the project that reinforces a sense of continual refinement of processes. I certainly don't want to be contributing code/resources to the project that was the result of some half-assed effort. All of these factors help me to keep myself in a continual state of Positive Dissatisfaction (have I said that enough yet?) so that I'm attempting to contribute with a 110% effort.\n\nWhen you fit the company, it really makes you want to contribute that way\n"
}></pre></div><div><a href="/posts/2008-08-27-on-work-macs-python-google-app-engine-and-django.html">On Work, Macs, Python, Google App Engine &amp; Django</a><pre><{
  "path": "app/posts/2008-08-27-on-work-macs-python-google-app-engine-and-django.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "On Work, Macs, Python, Google App Engine & Django",
      "date": "2008-08-27"
    },
    "source": "\nI've been at VendAsta for a week now and I'm happy to say that my initial impressions haven't changed all that much. It's really fulfilling to go in every day and feel totally engaged and encouraged by both the work you're doing and the people you're working with. I've heard some people say negative things about VendAsta; things like *\"they won't be around longer than 8 months\"* or *\"they're just a start up, how can they hope to accomplish anything\"*. I find most of the people saying these things are either uninformed about what it is we're working on or just spiteful for some reason. Well, to those of you in either camp let me enlighten you.\n\n\n## On Work\n\nVendAsta is about building **quality** software. VendAsta is about **empowering** people by allowing them to work on the things they are **passionate** about. Right now the team I'm working on is building a social marketing tool that will enable homeowners and home industry service providers to share their experiences on whatever social network they happen to be using. There is a lot of room for movement in this area of the social networking sphere, particularly because nobody else has really taken advantage of the online experience as it relates to our homes and home experiences. Rennovations, improvements, parties, appliances you purchased, decorating tips... the list of things people can share about their homes goes on and on. So when I hear people predicting the downfall of VendAsta I really think they have no clue about how much potential there is in the market segment we're working in. Oh and did I mention, that's only 1/2 of what we do?\n\n## On Macs\n\nI made the switch to working on a Mac at home about 8 months ago. It was more of a novelty at the time, but I needed a change and was tired of \"*tweaking\"*my PC when I got home from work. I did manage to learn some important tricks about OS X and get a glimpse of what actually \"*working*\" on one would be like. Flash forward some 9 months and I work full time on a MacBook Pro developing with some of the most [intriguing](https://code.google.com/appengine/) [technologies](https://www.python.org) out there. The only thing holding me back to Windows for the longest time was the games, and I find now that most of my [gaming](https://www.worldofwarcraft.com) plays better on my iMac anyways. The keyboard shortcuts are kind of a pain to get used to, but once you realize you actually have an additional modifier key to work with things just kind of click.\n\n## On Python\n\nPython is neat. It's kind of like JavaScript with less of the syntax cruft (hooray for no more semicolons). It's also kind of like C (I think some of the base libraries are actually written in C) and while I don't have a lot of C experience, the one [class](https://programs.siast.sk.ca/cst/cosc286/) I did take was very enjoyable. It's like you get all the power in the lower level like C but without all the syntax nightmares; you also have access to a lot of libraries. Writing python is kind of like writing [pseudo code](https://en.wikipedia.org/wiki/Pseudocode), which is a good fit for me because I always thought I was better at coming up with pseudo code algorithms than actually programming.\n\nIf you're interested in learning I can't recommend this book enough: [Dive Into Python](https://www.diveintopython.org). The best part is, you can download a full [PDF](https://diveintopython.org/download/diveintopython-pdf-5.4.zip) of the book entirely free! I'm only about half way through so far but it's written in a very easy to understand style and comes with many code examples in the zip file. If you're following along using the examples on a Mac it's even better because Leopard comes already installed with Python 2.5. Yes, working with Python is good stuff.\n\n## On Google App Engine (GAE)\n\nGoogle App Engine is an interesting beast. I've read some [articles](https://highscalability.com/google-appengine-second-look) already about how it's changing development paradigms and forcing developers to think about scalability and data access in a completely different way. I don't purport to be a database expert but from what I've read GAE uses a storage system called [BigTable](https://labs.google.com/papers/bigtable.html) that differs radically from typical RDBS (Relational Database Systems). While this doesn't affect me directly (yet) I find it interesting to read about problems like scalability. The GAE DataStore API is really simple yet effective, and so far the documentation has been really easy to read and the code examples really easy to follow. A few [posts](https://groups.google.com/group/google-appengine/browse_thread/thread/3cbad64e01d18d9c/71b01f183bd1a5cc?lnk=gst&q=scalability#71b01f183bd1a5cc) in the [Google Groups section for GAE](https://groups.google.com/group/google-appengine) have some further detail on performance testing and the results are intriguing. My only beef so far with GAE is with running Django on it and the fact that there seems to be a few established ways of running it but no \"standard\" way:\n\n1.  [Google Code - Running Django on Google App Engine](https://code.google.com/appengine/articles/django.html)\n2.  [GC Project - Google-AppEngine-Django](https://code.google.com/p/google-app-engine-django/)\n3.  [Guido van Rossum - Rietveld (sample django on GAE project)](https://code.google.com/p/rietveld/)\n\nI've been working hard to try and figure out some of the best practices for running Django on GAE but I suppose a lot of this is subject to potential change considering GAE is still in PREVIEW RELEASE mode and the Django 1.0 release is still a few weeks away. I don't anticipate too much change though as there is quite a bit of the API already established. I guess it's a good thing we're using the latest SVN releases of Django instead of the default 0.96, 0.97 releases GAE comes with by default.\n\n## On Django\n\nI tried doing some tutorials on the [Django](https://www.djangoproject.com) website a few months back and while it was really cool seeing all the *\"magic\"* stuff that you got for free with things like the admin interface, ORM layer etc... I don't think I really appreciated the power of what it can do until I started reading Dive Into Python. Since Django is written in Python it really helps to have an understanding of the language at a more rudimentary level to see exactly how Django works and to avoid the *\"wtf?! how did it do that?\"*questions I was having previously. It seems to me that the guys who built Django really understand what's tedious about building web applications and they've created this set of tools to make web application development much more enjoyable.\n\nI personally enjoy working on backend stuff like configuration, deployment, [ORM](https://en.wikipedia.org/wiki/Object-relational_mapping) setup and working with Django + GAE is really nice for all of that, but at the same time part of me really enjoys constructing the CSS, XHTML templates, implementing [jQuery](https://www.jquery.com) and YUI for effects and interface widgets, and actually designing the graphics... all of the more frontend type work. I consider myself a\n[Sweeper](https://gettingreal.37signals.com/ch03_The_Three_Musketeers.php) (read the first paragraph), although more of a frontend leaning Sweeper, but working with the tools and technologies I am able to work with here at VendAsta has really empowered me to *\"sweep\"*from frontend to backend and picking up all kinds of knowledge everywhere in between. Just one more thing that makes me really feel like I've finally found a job that fits with my never ending thirst to work in both worlds.\n\nDid I mention, [we're hiring?](https://vendasta.com/careers/)\n"
  },
  "attributes": {
    "title": "On Work, Macs, Python, Google App Engine & Django",
    "date": "2008-08-27"
  },
  "markdown": "\nI've been at VendAsta for a week now and I'm happy to say that my initial impressions haven't changed all that much. It's really fulfilling to go in every day and feel totally engaged and encouraged by both the work you're doing and the people you're working with. I've heard some people say negative things about VendAsta; things like *\"they won't be around longer than 8 months\"* or *\"they're just a start up, how can they hope to accomplish anything\"*. I find most of the people saying these things are either uninformed about what it is we're working on or just spiteful for some reason. Well, to those of you in either camp let me enlighten you.\n\n\n## On Work\n\nVendAsta is about building **quality** software. VendAsta is about **empowering** people by allowing them to work on the things they are **passionate** about. Right now the team I'm working on is building a social marketing tool that will enable homeowners and home industry service providers to share their experiences on whatever social network they happen to be using. There is a lot of room for movement in this area of the social networking sphere, particularly because nobody else has really taken advantage of the online experience as it relates to our homes and home experiences. Rennovations, improvements, parties, appliances you purchased, decorating tips... the list of things people can share about their homes goes on and on. So when I hear people predicting the downfall of VendAsta I really think they have no clue about how much potential there is in the market segment we're working in. Oh and did I mention, that's only 1/2 of what we do?\n\n## On Macs\n\nI made the switch to working on a Mac at home about 8 months ago. It was more of a novelty at the time, but I needed a change and was tired of \"*tweaking\"*my PC when I got home from work. I did manage to learn some important tricks about OS X and get a glimpse of what actually \"*working*\" on one would be like. Flash forward some 9 months and I work full time on a MacBook Pro developing with some of the most [intriguing](https://code.google.com/appengine/) [technologies](https://www.python.org) out there. The only thing holding me back to Windows for the longest time was the games, and I find now that most of my [gaming](https://www.worldofwarcraft.com) plays better on my iMac anyways. The keyboard shortcuts are kind of a pain to get used to, but once you realize you actually have an additional modifier key to work with things just kind of click.\n\n## On Python\n\nPython is neat. It's kind of like JavaScript with less of the syntax cruft (hooray for no more semicolons). It's also kind of like C (I think some of the base libraries are actually written in C) and while I don't have a lot of C experience, the one [class](https://programs.siast.sk.ca/cst/cosc286/) I did take was very enjoyable. It's like you get all the power in the lower level like C but without all the syntax nightmares; you also have access to a lot of libraries. Writing python is kind of like writing [pseudo code](https://en.wikipedia.org/wiki/Pseudocode), which is a good fit for me because I always thought I was better at coming up with pseudo code algorithms than actually programming.\n\nIf you're interested in learning I can't recommend this book enough: [Dive Into Python](https://www.diveintopython.org). The best part is, you can download a full [PDF](https://diveintopython.org/download/diveintopython-pdf-5.4.zip) of the book entirely free! I'm only about half way through so far but it's written in a very easy to understand style and comes with many code examples in the zip file. If you're following along using the examples on a Mac it's even better because Leopard comes already installed with Python 2.5. Yes, working with Python is good stuff.\n\n## On Google App Engine (GAE)\n\nGoogle App Engine is an interesting beast. I've read some [articles](https://highscalability.com/google-appengine-second-look) already about how it's changing development paradigms and forcing developers to think about scalability and data access in a completely different way. I don't purport to be a database expert but from what I've read GAE uses a storage system called [BigTable](https://labs.google.com/papers/bigtable.html) that differs radically from typical RDBS (Relational Database Systems). While this doesn't affect me directly (yet) I find it interesting to read about problems like scalability. The GAE DataStore API is really simple yet effective, and so far the documentation has been really easy to read and the code examples really easy to follow. A few [posts](https://groups.google.com/group/google-appengine/browse_thread/thread/3cbad64e01d18d9c/71b01f183bd1a5cc?lnk=gst&q=scalability#71b01f183bd1a5cc) in the [Google Groups section for GAE](https://groups.google.com/group/google-appengine) have some further detail on performance testing and the results are intriguing. My only beef so far with GAE is with running Django on it and the fact that there seems to be a few established ways of running it but no \"standard\" way:\n\n1.  [Google Code - Running Django on Google App Engine](https://code.google.com/appengine/articles/django.html)\n2.  [GC Project - Google-AppEngine-Django](https://code.google.com/p/google-app-engine-django/)\n3.  [Guido van Rossum - Rietveld (sample django on GAE project)](https://code.google.com/p/rietveld/)\n\nI've been working hard to try and figure out some of the best practices for running Django on GAE but I suppose a lot of this is subject to potential change considering GAE is still in PREVIEW RELEASE mode and the Django 1.0 release is still a few weeks away. I don't anticipate too much change though as there is quite a bit of the API already established. I guess it's a good thing we're using the latest SVN releases of Django instead of the default 0.96, 0.97 releases GAE comes with by default.\n\n## On Django\n\nI tried doing some tutorials on the [Django](https://www.djangoproject.com) website a few months back and while it was really cool seeing all the *\"magic\"* stuff that you got for free with things like the admin interface, ORM layer etc... I don't think I really appreciated the power of what it can do until I started reading Dive Into Python. Since Django is written in Python it really helps to have an understanding of the language at a more rudimentary level to see exactly how Django works and to avoid the *\"wtf?! how did it do that?\"*questions I was having previously. It seems to me that the guys who built Django really understand what's tedious about building web applications and they've created this set of tools to make web application development much more enjoyable.\n\nI personally enjoy working on backend stuff like configuration, deployment, [ORM](https://en.wikipedia.org/wiki/Object-relational_mapping) setup and working with Django + GAE is really nice for all of that, but at the same time part of me really enjoys constructing the CSS, XHTML templates, implementing [jQuery](https://www.jquery.com) and YUI for effects and interface widgets, and actually designing the graphics... all of the more frontend type work. I consider myself a\n[Sweeper](https://gettingreal.37signals.com/ch03_The_Three_Musketeers.php) (read the first paragraph), although more of a frontend leaning Sweeper, but working with the tools and technologies I am able to work with here at VendAsta has really empowered me to *\"sweep\"*from frontend to backend and picking up all kinds of knowledge everywhere in between. Just one more thing that makes me really feel like I've finally found a job that fits with my never ending thirst to work in both worlds.\n\nDid I mention, [we're hiring?](https://vendasta.com/careers/)\n"
}></{
  "path": "app/posts/2008-08-27-on-work-macs-python-google-app-engine-and-django.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "On Work, Macs, Python, Google App Engine & Django",
      "date": "2008-08-27"
    },
    "source": "\nI've been at VendAsta for a week now and I'm happy to say that my initial impressions haven't changed all that much. It's really fulfilling to go in every day and feel totally engaged and encouraged by both the work you're doing and the people you're working with. I've heard some people say negative things about VendAsta; things like *\"they won't be around longer than 8 months\"* or *\"they're just a start up, how can they hope to accomplish anything\"*. I find most of the people saying these things are either uninformed about what it is we're working on or just spiteful for some reason. Well, to those of you in either camp let me enlighten you.\n\n\n## On Work\n\nVendAsta is about building **quality** software. VendAsta is about **empowering** people by allowing them to work on the things they are **passionate** about. Right now the team I'm working on is building a social marketing tool that will enable homeowners and home industry service providers to share their experiences on whatever social network they happen to be using. There is a lot of room for movement in this area of the social networking sphere, particularly because nobody else has really taken advantage of the online experience as it relates to our homes and home experiences. Rennovations, improvements, parties, appliances you purchased, decorating tips... the list of things people can share about their homes goes on and on. So when I hear people predicting the downfall of VendAsta I really think they have no clue about how much potential there is in the market segment we're working in. Oh and did I mention, that's only 1/2 of what we do?\n\n## On Macs\n\nI made the switch to working on a Mac at home about 8 months ago. It was more of a novelty at the time, but I needed a change and was tired of \"*tweaking\"*my PC when I got home from work. I did manage to learn some important tricks about OS X and get a glimpse of what actually \"*working*\" on one would be like. Flash forward some 9 months and I work full time on a MacBook Pro developing with some of the most [intriguing](https://code.google.com/appengine/) [technologies](https://www.python.org) out there. The only thing holding me back to Windows for the longest time was the games, and I find now that most of my [gaming](https://www.worldofwarcraft.com) plays better on my iMac anyways. The keyboard shortcuts are kind of a pain to get used to, but once you realize you actually have an additional modifier key to work with things just kind of click.\n\n## On Python\n\nPython is neat. It's kind of like JavaScript with less of the syntax cruft (hooray for no more semicolons). It's also kind of like C (I think some of the base libraries are actually written in C) and while I don't have a lot of C experience, the one [class](https://programs.siast.sk.ca/cst/cosc286/) I did take was very enjoyable. It's like you get all the power in the lower level like C but without all the syntax nightmares; you also have access to a lot of libraries. Writing python is kind of like writing [pseudo code](https://en.wikipedia.org/wiki/Pseudocode), which is a good fit for me because I always thought I was better at coming up with pseudo code algorithms than actually programming.\n\nIf you're interested in learning I can't recommend this book enough: [Dive Into Python](https://www.diveintopython.org). The best part is, you can download a full [PDF](https://diveintopython.org/download/diveintopython-pdf-5.4.zip) of the book entirely free! I'm only about half way through so far but it's written in a very easy to understand style and comes with many code examples in the zip file. If you're following along using the examples on a Mac it's even better because Leopard comes already installed with Python 2.5. Yes, working with Python is good stuff.\n\n## On Google App Engine (GAE)\n\nGoogle App Engine is an interesting beast. I've read some [articles](https://highscalability.com/google-appengine-second-look) already about how it's changing development paradigms and forcing developers to think about scalability and data access in a completely different way. I don't purport to be a database expert but from what I've read GAE uses a storage system called [BigTable](https://labs.google.com/papers/bigtable.html) that differs radically from typical RDBS (Relational Database Systems). While this doesn't affect me directly (yet) I find it interesting to read about problems like scalability. The GAE DataStore API is really simple yet effective, and so far the documentation has been really easy to read and the code examples really easy to follow. A few [posts](https://groups.google.com/group/google-appengine/browse_thread/thread/3cbad64e01d18d9c/71b01f183bd1a5cc?lnk=gst&q=scalability#71b01f183bd1a5cc) in the [Google Groups section for GAE](https://groups.google.com/group/google-appengine) have some further detail on performance testing and the results are intriguing. My only beef so far with GAE is with running Django on it and the fact that there seems to be a few established ways of running it but no \"standard\" way:\n\n1.  [Google Code - Running Django on Google App Engine](https://code.google.com/appengine/articles/django.html)\n2.  [GC Project - Google-AppEngine-Django](https://code.google.com/p/google-app-engine-django/)\n3.  [Guido van Rossum - Rietveld (sample django on GAE project)](https://code.google.com/p/rietveld/)\n\nI've been working hard to try and figure out some of the best practices for running Django on GAE but I suppose a lot of this is subject to potential change considering GAE is still in PREVIEW RELEASE mode and the Django 1.0 release is still a few weeks away. I don't anticipate too much change though as there is quite a bit of the API already established. I guess it's a good thing we're using the latest SVN releases of Django instead of the default 0.96, 0.97 releases GAE comes with by default.\n\n## On Django\n\nI tried doing some tutorials on the [Django](https://www.djangoproject.com) website a few months back and while it was really cool seeing all the *\"magic\"* stuff that you got for free with things like the admin interface, ORM layer etc... I don't think I really appreciated the power of what it can do until I started reading Dive Into Python. Since Django is written in Python it really helps to have an understanding of the language at a more rudimentary level to see exactly how Django works and to avoid the *\"wtf?! how did it do that?\"*questions I was having previously. It seems to me that the guys who built Django really understand what's tedious about building web applications and they've created this set of tools to make web application development much more enjoyable.\n\nI personally enjoy working on backend stuff like configuration, deployment, [ORM](https://en.wikipedia.org/wiki/Object-relational_mapping) setup and working with Django + GAE is really nice for all of that, but at the same time part of me really enjoys constructing the CSS, XHTML templates, implementing [jQuery](https://www.jquery.com) and YUI for effects and interface widgets, and actually designing the graphics... all of the more frontend type work. I consider myself a\n[Sweeper](https://gettingreal.37signals.com/ch03_The_Three_Musketeers.php) (read the first paragraph), although more of a frontend leaning Sweeper, but working with the tools and technologies I am able to work with here at VendAsta has really empowered me to *\"sweep\"*from frontend to backend and picking up all kinds of knowledge everywhere in between. Just one more thing that makes me really feel like I've finally found a job that fits with my never ending thirst to work in both worlds.\n\nDid I mention, [we're hiring?](https://vendasta.com/careers/)\n"
  },
  "attributes": {
    "title": "On Work, Macs, Python, Google App Engine & Django",
    "date": "2008-08-27"
  },
  "markdown": "\nI've been at VendAsta for a week now and I'm happy to say that my initial impressions haven't changed all that much. It's really fulfilling to go in every day and feel totally engaged and encouraged by both the work you're doing and the people you're working with. I've heard some people say negative things about VendAsta; things like *\"they won't be around longer than 8 months\"* or *\"they're just a start up, how can they hope to accomplish anything\"*. I find most of the people saying these things are either uninformed about what it is we're working on or just spiteful for some reason. Well, to those of you in either camp let me enlighten you.\n\n\n## On Work\n\nVendAsta is about building **quality** software. VendAsta is about **empowering** people by allowing them to work on the things they are **passionate** about. Right now the team I'm working on is building a social marketing tool that will enable homeowners and home industry service providers to share their experiences on whatever social network they happen to be using. There is a lot of room for movement in this area of the social networking sphere, particularly because nobody else has really taken advantage of the online experience as it relates to our homes and home experiences. Rennovations, improvements, parties, appliances you purchased, decorating tips... the list of things people can share about their homes goes on and on. So when I hear people predicting the downfall of VendAsta I really think they have no clue about how much potential there is in the market segment we're working in. Oh and did I mention, that's only 1/2 of what we do?\n\n## On Macs\n\nI made the switch to working on a Mac at home about 8 months ago. It was more of a novelty at the time, but I needed a change and was tired of \"*tweaking\"*my PC when I got home from work. I did manage to learn some important tricks about OS X and get a glimpse of what actually \"*working*\" on one would be like. Flash forward some 9 months and I work full time on a MacBook Pro developing with some of the most [intriguing](https://code.google.com/appengine/) [technologies](https://www.python.org) out there. The only thing holding me back to Windows for the longest time was the games, and I find now that most of my [gaming](https://www.worldofwarcraft.com) plays better on my iMac anyways. The keyboard shortcuts are kind of a pain to get used to, but once you realize you actually have an additional modifier key to work with things just kind of click.\n\n## On Python\n\nPython is neat. It's kind of like JavaScript with less of the syntax cruft (hooray for no more semicolons). It's also kind of like C (I think some of the base libraries are actually written in C) and while I don't have a lot of C experience, the one [class](https://programs.siast.sk.ca/cst/cosc286/) I did take was very enjoyable. It's like you get all the power in the lower level like C but without all the syntax nightmares; you also have access to a lot of libraries. Writing python is kind of like writing [pseudo code](https://en.wikipedia.org/wiki/Pseudocode), which is a good fit for me because I always thought I was better at coming up with pseudo code algorithms than actually programming.\n\nIf you're interested in learning I can't recommend this book enough: [Dive Into Python](https://www.diveintopython.org). The best part is, you can download a full [PDF](https://diveintopython.org/download/diveintopython-pdf-5.4.zip) of the book entirely free! I'm only about half way through so far but it's written in a very easy to understand style and comes with many code examples in the zip file. If you're following along using the examples on a Mac it's even better because Leopard comes already installed with Python 2.5. Yes, working with Python is good stuff.\n\n## On Google App Engine (GAE)\n\nGoogle App Engine is an interesting beast. I've read some [articles](https://highscalability.com/google-appengine-second-look) already about how it's changing development paradigms and forcing developers to think about scalability and data access in a completely different way. I don't purport to be a database expert but from what I've read GAE uses a storage system called [BigTable](https://labs.google.com/papers/bigtable.html) that differs radically from typical RDBS (Relational Database Systems). While this doesn't affect me directly (yet) I find it interesting to read about problems like scalability. The GAE DataStore API is really simple yet effective, and so far the documentation has been really easy to read and the code examples really easy to follow. A few [posts](https://groups.google.com/group/google-appengine/browse_thread/thread/3cbad64e01d18d9c/71b01f183bd1a5cc?lnk=gst&q=scalability#71b01f183bd1a5cc) in the [Google Groups section for GAE](https://groups.google.com/group/google-appengine) have some further detail on performance testing and the results are intriguing. My only beef so far with GAE is with running Django on it and the fact that there seems to be a few established ways of running it but no \"standard\" way:\n\n1.  [Google Code - Running Django on Google App Engine](https://code.google.com/appengine/articles/django.html)\n2.  [GC Project - Google-AppEngine-Django](https://code.google.com/p/google-app-engine-django/)\n3.  [Guido van Rossum - Rietveld (sample django on GAE project)](https://code.google.com/p/rietveld/)\n\nI've been working hard to try and figure out some of the best practices for running Django on GAE but I suppose a lot of this is subject to potential change considering GAE is still in PREVIEW RELEASE mode and the Django 1.0 release is still a few weeks away. I don't anticipate too much change though as there is quite a bit of the API already established. I guess it's a good thing we're using the latest SVN releases of Django instead of the default 0.96, 0.97 releases GAE comes with by default.\n\n## On Django\n\nI tried doing some tutorials on the [Django](https://www.djangoproject.com) website a few months back and while it was really cool seeing all the *\"magic\"* stuff that you got for free with things like the admin interface, ORM layer etc... I don't think I really appreciated the power of what it can do until I started reading Dive Into Python. Since Django is written in Python it really helps to have an understanding of the language at a more rudimentary level to see exactly how Django works and to avoid the *\"wtf?! how did it do that?\"*questions I was having previously. It seems to me that the guys who built Django really understand what's tedious about building web applications and they've created this set of tools to make web application development much more enjoyable.\n\nI personally enjoy working on backend stuff like configuration, deployment, [ORM](https://en.wikipedia.org/wiki/Object-relational_mapping) setup and working with Django + GAE is really nice for all of that, but at the same time part of me really enjoys constructing the CSS, XHTML templates, implementing [jQuery](https://www.jquery.com) and YUI for effects and interface widgets, and actually designing the graphics... all of the more frontend type work. I consider myself a\n[Sweeper](https://gettingreal.37signals.com/ch03_The_Three_Musketeers.php) (read the first paragraph), although more of a frontend leaning Sweeper, but working with the tools and technologies I am able to work with here at VendAsta has really empowered me to *\"sweep\"*from frontend to backend and picking up all kinds of knowledge everywhere in between. Just one more thing that makes me really feel like I've finally found a job that fits with my never ending thirst to work in both worlds.\n\nDid I mention, [we're hiring?](https://vendasta.com/careers/)\n"
}></pre></div><div><a href="/posts/2008-08-18-work-bliss.html">Work Bliss</a><pre><{
  "path": "app/posts/2008-08-18-work-bliss.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Work Bliss",
      "date": "2008-08-18"
    },
    "source": "\n> Normally I think most people would associate work with emotions other than bliss.\n\nIt's not often in life you can find yourself working in a job with people who are on the same page as you. It's also not too often in life you can find yourself working in a job where the things you are passionately interested in are what people want you to work on. Combine the two previously mentioned \"hard-to-find\" qualities with a brand new MacBook Pro and a healthy salary (there's something to be said for getting paid well for the things you love to do) and you have what I would consider the recipe for the perfect job; aka: work bliss.\n\nToday is my first day at [VendAsta](https://www.vendasta.com) and already I've been able to configure my work environment the way I want (3 cheers for [TextMate](https://macromates.com/), [SVN](https://subversion.tigris.org/), [FireBug](https://www.getfirebug.com), [FireWorks](https://www.adobe.com/fireworks)) after being told if there was anything I need to just let them know and they'd have no problem getting it. So I got right into things, checked out a few projects from SVN that we're working on utilizing [Django](https://www.djangoproject.com) and [Google App Engine](https://code.google.com/appengine/). Normally at a new job you'd probably have a lot of red tape and \"new hire\" overhead to go through; not at VendAsta.\n\n<**sarcasm**>I couldn't believe there was **gasp** documentation for the projects!</**sarcasm**> There's something to be said for working with quality processes like [Scrum](https://en.wikipedia.org/wiki/Scrum_(development)) and [Agile](https://en.wikipedia.org/wiki/Agile_software_development), and great tools like [JIRA](https://www.atlassian.com/software/jira/) and [GoogleApps](https://www.google.com/a/help/intl/en/index.html) at a software development company; try working without these things, it's just not fun.\n\nI think the thing I've been impressed with most in my first day at VendAsta is the fact that there are people who are willing to listen to my ideas. I don't feel intimidated at all, the culture here is very welcoming and open and the tools provided make it very easy to actually want to be as productive as you can be. Obviously it's only the first day on the job so I can't expect you all to take everything I'm saying at face value. Time will tell how things pan out, but after the first day I can definitely say that my first day @ VendAsta has been far more enlightening and empowering than a couple of years working for other companies.\n"
  },
  "attributes": {
    "title": "Work Bliss",
    "date": "2008-08-18"
  },
  "markdown": "\n> Normally I think most people would associate work with emotions other than bliss.\n\nIt's not often in life you can find yourself working in a job with people who are on the same page as you. It's also not too often in life you can find yourself working in a job where the things you are passionately interested in are what people want you to work on. Combine the two previously mentioned \"hard-to-find\" qualities with a brand new MacBook Pro and a healthy salary (there's something to be said for getting paid well for the things you love to do) and you have what I would consider the recipe for the perfect job; aka: work bliss.\n\nToday is my first day at [VendAsta](https://www.vendasta.com) and already I've been able to configure my work environment the way I want (3 cheers for [TextMate](https://macromates.com/), [SVN](https://subversion.tigris.org/), [FireBug](https://www.getfirebug.com), [FireWorks](https://www.adobe.com/fireworks)) after being told if there was anything I need to just let them know and they'd have no problem getting it. So I got right into things, checked out a few projects from SVN that we're working on utilizing [Django](https://www.djangoproject.com) and [Google App Engine](https://code.google.com/appengine/). Normally at a new job you'd probably have a lot of red tape and \"new hire\" overhead to go through; not at VendAsta.\n\n<**sarcasm**>I couldn't believe there was **gasp** documentation for the projects!</**sarcasm**> There's something to be said for working with quality processes like [Scrum](https://en.wikipedia.org/wiki/Scrum_(development)) and [Agile](https://en.wikipedia.org/wiki/Agile_software_development), and great tools like [JIRA](https://www.atlassian.com/software/jira/) and [GoogleApps](https://www.google.com/a/help/intl/en/index.html) at a software development company; try working without these things, it's just not fun.\n\nI think the thing I've been impressed with most in my first day at VendAsta is the fact that there are people who are willing to listen to my ideas. I don't feel intimidated at all, the culture here is very welcoming and open and the tools provided make it very easy to actually want to be as productive as you can be. Obviously it's only the first day on the job so I can't expect you all to take everything I'm saying at face value. Time will tell how things pan out, but after the first day I can definitely say that my first day @ VendAsta has been far more enlightening and empowering than a couple of years working for other companies.\n"
}></{
  "path": "app/posts/2008-08-18-work-bliss.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Work Bliss",
      "date": "2008-08-18"
    },
    "source": "\n> Normally I think most people would associate work with emotions other than bliss.\n\nIt's not often in life you can find yourself working in a job with people who are on the same page as you. It's also not too often in life you can find yourself working in a job where the things you are passionately interested in are what people want you to work on. Combine the two previously mentioned \"hard-to-find\" qualities with a brand new MacBook Pro and a healthy salary (there's something to be said for getting paid well for the things you love to do) and you have what I would consider the recipe for the perfect job; aka: work bliss.\n\nToday is my first day at [VendAsta](https://www.vendasta.com) and already I've been able to configure my work environment the way I want (3 cheers for [TextMate](https://macromates.com/), [SVN](https://subversion.tigris.org/), [FireBug](https://www.getfirebug.com), [FireWorks](https://www.adobe.com/fireworks)) after being told if there was anything I need to just let them know and they'd have no problem getting it. So I got right into things, checked out a few projects from SVN that we're working on utilizing [Django](https://www.djangoproject.com) and [Google App Engine](https://code.google.com/appengine/). Normally at a new job you'd probably have a lot of red tape and \"new hire\" overhead to go through; not at VendAsta.\n\n<**sarcasm**>I couldn't believe there was **gasp** documentation for the projects!</**sarcasm**> There's something to be said for working with quality processes like [Scrum](https://en.wikipedia.org/wiki/Scrum_(development)) and [Agile](https://en.wikipedia.org/wiki/Agile_software_development), and great tools like [JIRA](https://www.atlassian.com/software/jira/) and [GoogleApps](https://www.google.com/a/help/intl/en/index.html) at a software development company; try working without these things, it's just not fun.\n\nI think the thing I've been impressed with most in my first day at VendAsta is the fact that there are people who are willing to listen to my ideas. I don't feel intimidated at all, the culture here is very welcoming and open and the tools provided make it very easy to actually want to be as productive as you can be. Obviously it's only the first day on the job so I can't expect you all to take everything I'm saying at face value. Time will tell how things pan out, but after the first day I can definitely say that my first day @ VendAsta has been far more enlightening and empowering than a couple of years working for other companies.\n"
  },
  "attributes": {
    "title": "Work Bliss",
    "date": "2008-08-18"
  },
  "markdown": "\n> Normally I think most people would associate work with emotions other than bliss.\n\nIt's not often in life you can find yourself working in a job with people who are on the same page as you. It's also not too often in life you can find yourself working in a job where the things you are passionately interested in are what people want you to work on. Combine the two previously mentioned \"hard-to-find\" qualities with a brand new MacBook Pro and a healthy salary (there's something to be said for getting paid well for the things you love to do) and you have what I would consider the recipe for the perfect job; aka: work bliss.\n\nToday is my first day at [VendAsta](https://www.vendasta.com) and already I've been able to configure my work environment the way I want (3 cheers for [TextMate](https://macromates.com/), [SVN](https://subversion.tigris.org/), [FireBug](https://www.getfirebug.com), [FireWorks](https://www.adobe.com/fireworks)) after being told if there was anything I need to just let them know and they'd have no problem getting it. So I got right into things, checked out a few projects from SVN that we're working on utilizing [Django](https://www.djangoproject.com) and [Google App Engine](https://code.google.com/appengine/). Normally at a new job you'd probably have a lot of red tape and \"new hire\" overhead to go through; not at VendAsta.\n\n<**sarcasm**>I couldn't believe there was **gasp** documentation for the projects!</**sarcasm**> There's something to be said for working with quality processes like [Scrum](https://en.wikipedia.org/wiki/Scrum_(development)) and [Agile](https://en.wikipedia.org/wiki/Agile_software_development), and great tools like [JIRA](https://www.atlassian.com/software/jira/) and [GoogleApps](https://www.google.com/a/help/intl/en/index.html) at a software development company; try working without these things, it's just not fun.\n\nI think the thing I've been impressed with most in my first day at VendAsta is the fact that there are people who are willing to listen to my ideas. I don't feel intimidated at all, the culture here is very welcoming and open and the tools provided make it very easy to actually want to be as productive as you can be. Obviously it's only the first day on the job so I can't expect you all to take everything I'm saying at face value. Time will tell how things pan out, but after the first day I can definitely say that my first day @ VendAsta has been far more enlightening and empowering than a couple of years working for other companies.\n"
}></pre></div><div><a href="/posts/2007-01-01-bundle-links.html">Talks, Screencasts &amp; Links</a><pre><{
  "path": "app/posts/2007-01-01-bundle-links.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Talks, Screencasts & Links",
      "date": "2007-01-01"
    },
    "source": "\n> Link Bundles for various talks and screencasts I've given\n\n***\n\n<iframe id=\"empath-equation\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/_ECwOcrKqo0\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [The Empathy Equation: Slides on Speakerdeck](https://speakerdeck.com/dmosher/the-empathy-equation)\n* [Five Dysfunctions Products | The Table Group](https://www.tablegroup.com/books/dysfunctions)\n* [Crucial Conversations | Joseph Grenny - YouTube](https://www.youtube.com/watch?v=PuJgqTs-G44)\n* [Books - 7 Habits of Highly Effective People](https://www.stephencovey.com/7habits/7habits.php)\n* [Crucial Conversations Book - VitalSmarts](https://www.vitalsmarts.com/crucialconversations/)\n\n***\n\n<iframe id=\"javascript-coffeescript-dsl\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/EOksrrySfwI\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Building DSLs with JavaScript and CoffeeScript // Speaker Deck](https://speakerdeck.com/dmosher/building-dsls-with-javascript-and-coffeescript)\n* [davemo/jsdsl · GitHub](https://github.com/davemo/jsdsl)\n* [Proxy - JavaScript | MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy)\n* [Data model — Python 2.7.8 documentation](https://docs.python.org/2/reference/datamodel.html#customizing-attribute-access)\n* [Meta-Programming in JavaScript](https://aaronblohowiak.telegr.am/blog_posts/meta-programming-in-javascript)\n* [Fowler on the Fluent Interface](https://martinfowler.com/bliki/FluentInterface.html)\n* [Fowler on Domain Specific Languages](https://martinfowler.com/books/dsl.html)\n* [testdouble/backbone-fixins · GitHub](https://github.com/testdouble/backbone-fixins)\n\n***\n\n<iframe id=\"frontend-workflows-grunt-and-angular\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/fSAgFxjFSqY\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Ender - the no-library JavaScript library](https://ender.jit.su/)\n* [ded/reqwest · GitHub](https://github.com/ded/reqwest)\n* [Frontend Workflows with Grunt and Angular on Github](https://github.com/davemo/frontend-workflows-with-grunt-and-angularjs)\n\n***\n\n<iframe id=\"security-with-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/18ifoT-Id54\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Best Practices for Designing a Pragmatic RESTful API | Vinay Sahni](https://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api)\n* [Comparing 370eddc83f...f2e04b5c9a · davemo/end-to-end-with-angularjs · GitHub](https://github.com/davemo/end-to-end-with-angularjs/compare/370eddc83f...f2e04b5c9a)\n* [Troy Hunt: Your login form posts to HTTPS, but you blew it when you loaded it over HTTP](https://www.troyhunt.com/your-login-form-posts-to-https-but-you/)\n\n***\n\n<iframe id=\"end-to-end-with-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/hqAyiqUs93c\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [davemo/end-to-end-with-angularjs · GitHub](https://github.com/davemo/end-to-end-with-angularjs)\n* [Laravel 4: Protecting Routes](https://four.laravel.com/docs/security#protecting-routes)\n* [Laravel 4 Mastery | Nettuts+](https://net.tutsplus.com/tutorials/php/laravel-4-mastery/)\n* [Laravel 4 Documentation](https://four.laravel.com/)\n* [Authentication in Single Page Applications with Angular.js - A Modest Proposal](https://www.frederiknakstad.com/authentication-in-single-page-applications-with-angular-js/)\n\n***\n\n<iframe id=\"introduction-to-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/8ILQOFAgaXE\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [btford/ngmin · GitHub](https://github.com/btford/ngmin)\n* [paulirish/dotfiles · GitHub](https://github.com/paulirish/dotfiles/blob/master/.functions#L26)\n* [Welcome to Yearofmoo](https://www.yearofmoo.com/)\n* [Excellent 5-Minute Angular JS tutorial videos by John Lindquist](https://www.egghead.io/)\n* [Architecting Your Application for Testability - YouTube](https://www.youtube.com/watch?v=JjqKQ8ezwKQ)\n* [Bringing Angular Apps to Life with Animation by Miško Hevery - YouTube](https://www.youtube.com/watch?feature=player_embedded&v=cF_JsA9KsDM)\n* [davemo/intro-to-angularjs · GitHub](https://github.com/davemo/intro-to-angularjs)\n\n***\n\n<iframe id=\"mobile-ui-components-with-composition\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/9cBSl1w8cxA\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [davemo/composing-mobile-widgets · GitHub](https://github.com/davemo/composing-mobile-widgets)\n* [Multiple inheritance - Wikipedia](https://en.wikipedia.org/wiki/Diamond_problem#The_diamond_problem)\n* [Mixin - Wikipedia](https://en.wikipedia.org/wiki/Mixin)\n* [Microjs: Fantastic Micro-Frameworks and Micro-Libraries](https://microjs.com/)\n* [Zepto.js: the aerogel-weight jQuery-compatible JavaScript library](https://zeptojs.com/)\n* [Backbone.js](https://backbonejs.org/)\n* [Foundation from ZURB](https://foundation.zurb.com/)\n\n***\n\n<iframe id=\"inversion-of-control-ui-thread-backbone-views\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/mU1JcPikdMs\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [How Chromium Displays Web Pages - The Chromium Projects](https://www.chromium.org/developers/design-documents/displaying-a-web-page-in-chrome)\n* [Browsers are single threaded and this single thread (The UI thread) is shared between the rendering engine and the js engine.](https://stackoverflow.com/a/9084320)\n* [Events and timing in-depth](https://javascript.info/tutorial/events-and-timing-depth)\n* [Script yielding with setImmediate | NCZOnline](https://www.nczonline.net/blog/2011/09/19/script-yielding-with-setimmediate/)\n* [Underscore.js Defer](https://underscorejs.org/#defer)\n* [What is a non-blocking script? | NCZOnline](https://www.nczonline.net/blog/2010/08/10/what-is-a-non-blocking-script/)\n\n***\n\n<iframe id=\"so-you-want-to-be-a-frontend-engineer\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/Lsg84NtJbmI\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [So, You Want to Be a Front-End Engineer? // Speaker Deck](https://speakerdeck.com/dmosher/so-you-want-to-be-a-front-end-engineer)\n* [CSS display: inline-Block: Why It Rocks, And Why It Sucks](https://robertnyman.com/2010/02/24/css-display-inline-block-why-it-rocks-and-why-it-sucks/)\n* [Should You Reset Your CSS?](https://sixrevisions.com/css/should-you-reset-your-css/)\n* [Perfection kills » Profiling CSS for fun and profit. Optimization notes.](https://perfectionkills.com/profiling-css-for-fun-and-profit-optimization-notes/)\n* [Our (CSS) Best Practices Are Killing US](https://www.stubbornella.org/content/2011/04/28/our-best-practices-are-killing-us/)\n* [Modern Web Development](https://jtaby.com/2012/04/23/modern-web-development-part-1.html)\n* [Tooling & The Webapp Development Stack](https://dl.dropbox.com/u/39519/talks/tooling-q1/index.html)\n* [Roundup on Parallel Connections | High Performance Web Sites](https://www.stevesouders.com/blog/2008/03/20/roundup-on-parallel-connections/)\n* [How Browsers Work: Behind the scenes of modern web browsers - HTML5 Rocks](https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/)\n* [Reflows & Repaints: CSS Performance making your JavaScript slow?](https://www.stubbornella.org/content/2009/03/27/reflows-repaints-css-performance-making-your-javascript-slow/)\n"
  },
  "attributes": {
    "title": "Talks, Screencasts & Links",
    "date": "2007-01-01"
  },
  "markdown": "\n> Link Bundles for various talks and screencasts I've given\n\n***\n\n<iframe id=\"empath-equation\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/_ECwOcrKqo0\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [The Empathy Equation: Slides on Speakerdeck](https://speakerdeck.com/dmosher/the-empathy-equation)\n* [Five Dysfunctions Products | The Table Group](https://www.tablegroup.com/books/dysfunctions)\n* [Crucial Conversations | Joseph Grenny - YouTube](https://www.youtube.com/watch?v=PuJgqTs-G44)\n* [Books - 7 Habits of Highly Effective People](https://www.stephencovey.com/7habits/7habits.php)\n* [Crucial Conversations Book - VitalSmarts](https://www.vitalsmarts.com/crucialconversations/)\n\n***\n\n<iframe id=\"javascript-coffeescript-dsl\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/EOksrrySfwI\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Building DSLs with JavaScript and CoffeeScript // Speaker Deck](https://speakerdeck.com/dmosher/building-dsls-with-javascript-and-coffeescript)\n* [davemo/jsdsl · GitHub](https://github.com/davemo/jsdsl)\n* [Proxy - JavaScript | MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy)\n* [Data model — Python 2.7.8 documentation](https://docs.python.org/2/reference/datamodel.html#customizing-attribute-access)\n* [Meta-Programming in JavaScript](https://aaronblohowiak.telegr.am/blog_posts/meta-programming-in-javascript)\n* [Fowler on the Fluent Interface](https://martinfowler.com/bliki/FluentInterface.html)\n* [Fowler on Domain Specific Languages](https://martinfowler.com/books/dsl.html)\n* [testdouble/backbone-fixins · GitHub](https://github.com/testdouble/backbone-fixins)\n\n***\n\n<iframe id=\"frontend-workflows-grunt-and-angular\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/fSAgFxjFSqY\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Ender - the no-library JavaScript library](https://ender.jit.su/)\n* [ded/reqwest · GitHub](https://github.com/ded/reqwest)\n* [Frontend Workflows with Grunt and Angular on Github](https://github.com/davemo/frontend-workflows-with-grunt-and-angularjs)\n\n***\n\n<iframe id=\"security-with-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/18ifoT-Id54\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Best Practices for Designing a Pragmatic RESTful API | Vinay Sahni](https://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api)\n* [Comparing 370eddc83f...f2e04b5c9a · davemo/end-to-end-with-angularjs · GitHub](https://github.com/davemo/end-to-end-with-angularjs/compare/370eddc83f...f2e04b5c9a)\n* [Troy Hunt: Your login form posts to HTTPS, but you blew it when you loaded it over HTTP](https://www.troyhunt.com/your-login-form-posts-to-https-but-you/)\n\n***\n\n<iframe id=\"end-to-end-with-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/hqAyiqUs93c\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [davemo/end-to-end-with-angularjs · GitHub](https://github.com/davemo/end-to-end-with-angularjs)\n* [Laravel 4: Protecting Routes](https://four.laravel.com/docs/security#protecting-routes)\n* [Laravel 4 Mastery | Nettuts+](https://net.tutsplus.com/tutorials/php/laravel-4-mastery/)\n* [Laravel 4 Documentation](https://four.laravel.com/)\n* [Authentication in Single Page Applications with Angular.js - A Modest Proposal](https://www.frederiknakstad.com/authentication-in-single-page-applications-with-angular-js/)\n\n***\n\n<iframe id=\"introduction-to-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/8ILQOFAgaXE\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [btford/ngmin · GitHub](https://github.com/btford/ngmin)\n* [paulirish/dotfiles · GitHub](https://github.com/paulirish/dotfiles/blob/master/.functions#L26)\n* [Welcome to Yearofmoo](https://www.yearofmoo.com/)\n* [Excellent 5-Minute Angular JS tutorial videos by John Lindquist](https://www.egghead.io/)\n* [Architecting Your Application for Testability - YouTube](https://www.youtube.com/watch?v=JjqKQ8ezwKQ)\n* [Bringing Angular Apps to Life with Animation by Miško Hevery - YouTube](https://www.youtube.com/watch?feature=player_embedded&v=cF_JsA9KsDM)\n* [davemo/intro-to-angularjs · GitHub](https://github.com/davemo/intro-to-angularjs)\n\n***\n\n<iframe id=\"mobile-ui-components-with-composition\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/9cBSl1w8cxA\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [davemo/composing-mobile-widgets · GitHub](https://github.com/davemo/composing-mobile-widgets)\n* [Multiple inheritance - Wikipedia](https://en.wikipedia.org/wiki/Diamond_problem#The_diamond_problem)\n* [Mixin - Wikipedia](https://en.wikipedia.org/wiki/Mixin)\n* [Microjs: Fantastic Micro-Frameworks and Micro-Libraries](https://microjs.com/)\n* [Zepto.js: the aerogel-weight jQuery-compatible JavaScript library](https://zeptojs.com/)\n* [Backbone.js](https://backbonejs.org/)\n* [Foundation from ZURB](https://foundation.zurb.com/)\n\n***\n\n<iframe id=\"inversion-of-control-ui-thread-backbone-views\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/mU1JcPikdMs\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [How Chromium Displays Web Pages - The Chromium Projects](https://www.chromium.org/developers/design-documents/displaying-a-web-page-in-chrome)\n* [Browsers are single threaded and this single thread (The UI thread) is shared between the rendering engine and the js engine.](https://stackoverflow.com/a/9084320)\n* [Events and timing in-depth](https://javascript.info/tutorial/events-and-timing-depth)\n* [Script yielding with setImmediate | NCZOnline](https://www.nczonline.net/blog/2011/09/19/script-yielding-with-setimmediate/)\n* [Underscore.js Defer](https://underscorejs.org/#defer)\n* [What is a non-blocking script? | NCZOnline](https://www.nczonline.net/blog/2010/08/10/what-is-a-non-blocking-script/)\n\n***\n\n<iframe id=\"so-you-want-to-be-a-frontend-engineer\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/Lsg84NtJbmI\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [So, You Want to Be a Front-End Engineer? // Speaker Deck](https://speakerdeck.com/dmosher/so-you-want-to-be-a-front-end-engineer)\n* [CSS display: inline-Block: Why It Rocks, And Why It Sucks](https://robertnyman.com/2010/02/24/css-display-inline-block-why-it-rocks-and-why-it-sucks/)\n* [Should You Reset Your CSS?](https://sixrevisions.com/css/should-you-reset-your-css/)\n* [Perfection kills » Profiling CSS for fun and profit. Optimization notes.](https://perfectionkills.com/profiling-css-for-fun-and-profit-optimization-notes/)\n* [Our (CSS) Best Practices Are Killing US](https://www.stubbornella.org/content/2011/04/28/our-best-practices-are-killing-us/)\n* [Modern Web Development](https://jtaby.com/2012/04/23/modern-web-development-part-1.html)\n* [Tooling & The Webapp Development Stack](https://dl.dropbox.com/u/39519/talks/tooling-q1/index.html)\n* [Roundup on Parallel Connections | High Performance Web Sites](https://www.stevesouders.com/blog/2008/03/20/roundup-on-parallel-connections/)\n* [How Browsers Work: Behind the scenes of modern web browsers - HTML5 Rocks](https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/)\n* [Reflows & Repaints: CSS Performance making your JavaScript slow?](https://www.stubbornella.org/content/2009/03/27/reflows-repaints-css-performance-making-your-javascript-slow/)\n"
}></{
  "path": "app/posts/2007-01-01-bundle-links.md",
  "htmlDirPath": "posts",
  "dateFormat": "MMMM Do, YYYY",
  "_markdown": {
    "header": {
      "title": "Talks, Screencasts & Links",
      "date": "2007-01-01"
    },
    "source": "\n> Link Bundles for various talks and screencasts I've given\n\n***\n\n<iframe id=\"empath-equation\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/_ECwOcrKqo0\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [The Empathy Equation: Slides on Speakerdeck](https://speakerdeck.com/dmosher/the-empathy-equation)\n* [Five Dysfunctions Products | The Table Group](https://www.tablegroup.com/books/dysfunctions)\n* [Crucial Conversations | Joseph Grenny - YouTube](https://www.youtube.com/watch?v=PuJgqTs-G44)\n* [Books - 7 Habits of Highly Effective People](https://www.stephencovey.com/7habits/7habits.php)\n* [Crucial Conversations Book - VitalSmarts](https://www.vitalsmarts.com/crucialconversations/)\n\n***\n\n<iframe id=\"javascript-coffeescript-dsl\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/EOksrrySfwI\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Building DSLs with JavaScript and CoffeeScript // Speaker Deck](https://speakerdeck.com/dmosher/building-dsls-with-javascript-and-coffeescript)\n* [davemo/jsdsl · GitHub](https://github.com/davemo/jsdsl)\n* [Proxy - JavaScript | MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy)\n* [Data model — Python 2.7.8 documentation](https://docs.python.org/2/reference/datamodel.html#customizing-attribute-access)\n* [Meta-Programming in JavaScript](https://aaronblohowiak.telegr.am/blog_posts/meta-programming-in-javascript)\n* [Fowler on the Fluent Interface](https://martinfowler.com/bliki/FluentInterface.html)\n* [Fowler on Domain Specific Languages](https://martinfowler.com/books/dsl.html)\n* [testdouble/backbone-fixins · GitHub](https://github.com/testdouble/backbone-fixins)\n\n***\n\n<iframe id=\"frontend-workflows-grunt-and-angular\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/fSAgFxjFSqY\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Ender - the no-library JavaScript library](https://ender.jit.su/)\n* [ded/reqwest · GitHub](https://github.com/ded/reqwest)\n* [Frontend Workflows with Grunt and Angular on Github](https://github.com/davemo/frontend-workflows-with-grunt-and-angularjs)\n\n***\n\n<iframe id=\"security-with-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/18ifoT-Id54\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Best Practices for Designing a Pragmatic RESTful API | Vinay Sahni](https://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api)\n* [Comparing 370eddc83f...f2e04b5c9a · davemo/end-to-end-with-angularjs · GitHub](https://github.com/davemo/end-to-end-with-angularjs/compare/370eddc83f...f2e04b5c9a)\n* [Troy Hunt: Your login form posts to HTTPS, but you blew it when you loaded it over HTTP](https://www.troyhunt.com/your-login-form-posts-to-https-but-you/)\n\n***\n\n<iframe id=\"end-to-end-with-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/hqAyiqUs93c\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [davemo/end-to-end-with-angularjs · GitHub](https://github.com/davemo/end-to-end-with-angularjs)\n* [Laravel 4: Protecting Routes](https://four.laravel.com/docs/security#protecting-routes)\n* [Laravel 4 Mastery | Nettuts+](https://net.tutsplus.com/tutorials/php/laravel-4-mastery/)\n* [Laravel 4 Documentation](https://four.laravel.com/)\n* [Authentication in Single Page Applications with Angular.js - A Modest Proposal](https://www.frederiknakstad.com/authentication-in-single-page-applications-with-angular-js/)\n\n***\n\n<iframe id=\"introduction-to-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/8ILQOFAgaXE\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [btford/ngmin · GitHub](https://github.com/btford/ngmin)\n* [paulirish/dotfiles · GitHub](https://github.com/paulirish/dotfiles/blob/master/.functions#L26)\n* [Welcome to Yearofmoo](https://www.yearofmoo.com/)\n* [Excellent 5-Minute Angular JS tutorial videos by John Lindquist](https://www.egghead.io/)\n* [Architecting Your Application for Testability - YouTube](https://www.youtube.com/watch?v=JjqKQ8ezwKQ)\n* [Bringing Angular Apps to Life with Animation by Miško Hevery - YouTube](https://www.youtube.com/watch?feature=player_embedded&v=cF_JsA9KsDM)\n* [davemo/intro-to-angularjs · GitHub](https://github.com/davemo/intro-to-angularjs)\n\n***\n\n<iframe id=\"mobile-ui-components-with-composition\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/9cBSl1w8cxA\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [davemo/composing-mobile-widgets · GitHub](https://github.com/davemo/composing-mobile-widgets)\n* [Multiple inheritance - Wikipedia](https://en.wikipedia.org/wiki/Diamond_problem#The_diamond_problem)\n* [Mixin - Wikipedia](https://en.wikipedia.org/wiki/Mixin)\n* [Microjs: Fantastic Micro-Frameworks and Micro-Libraries](https://microjs.com/)\n* [Zepto.js: the aerogel-weight jQuery-compatible JavaScript library](https://zeptojs.com/)\n* [Backbone.js](https://backbonejs.org/)\n* [Foundation from ZURB](https://foundation.zurb.com/)\n\n***\n\n<iframe id=\"inversion-of-control-ui-thread-backbone-views\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/mU1JcPikdMs\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [How Chromium Displays Web Pages - The Chromium Projects](https://www.chromium.org/developers/design-documents/displaying-a-web-page-in-chrome)\n* [Browsers are single threaded and this single thread (The UI thread) is shared between the rendering engine and the js engine.](https://stackoverflow.com/a/9084320)\n* [Events and timing in-depth](https://javascript.info/tutorial/events-and-timing-depth)\n* [Script yielding with setImmediate | NCZOnline](https://www.nczonline.net/blog/2011/09/19/script-yielding-with-setimmediate/)\n* [Underscore.js Defer](https://underscorejs.org/#defer)\n* [What is a non-blocking script? | NCZOnline](https://www.nczonline.net/blog/2010/08/10/what-is-a-non-blocking-script/)\n\n***\n\n<iframe id=\"so-you-want-to-be-a-frontend-engineer\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/Lsg84NtJbmI\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [So, You Want to Be a Front-End Engineer? // Speaker Deck](https://speakerdeck.com/dmosher/so-you-want-to-be-a-front-end-engineer)\n* [CSS display: inline-Block: Why It Rocks, And Why It Sucks](https://robertnyman.com/2010/02/24/css-display-inline-block-why-it-rocks-and-why-it-sucks/)\n* [Should You Reset Your CSS?](https://sixrevisions.com/css/should-you-reset-your-css/)\n* [Perfection kills » Profiling CSS for fun and profit. Optimization notes.](https://perfectionkills.com/profiling-css-for-fun-and-profit-optimization-notes/)\n* [Our (CSS) Best Practices Are Killing US](https://www.stubbornella.org/content/2011/04/28/our-best-practices-are-killing-us/)\n* [Modern Web Development](https://jtaby.com/2012/04/23/modern-web-development-part-1.html)\n* [Tooling & The Webapp Development Stack](https://dl.dropbox.com/u/39519/talks/tooling-q1/index.html)\n* [Roundup on Parallel Connections | High Performance Web Sites](https://www.stevesouders.com/blog/2008/03/20/roundup-on-parallel-connections/)\n* [How Browsers Work: Behind the scenes of modern web browsers - HTML5 Rocks](https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/)\n* [Reflows & Repaints: CSS Performance making your JavaScript slow?](https://www.stubbornella.org/content/2009/03/27/reflows-repaints-css-performance-making-your-javascript-slow/)\n"
  },
  "attributes": {
    "title": "Talks, Screencasts & Links",
    "date": "2007-01-01"
  },
  "markdown": "\n> Link Bundles for various talks and screencasts I've given\n\n***\n\n<iframe id=\"empath-equation\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/_ECwOcrKqo0\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [The Empathy Equation: Slides on Speakerdeck](https://speakerdeck.com/dmosher/the-empathy-equation)\n* [Five Dysfunctions Products | The Table Group](https://www.tablegroup.com/books/dysfunctions)\n* [Crucial Conversations | Joseph Grenny - YouTube](https://www.youtube.com/watch?v=PuJgqTs-G44)\n* [Books - 7 Habits of Highly Effective People](https://www.stephencovey.com/7habits/7habits.php)\n* [Crucial Conversations Book - VitalSmarts](https://www.vitalsmarts.com/crucialconversations/)\n\n***\n\n<iframe id=\"javascript-coffeescript-dsl\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/EOksrrySfwI\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Building DSLs with JavaScript and CoffeeScript // Speaker Deck](https://speakerdeck.com/dmosher/building-dsls-with-javascript-and-coffeescript)\n* [davemo/jsdsl · GitHub](https://github.com/davemo/jsdsl)\n* [Proxy - JavaScript | MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy)\n* [Data model — Python 2.7.8 documentation](https://docs.python.org/2/reference/datamodel.html#customizing-attribute-access)\n* [Meta-Programming in JavaScript](https://aaronblohowiak.telegr.am/blog_posts/meta-programming-in-javascript)\n* [Fowler on the Fluent Interface](https://martinfowler.com/bliki/FluentInterface.html)\n* [Fowler on Domain Specific Languages](https://martinfowler.com/books/dsl.html)\n* [testdouble/backbone-fixins · GitHub](https://github.com/testdouble/backbone-fixins)\n\n***\n\n<iframe id=\"frontend-workflows-grunt-and-angular\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/fSAgFxjFSqY\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Ender - the no-library JavaScript library](https://ender.jit.su/)\n* [ded/reqwest · GitHub](https://github.com/ded/reqwest)\n* [Frontend Workflows with Grunt and Angular on Github](https://github.com/davemo/frontend-workflows-with-grunt-and-angularjs)\n\n***\n\n<iframe id=\"security-with-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/18ifoT-Id54\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [Best Practices for Designing a Pragmatic RESTful API | Vinay Sahni](https://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api)\n* [Comparing 370eddc83f...f2e04b5c9a · davemo/end-to-end-with-angularjs · GitHub](https://github.com/davemo/end-to-end-with-angularjs/compare/370eddc83f...f2e04b5c9a)\n* [Troy Hunt: Your login form posts to HTTPS, but you blew it when you loaded it over HTTP](https://www.troyhunt.com/your-login-form-posts-to-https-but-you/)\n\n***\n\n<iframe id=\"end-to-end-with-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/hqAyiqUs93c\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [davemo/end-to-end-with-angularjs · GitHub](https://github.com/davemo/end-to-end-with-angularjs)\n* [Laravel 4: Protecting Routes](https://four.laravel.com/docs/security#protecting-routes)\n* [Laravel 4 Mastery | Nettuts+](https://net.tutsplus.com/tutorials/php/laravel-4-mastery/)\n* [Laravel 4 Documentation](https://four.laravel.com/)\n* [Authentication in Single Page Applications with Angular.js - A Modest Proposal](https://www.frederiknakstad.com/authentication-in-single-page-applications-with-angular-js/)\n\n***\n\n<iframe id=\"introduction-to-angularjs\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/8ILQOFAgaXE\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [btford/ngmin · GitHub](https://github.com/btford/ngmin)\n* [paulirish/dotfiles · GitHub](https://github.com/paulirish/dotfiles/blob/master/.functions#L26)\n* [Welcome to Yearofmoo](https://www.yearofmoo.com/)\n* [Excellent 5-Minute Angular JS tutorial videos by John Lindquist](https://www.egghead.io/)\n* [Architecting Your Application for Testability - YouTube](https://www.youtube.com/watch?v=JjqKQ8ezwKQ)\n* [Bringing Angular Apps to Life with Animation by Miško Hevery - YouTube](https://www.youtube.com/watch?feature=player_embedded&v=cF_JsA9KsDM)\n* [davemo/intro-to-angularjs · GitHub](https://github.com/davemo/intro-to-angularjs)\n\n***\n\n<iframe id=\"mobile-ui-components-with-composition\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/9cBSl1w8cxA\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [davemo/composing-mobile-widgets · GitHub](https://github.com/davemo/composing-mobile-widgets)\n* [Multiple inheritance - Wikipedia](https://en.wikipedia.org/wiki/Diamond_problem#The_diamond_problem)\n* [Mixin - Wikipedia](https://en.wikipedia.org/wiki/Mixin)\n* [Microjs: Fantastic Micro-Frameworks and Micro-Libraries](https://microjs.com/)\n* [Zepto.js: the aerogel-weight jQuery-compatible JavaScript library](https://zeptojs.com/)\n* [Backbone.js](https://backbonejs.org/)\n* [Foundation from ZURB](https://foundation.zurb.com/)\n\n***\n\n<iframe id=\"inversion-of-control-ui-thread-backbone-views\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/mU1JcPikdMs\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [How Chromium Displays Web Pages - The Chromium Projects](https://www.chromium.org/developers/design-documents/displaying-a-web-page-in-chrome)\n* [Browsers are single threaded and this single thread (The UI thread) is shared between the rendering engine and the js engine.](https://stackoverflow.com/a/9084320)\n* [Events and timing in-depth](https://javascript.info/tutorial/events-and-timing-depth)\n* [Script yielding with setImmediate | NCZOnline](https://www.nczonline.net/blog/2011/09/19/script-yielding-with-setimmediate/)\n* [Underscore.js Defer](https://underscorejs.org/#defer)\n* [What is a non-blocking script? | NCZOnline](https://www.nczonline.net/blog/2010/08/10/what-is-a-non-blocking-script/)\n\n***\n\n<iframe id=\"so-you-want-to-be-a-frontend-engineer\" width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/Lsg84NtJbmI\" frameborder=\"0\" allowfullscreen></iframe>\n\n* [So, You Want to Be a Front-End Engineer? // Speaker Deck](https://speakerdeck.com/dmosher/so-you-want-to-be-a-front-end-engineer)\n* [CSS display: inline-Block: Why It Rocks, And Why It Sucks](https://robertnyman.com/2010/02/24/css-display-inline-block-why-it-rocks-and-why-it-sucks/)\n* [Should You Reset Your CSS?](https://sixrevisions.com/css/should-you-reset-your-css/)\n* [Perfection kills » Profiling CSS for fun and profit. Optimization notes.](https://perfectionkills.com/profiling-css-for-fun-and-profit-optimization-notes/)\n* [Our (CSS) Best Practices Are Killing US](https://www.stubbornella.org/content/2011/04/28/our-best-practices-are-killing-us/)\n* [Modern Web Development](https://jtaby.com/2012/04/23/modern-web-development-part-1.html)\n* [Tooling & The Webapp Development Stack](https://dl.dropbox.com/u/39519/talks/tooling-q1/index.html)\n* [Roundup on Parallel Connections | High Performance Web Sites](https://www.stevesouders.com/blog/2008/03/20/roundup-on-parallel-connections/)\n* [How Browsers Work: Behind the scenes of modern web browsers - HTML5 Rocks](https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/)\n* [Reflows & Repaints: CSS Performance making your JavaScript slow?](https://www.stubbornella.org/content/2009/03/27/reflows-repaints-css-performance-making-your-javascript-slow/)\n"
}></pre></div></div></section></article><footer class="root">&copy; 2021 - David A. Mosher</footer></div><script type="text/javascript" src="/js/app.js"></script></body></html>